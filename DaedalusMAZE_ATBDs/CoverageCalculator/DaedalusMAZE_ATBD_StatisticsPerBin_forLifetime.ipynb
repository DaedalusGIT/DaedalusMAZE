{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Joule Heating Statistics per Bin\n",
    "\n",
    "## Introduction\n",
    "Joule Heating is an observable which Daedalus satelite will be able to measure and is indicative of the phenomena we want to study. That is why we use it to check if Daedalus will be able to measure adequately the Thermosphere along his orbit.\n",
    "Our purpose is to compare the sparse Joule Heating measurements which Daedalus will take while he passes along areas of interest with the dense measurements across a space-time grid of the whole area of interest.\n",
    "The measurements data for the grid come from TIEGCM simulations for the 3 years of the mission (2015-7). The data measured along the orbit come from the same source, but are interpolated for each satellite position.\n",
    "In order to compare the results we employ several plots and calculate mean, variance and standard deviation values.\n",
    "\n",
    "#### Areas of interest\n",
    "We have defined large areas called \"regions\" and we devide them in smaller ones called 'bins'. The bin boundaries are defined by ranges of:\n",
    "1. Magnetic Local Time (MLT)\n",
    "2. Magnetic Latitude (MagLat)\n",
    "3. Altitude\n",
    "4. Geomagnetic Kp index\n",
    "For example, we have defined a region called \"AEM - Auroral E region, midnight sector\". AEM's boundaries are:\n",
    "     60 <  Magnetic Latitude  < 75\n",
    "  22:00 < Magnetic Local Time < 02:00\n",
    "    115 < Altitude            < 140\n",
    "      0 < Kp index            < 9\n",
    "AEM is divided in 9 bins according to smaller ranges of altitude and Kp index.\n",
    "\n",
    "## Data\n",
    "#### TIEGCM grid data \n",
    "The Thermosphere is described in several TIEGCM files of netCDF type. Each file contains simulated data for 5 days and we have files for the satellite's 3 years lifetime. Inside the file there are data for every 2.5 degrees of Latitude, for every 2.5 degrees of Longitude, for every 2 hours and for 57 pressure levels.\n",
    "#### Orbit data\n",
    "A simulated orbit provides data about each position of the satellite stored in netCDF format. These include time, latitude, longitude, altitude Magnetic Latitude, Magnetic Local Time, Kp index and interpolated Joule Heating value.\n",
    "#### Result data\n",
    "The result data are stored in order to be ploted easier without the time intensive calculation.\n",
    "The execution and ploting is separated in regions to make calculations easier to handle and plot more clear.\n",
    "The result data are stored in both netCDF and plain text format and contain Joule Heating measurements across the area of interest. \n",
    "\n",
    "\n",
    "## Algorithms Description\n",
    "Firstly, we use the TIEGCM grid data in order to have a picture of Joule Heating for each area of interest. \n",
    "A) For each area of interest:\n",
    "     - parse all TIEGCM files and for every point of the space-time grid:\n",
    "        - check if the point lies inside any of the pre-defined bins.\n",
    "        - if it does, then assign the Joule Heating value of this point to the correct bin.\n",
    "     - for each bin calculate the mean, variance, standard deviation of Joule Heating.\n",
    "     - all the generated data constitute the TIEGCM-grid results\n",
    "     \n",
    "Afterwards we use the orbit data in order see the Joule Heating the satellite will be able to measure.\n",
    "B) For each area of interest:\n",
    "    - For every satellite position check if the satellite position lies inside any of the pre-defined bins:\n",
    "\t\t1. read Altitude, Magnetic-Latitude, Magnetic-Local-Time.\n",
    "\t\t2. Check if the above values lie inside the ranges of a bin.\n",
    "\t   \t   If they do then we have to check the Kp-value following the next step. \t\t   \n",
    "\t\t4. Kp index is stored in a TIEGCM file. \n",
    "           Read the time of the satellite position and locate the corresponding TIEGCM file.\n",
    "\t\t5. Read the Kp-value according to the current time.\n",
    "\t\t6. Now we can check if the satellite position really lies inside a bin.\n",
    "\t\t   If it does, then assign the Joule Heating value to the correct bin.\n",
    "    - for each bin calculate the mean, variance, standard deviation of Joule Heating.\n",
    "    - all the generated data constitute the along-Orbit results\n",
    "\n",
    "\n",
    "## Plots\n",
    "We have constructed several plots to display the multi-dimensional data which result from the algorithm.\n",
    "Both TIEGCM-grid and along-Orbit results are demonstrated using the same plots as described below.\n",
    "#### Joule Heating versus Magnetic Latitude / Magnetic Local Time / Altitude\n",
    "In these scatter plots each dot represents an instance of a measurement which was taken inside the area of interest. \n",
    "The plot usually does not display all the measurements because of their vast number. The plot also contains lines which indicate the Joule Heating mean and standard deviation calculated on all the values of the area of interest. The mean is displayed as a horizontal line and the standard deviation as a vertical line. \n",
    "The same plots are also available in a divided-by-Kp form. The Joule Heating versus Altiude plot display lines which connect the measurements which are successive along the orbit of the satellite (applies only on orbit data).\n",
    "#### Joule Heating distribution\n",
    "We provide a Joule Heating distribution plot for each area of interest and each bin. This plot can also display fitting functions along the data (An Euler function is usually the best fit).\n",
    "#### Altitude versus Magnetic Latitude\n",
    "There is also a scatter plot of Altitude versus Magnetic Latitude where each dot represents a measuremnt inside the area of interest and its color corresponds to its Joule Heating value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4429dff8af141e3adc97a0e857f1673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(VBox(children=(Dropdown(description='TIEGCM files: ', layout=Layout(width='780px'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGION = AEM\n",
      "Loading data set 1: /home/NAS/Data_Files/CoverageResults/AEM.TIEGCM_Lifetime_2015_to_2018_JH_QD.Lifetime_10sTricubic.ValuesPerBinResults.nc\n",
      "Started Loading /home/NAS/Data_Files/CoverageResults/AEM.TIEGCM_Lifetime_2015_to_2018_JH_QD.Lifetime_10sTricubic.ValuesPerBinResults.nc 2020-08-31 09:25:51.486686\n",
      "Now Loading /home/NAS/Data_Files/CoverageResults/AEM.TIEGCM_Lifetime_2015_to_2018_JH_QD.Lifetime_10sTricubic.ValuesPerBinResults.nc\n",
      "DateOfCreation: 23-08-2020 21:40:00  LastExecDurationSec : 453 sec\n",
      "Region: AEM\n",
      "OrbitFile: /home/NAS/Data_Files/InterpolatedData/Lifetime_10sTricubic/\n",
      "TIEGCM data path: /home/NAS/TIEGCM_DATA_2/TIEGCM_Lifetime_2015_to_2018_JH_QD/ \n",
      "\n",
      "AEM_L3 LENGTH BEFORE: 106\n",
      "AEM_L3 : huge values = 0 negative values = 0 nan values = 0\n",
      "AEM_L3 LENGTH AFTER: 106\n",
      "AEM_L4 LENGTH BEFORE: 1345\n",
      "AEM_L4 : huge values = 0 negative values = 0 nan values = 0\n",
      "AEM_L4 LENGTH AFTER: 1345\n",
      "AEM_L5 LENGTH BEFORE: 638\n",
      "AEM_L5 : huge values = 0 negative values = 0 nan values = 5\n",
      "AEM_L5 LENGTH AFTER: 633\n",
      "AEM_L6 LENGTH BEFORE: 416\n",
      "AEM_L6 : huge values = 0 negative values = 0 nan values = 6\n",
      "AEM_L6 LENGTH AFTER: 410\n",
      "AEM_L7 LENGTH BEFORE: 309\n",
      "AEM_L7 : huge values = 0 negative values = 0 nan values = 6\n",
      "AEM_L7 LENGTH AFTER: 303\n",
      "AEM_L8 LENGTH BEFORE: 354\n",
      "AEM_L8 : huge values = 0 negative values = 0 nan values = 9\n",
      "AEM_L8 LENGTH AFTER: 345\n",
      "AEM_L9 LENGTH BEFORE: 1092\n",
      "AEM_L9 : huge values = 3 negative values = 0 nan values = 14\n",
      "AEM_L9 LENGTH AFTER: 1075\n",
      "AEM_M2 LENGTH BEFORE: 651\n",
      "AEM_M2 : huge values = 0 negative values = 0 nan values = 0\n",
      "AEM_M2 LENGTH AFTER: 651\n",
      "AEM_M3 LENGTH BEFORE: 1064\n",
      "AEM_M3 : huge values = 0 negative values = 0 nan values = 0\n",
      "AEM_M3 LENGTH AFTER: 1064\n",
      "AEM_M4 LENGTH BEFORE: 439\n",
      "AEM_M4 : huge values = 0 negative values = 0 nan values = 0\n",
      "AEM_M4 LENGTH AFTER: 439\n",
      "AEM_M5 LENGTH BEFORE: 293\n",
      "AEM_M5 : huge values = 0 negative values = 0 nan values = 6\n",
      "AEM_M5 LENGTH AFTER: 287\n",
      "AEM_M6 LENGTH BEFORE: 1213\n",
      "AEM_M6 : huge values = 1 negative values = 0 nan values = 11\n",
      "AEM_M6 LENGTH AFTER: 1201\n",
      "AEM_H0 LENGTH BEFORE: 298\n",
      "AEM_H0 : huge values = 0 negative values = 0 nan values = 0\n",
      "AEM_H0 LENGTH AFTER: 298\n",
      "ALL LENGTH BEFORE: 0\n",
      "Globaly : huge values = 0 negative values = 0 nan values = 0\n",
      "ALL LENGTH AFTER: 0\n",
      "Results loaded for Joule Heating      2020-08-31 09:25:52.073696 \n",
      "\n",
      "AEM_L0 has a only 0 items\n",
      "AEM_L1 has a only 0 items\n",
      "AEM_L2 has a only 0 items\n",
      "-------- TIEGCM AEM_L3 --------\n",
      "[8.632764e-09, 7.626236e-09, 9.158214e-09, 4.4775312e-08, 3.9786907e-09, 1.1302665e-09, 9.59743e-09, 6.0421987e-09, 1.0862158e-08, 2.9865572e-09, 1.9534196e-09, 5.868255e-09, 1.3744219e-08, 6.8654584e-09, 1.4394955e-08, 5.753379e-09, 2.2330422e-08, 1.3144792e-08, 1.131081e-09, 2.6552485e-09, 7.085707e-10, 1.2934118e-10, 1.7545916e-09, 5.425045e-11, 5.513017e-09, 1.1671721e-08, 4.0559565e-09, 1.9303934e-09, 7.578975e-09, 7.45251e-09, 8.577577e-09, 3.1551997e-09, 1.5335113e-08, 2.200603e-08, 6.180335e-10, 4.161787e-09, 8.3316865e-09, 2.648565e-09, 2.8990375e-08, 2.0349551e-08, 3.7337498e-09, 3.5509554e-08, 8.963014e-09, 6.257841e-10, 1.4341107e-09, 4.4596957e-09, 3.9892103e-09, 1.9077603e-08, 8.019137e-09, 1.3378855e-08]\n",
      "-------- TIEGCM AEM_L4 --------\n",
      "[2.4541387e-09, 4.4620507e-09, 1.5458168e-08, 2.7210891e-09, 5.0512533e-08, 1.8349533e-08, 2.7607747e-08, 9.222935e-09, 4.2084625e-09, 2.1761451e-08, 1.6244672e-09, 3.3251732e-09, 1.2677986e-10, 1.1984411e-09, 4.447405e-08, 2.259714e-09, 3.6127366e-09, 2.8836178e-09, 8.6880256e-08, 1.1406422e-09, 3.035486e-08, 3.5265818e-10, 4.5048754e-08, 1.5642927e-09, 6.522572e-09, 1.6288768e-09, 1.0833033e-09, 5.221942e-09, 2.5081903e-09, 1.1579668e-09, 2.25799e-08, 3.3118162e-09, 4.6682523e-08, 1.0830929e-08, 2.2595302e-10, 5.6156306e-09, 2.9106109e-09, 4.0088155e-09, 3.3064826e-09, 2.8685227e-08, 4.7318474e-09, 2.5109628e-08, 4.319776e-08, 9.772444e-10, 3.721775e-10, 4.73177e-09, 2.9439076e-09, 4.5878001e-10, 6.964983e-10, 3.8196952e-09]\n",
      "-------- TIEGCM AEM_L5 --------\n",
      "[1.6405628e-10, 1.0552198e-09, 3.941937e-09, 1.4707498e-08, 8.250099e-09, 2.369378e-08, 2.6915735e-08, 1.4994129e-08, 8.977911e-10, 6.113494e-08, 7.990465e-10, 4.560219e-09, 5.0815014e-08, 5.265714e-10, 5.420074e-09, 1.3892109e-08, 7.7319315e-09, 6.0241345e-09, 1.9924453e-09, 3.8936583e-09, 4.554109e-09, 2.4569449e-09, 3.377603e-09, 3.7317275e-08, 1.3591978e-09, 4.5393115e-08, 2.7026577e-08, 3.9594354e-09, 1.9043365e-09, 1.1461939e-11, 1.48171475e-08, 3.0650933e-09, 5.5767844e-09, 2.847887e-10, 5.6962763e-09, 2.545026e-09, 4.1168533e-08, 2.7514101e-08, 2.7691613e-09, 4.9071294e-09, 6.7022743e-09, 5.5469065e-09, 8.159459e-09, 3.222398e-09, 5.6172045e-09, 7.419132e-09, 5.0613014e-08, 7.3408724e-10, 4.732916e-10, 1.5951841e-10]\n",
      "-------- TIEGCM AEM_L6 --------\n",
      "[3.779202e-09, 1.4948371e-08, 8.561353e-09, 2.8350456e-08, 8.812467e-09, 1.063264e-08, 3.387435e-08, 1.845526e-08, 1.9370484e-08, 1.0690398e-08, 3.7965897e-09, 3.7731382e-09, 5.298495e-10, 6.7601738e-09, 2.4517028e-08, 1.24350255e-08, 9.83231e-09, 1.2120321e-08, 4.583746e-09, 6.8467516e-09, 1.6953875e-08, 2.6772962e-09, 3.3586204e-08, 1.5620783e-08, 1.5461918e-09, 5.1614705e-08, 2.141698e-08, 6.217883e-10, 9.3161034e-09, 1.8696316e-09, 1.3922352e-09, 7.24515e-09, 3.544759e-08, 3.5736267e-09, 1.5242062e-08, 1.9698643e-09, 2.6612648e-08, 1.4150006e-09, 3.337319e-10, 2.5647853e-09, 9.512595e-09, 1.0245096e-09, 3.325935e-10, 4.3248027e-09, 1.8399606e-09, 6.6289383e-09, 3.2884575e-09, 1.0178862e-08, 2.510163e-09, 3.7950496e-08]\n",
      "-------- TIEGCM AEM_L7 --------\n",
      "[3.0072517e-08, 1.2319997e-08, 2.6727396e-09, 4.4041553e-09, 3.1284961e-09, 8.938044e-09, 2.2751358e-08, 4.842037e-08, 1.9464474e-09, 1.4289649e-08, 2.0824908e-08, 1.3134462e-08, 4.9947193e-09, 2.8368348e-09, 4.54157e-09, 5.4402346e-08, 2.2385272e-08, 1.8492927e-09, 1.1773549e-08, 1.3523496e-09, 1.7475245e-09, 1.7015582e-09, 4.3234e-08, 5.551199e-10, 8.682893e-11, 2.474849e-09, 3.299679e-08, 2.672096e-08, 7.720774e-09, 3.1143166e-08, 2.5455233e-08, 9.750235e-09, 1.8053598e-08, 8.423793e-09, 1.4020884e-08, 6.8329835e-09, 2.0086072e-10, 1.5450404e-08, 9.110998e-09, 3.3203443e-10, 5.141197e-10, 4.472572e-08, 7.9013045e-09, 3.166899e-10, 2.7805836e-08, 1.3091155e-09, 1.7792942e-08, 4.2556977e-08, 2.3626695e-10, 3.2074374e-10]\n",
      "-------- TIEGCM AEM_L8 --------\n",
      "[8.077551e-09, 1.366395e-08, 1.0521526e-09, 7.216828e-09, 9.001959e-10, 8.355397e-09, 3.892368e-10, 9.0389936e-09, 2.6784405e-10, 4.7574737e-08, 1.6062629e-09, 4.6271023e-09, 7.393343e-10, 5.977835e-09, 1.3356028e-08, 5.9715977e-10, 1.7870277e-10, 7.8667695e-10, 4.4407245e-10, 1.2783603e-09, 2.19152e-09, 9.324876e-11, 1.8672601e-09, 1.289136e-08, 2.4832595e-08, 6.5485864e-08, 1.2781325e-10, 4.5186037e-09, 1.3652296e-09, 5.3494484e-09, 9.518446e-10, 2.3775804e-10, 5.4674523e-09, 1.3110788e-09, 2.7656116e-10, 2.5179057e-09, 2.9804254e-10, 6.8526558e-09, 6.527231e-09, 5.050381e-10, 5.532512e-10, 2.7202599e-10, 5.2095572e-09, 1.4574264e-08, 3.50169e-10, 1.0654789e-10, 3.653689e-10, 2.0333653e-08, 2.1791315e-08, 3.0795266e-10]\n",
      "-------- TIEGCM AEM_L9 --------\n",
      "[3.948396e-09, 3.2364873e-08, 1.0891704e-08, 6.120798e-09, 1.18887415e-08, 8.3073576e-10, 4.7710675e-09, 1.3685884e-09, 9.938004e-10, 9.1200345e-09, 3.5990107e-11, 7.0984e-09, 3.449827e-08, 1.4456925e-08, 6.7942016e-09, 1.080567e-09, 1.2302118e-08, 1.3481872e-08, 3.6546945e-09, 1.189731e-10, 5.5979457e-09, 5.43365e-09, 6.3663355e-09, 3.5144057e-09, 6.6694494e-10, 6.2258616e-09, 2.5087722e-08, 5.209576e-09, 6.901406e-10, 2.0668127e-09, 3.8898582e-10, 9.948202e-10, 3.5832628e-08, 9.279485e-09, 2.6684083e-10, 2.3618252e-08, 7.504002e-09, 7.3158507e-10, 2.8104017e-09, 1.5685945e-08, 6.8206276e-09, 1.3497271e-08, 2.2899563e-10, 5.475458e-09, 2.7986426e-08, 1.5692596e-09, 4.9982516e-09, 1.3638532e-08, 1.2110233e-09, 4.118056e-09]\n",
      "AEM_M0 has a only 0 items\n",
      "AEM_M1 has a only 0 items\n",
      "-------- TIEGCM AEM_M2 --------\n",
      "[4.1573003e-09, 2.9826438e-08, 1.6130048e-08, 4.520783e-09, 4.5900497e-09, 3.6311252e-09, 2.0870843e-08, 5.1992264e-09, 2.599967e-08, 3.5483887e-09, 6.305207e-08, 2.275998e-09, 5.09884e-09, 1.970459e-08, 6.462966e-09, 3.5499465e-08, 1.6971013e-08, 8.417013e-08, 1.8309146e-08, 2.185963e-09, 5.5495796e-08, 1.4786553e-07, 5.9387704e-09, 5.833596e-10, 4.17957e-09, 3.000677e-08, 8.253755e-09, 8.042529e-08, 9.6280015e-09, 5.532808e-08, 5.334025e-09, 5.6706284e-09, 3.9948794e-08, 2.4242417e-09, 1.987425e-08, 1.7635042e-08, 3.493386e-09, 5.170347e-09, 6.1207905e-09, 1.4184964e-09, 2.1465265e-08, 1.5803532e-09, 8.934063e-09, 4.7381308e-09, 1.9004247e-08, 1.9632148e-08, 3.7935264e-09, 5.117589e-09, 2.195874e-08, 8.839965e-08]\n",
      "-------- TIEGCM AEM_M3 --------\n",
      "[1.0134735e-08, 8.901014e-09, 9.437738e-10, 6.905964e-08, 2.6099407e-08, 8.949655e-09, 9.149846e-08, 1.10459e-08, 5.0589296e-08, 2.5703417e-09, 2.4263535e-08, 5.3830902e-08, 4.7192903e-09, 1.8378385e-08, 4.957318e-09, 2.5082677e-08, 9.003894e-10, 7.435743e-09, 1.7199788e-08, 1.3777592e-09, 3.131143e-08, 9.492966e-10, 2.5754648e-08, 1.4409903e-08, 8.810861e-08, 7.464844e-10, 1.7579126e-07, 7.896942e-08, 2.2031204e-09, 1.4030467e-09, 1.2852331e-08, 7.505589e-09, 3.7557694e-08, 2.027145e-08, 2.8990463e-09, 1.00152215e-08, 5.1109827e-09, 2.7888472e-08, 9.068969e-09, 1.947189e-08, 2.356089e-08, 2.8573446e-09, 4.478181e-08, 2.0632175e-10, 3.843776e-08, 2.1345272e-08, 2.6223028e-09, 3.9300883e-09, 1.0655148e-08, 1.0590388e-08]\n",
      "-------- TIEGCM AEM_M4 --------\n",
      "[4.2117282e-08, 6.531626e-08, 4.207024e-08, 4.5676803e-08, 8.4936325e-10, 1.2617778e-09, 5.5835563e-09, 5.54211e-09, 2.5948719e-09, 1.274789e-08, 1.37254625e-08, 6.9793273e-09, 7.2316926e-09, 1.0113207e-08, 1.07522276e-07, 1.3219101e-09, 6.0447314e-10, 7.501244e-09, 1.10703695e-08, 5.6764033e-09, 4.286217e-08, 3.6216485e-10, 3.3167186e-08, 1.46615955e-08, 5.158223e-09, 1.0626935e-07, 2.7858434e-08, 1.7156995e-09, 3.8320085e-09, 9.664182e-09, 3.4222886e-08, 7.112415e-08, 6.9664874e-09, 2.1119494e-08, 6.226614e-08, 2.8689687e-08, 1.3569894e-09, 2.4287399e-08, 3.0387137e-09, 4.6467342e-08, 7.3419892e-09, 1.1085101e-08, 5.1373448e-09, 4.348565e-08, 5.3835986e-08, 7.371464e-08, 7.615061e-09, 5.2165277e-08, 5.627148e-09, 1.2066573e-08]\n",
      "-------- TIEGCM AEM_M5 --------\n",
      "[2.8034068e-09, 4.2387756e-09, 1.6666435e-08, 8.926513e-09, 5.3373034e-10, 5.4265787e-09, 1.8247608e-09, 3.165041e-10, 8.492951e-09, 1.143258e-08, 1.0003485e-09, 2.5208817e-09, 8.22046e-09, 1.381042e-08, 6.885143e-09, 1.4843723e-08, 2.328715e-09, 1.8506746e-08, 6.385513e-09, 5.5092425e-08, 7.924343e-10, 2.1879229e-08, 1.117014e-09, 8.549192e-09, 3.6005463e-08, 1.0125095e-08, 9.4653316e-08, 8.1708307e-10, 2.7459934e-09, 6.810599e-08, 1.989469e-08, 1.9299538e-08, 3.3734064e-08, 5.9077103e-09, 4.936804e-10, 1.5159827e-08, 3.6596834e-08, 4.24265e-08, 2.7585816e-09, 1.9110247e-09, 1.1135392e-08, 3.0011986e-08, 2.0062607e-09, 2.8038656e-08, 5.7437495e-09, 1.1067326e-08, 4.48492e-09, 1.0330753e-08, 1.6556276e-09, 6.0628684e-09]\n",
      "-------- TIEGCM AEM_M6 --------\n",
      "[1.4076666e-08, 3.203906e-09, 2.6253026e-09, 1.6934312e-09, 1.4836134e-08, 2.67626e-09, 8.276404e-10, 5.710643e-10, 2.5322326e-09, 1.1305817e-08, 6.752204e-09, 2.6105007e-09, 2.797438e-09, 2.9918812e-09, 1.7180823e-10, 6.3867525e-09, 7.49841e-11, 6.917905e-10, 1.8238642e-09, 8.342103e-09, 4.181378e-08, 1.783837e-10, 5.505429e-10, 5.226747e-08, 9.127576e-10, 3.9201375e-10, 2.081961e-09, 1.6772036e-08, 3.1461354e-09, 4.598456e-10, 7.483196e-09, 1.2420295e-10, 2.762125e-08, 5.5572773e-09, 7.414511e-09, 4.9925206e-09, 3.8836294e-09, 3.5071002e-09, 3.8875705e-11, 1.7269169e-09, 6.486406e-09, 2.5281564e-08, 3.491728e-08, 4.730329e-10, 3.4030863e-09, 9.078116e-09, 3.4224406e-08, 2.0092769e-10, 1.1977623e-09, 7.453466e-09]\n",
      "-------- TIEGCM AEM_H0 --------\n",
      "[4.055313e-09, 6.889758e-08, 7.24455e-08, 7.020406e-10, 1.63664e-08, 6.411259e-08, 2.3138935e-07, 9.788594e-10, 7.986417e-09, 5.7893352e-08, 2.908491e-09, 5.3151822e-08, 8.952107e-09, 7.299084e-08, 6.2822394e-08, 4.1558734e-09, 3.201661e-08, 1.22894015e-08, 4.0241713e-10, 9.3182244e-08, 2.0842307e-07, 2.440409e-07, 2.5661075e-09, 9.631402e-09, 1.001143e-08, 3.1844136e-09, 9.591661e-10, 4.5581023e-09, 8.364081e-10, 7.677696e-09, 2.7898328e-10, 2.4711413e-08, 1.460962e-07, 3.8031445e-08, 4.703161e-10, 1.4790551e-07, 1.5749669e-07, 1.5843662e-08, 6.1043166e-09, 7.333094e-08, 5.4826597e-09, 1.9635515e-10, 2.709268e-09, 1.1877127e-08, 3.4820282e-11, 1.3185834e-07, 1.0397883e-08, 4.1277235e-11, 3.2298853e-08, 1.7300543e-08]\n",
      "Data reduced to a sample of 50\n",
      "TIEGCM\n",
      "  AEM_L0  Mean = 0.000e+00  StDev = 0.000e+00  Median = 0.000e+00  MAD = 0.000e+00  points = 0\n",
      "  AEM_L1  Mean = 0.000e+00  StDev = 0.000e+00  Median = 0.000e+00  MAD = 0.000e+00  points = 0\n",
      "  AEM_L2  Mean = 0.000e+00  StDev = 0.000e+00  Median = 0.000e+00  MAD = 0.000e+00  points = 0\n",
      "  AEM_L3  Mean = 9.136e-09  StDev = 9.255e-09  Median = 6.454e-09  MAD = 4.107e-09  points = 50\n",
      "  AEM_L4  Mean = 1.259e-08  StDev = 1.811e-08  Median = 3.716e-09  MAD = 2.604e-09  points = 50\n",
      "  AEM_L5  Mean = 1.179e-08  StDev = 1.556e-08  Median = 5.164e-09  MAD = 3.532e-09  points = 50\n",
      "  AEM_L6  Mean = 1.168e-08  StDev = 1.191e-08  Median = 7.903e-09  MAD = 5.984e-09  points = 50\n",
      "  AEM_L7  Mean = 1.396e-08  StDev = 1.459e-08  Median = 8.681e-09  MAD = 7.350e-09  points = 50\n",
      "  AEM_L8  Mean = 6.847e-09  StDev = 1.207e-08  Median = 1.486e-09  MAD = 1.278e-09  points = 50\n",
      "  AEM_L9  Mean = 8.418e-09  StDev = 9.272e-09  Median = 5.455e-09  MAD = 4.417e-09  points = 50\n",
      "  AEM_M0  Mean = 0.000e+00  StDev = 0.000e+00  Median = 0.000e+00  MAD = 0.000e+00  points = 0\n",
      "  AEM_M1  Mean = 0.000e+00  StDev = 0.000e+00  Median = 0.000e+00  MAD = 0.000e+00  points = 0\n",
      "  AEM_M2  Mean = 2.193e-08  StDev = 2.887e-08  Median = 8.594e-09  MAD = 7.094e-09  points = 50\n",
      "  AEM_M3  Mean = 2.395e-08  StDev = 3.186e-08  Median = 1.085e-08  MAD = 9.434e-09  points = 50\n",
      "  AEM_M4  Mean = 2.471e-08  StDev = 2.703e-08  Median = 1.108e-08  MAD = 9.738e-09  points = 50\n",
      "  AEM_M5  Mean = 1.478e-08  StDev = 1.869e-08  Median = 8.357e-09  MAD = 6.466e-09  points = 50\n",
      "  AEM_M6  Mean = 7.976e-09  StDev = 1.168e-08  Median = 3.069e-09  MAD = 2.643e-09  points = 50\n",
      "  AEM_H0  Mean = 4.437e-08  StDev = 6.309e-08  Median = 1.114e-08  MAD = 1.070e-08  points = 50\n",
      "Loading data set 2: /home/NAS/Data_Files/CoverageResults/AEM.TIEGCM_Lifetime_2015_to_2018_JH_QD.Lifetime_10sTricubic.ValuesPerBinResults.nc\n",
      "Started Loading /home/NAS/Data_Files/CoverageResults/AEM.TIEGCM_Lifetime_2015_to_2018_JH_QD.Lifetime_10sTricubic.ValuesPerBinResults.nc 2020-08-31 09:25:52.088234\n",
      "Now Loading /home/NAS/Data_Files/CoverageResults/AEM.TIEGCM_Lifetime_2015_to_2018_JH_QD.Lifetime_10sTricubic.ValuesPerBinResults.nc\n",
      "DateOfCreation: 23-08-2020 21:40:00  LastExecDurationSec : 453 sec\n",
      "Region: AEM\n",
      "OrbitFile: /home/NAS/Data_Files/InterpolatedData/Lifetime_10sTricubic/\n",
      "TIEGCM data path: /home/NAS/TIEGCM_DATA_2/TIEGCM_Lifetime_2015_to_2018_JH_QD/ \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEM_L3 LENGTH BEFORE: 106\n",
      "AEM_L3 : huge values = 0 negative values = 0 nan values = 0\n",
      "AEM_L3 LENGTH AFTER: 106\n",
      "AEM_L4 LENGTH BEFORE: 1345\n",
      "AEM_L4 : huge values = 0 negative values = 0 nan values = 0\n",
      "AEM_L4 LENGTH AFTER: 1345\n",
      "AEM_L5 LENGTH BEFORE: 638\n",
      "AEM_L5 : huge values = 0 negative values = 0 nan values = 5\n",
      "AEM_L5 LENGTH AFTER: 633\n",
      "AEM_L6 LENGTH BEFORE: 416\n",
      "AEM_L6 : huge values = 0 negative values = 0 nan values = 6\n",
      "AEM_L6 LENGTH AFTER: 410\n",
      "AEM_L7 LENGTH BEFORE: 309\n",
      "AEM_L7 : huge values = 0 negative values = 0 nan values = 6\n",
      "AEM_L7 LENGTH AFTER: 303\n",
      "AEM_L8 LENGTH BEFORE: 354\n",
      "AEM_L8 : huge values = 0 negative values = 0 nan values = 9\n",
      "AEM_L8 LENGTH AFTER: 345\n",
      "AEM_L9 LENGTH BEFORE: 1092\n",
      "AEM_L9 : huge values = 3 negative values = 0 nan values = 14\n",
      "AEM_L9 LENGTH AFTER: 1075\n",
      "AEM_M2 LENGTH BEFORE: 651\n",
      "AEM_M2 : huge values = 0 negative values = 0 nan values = 0\n",
      "AEM_M2 LENGTH AFTER: 651\n",
      "AEM_M3 LENGTH BEFORE: 1064\n",
      "AEM_M3 : huge values = 0 negative values = 0 nan values = 0\n",
      "AEM_M3 LENGTH AFTER: 1064\n",
      "AEM_M4 LENGTH BEFORE: 439\n",
      "AEM_M4 : huge values = 0 negative values = 0 nan values = 0\n",
      "AEM_M4 LENGTH AFTER: 439\n",
      "AEM_M5 LENGTH BEFORE: 293\n",
      "AEM_M5 : huge values = 0 negative values = 0 nan values = 6\n",
      "AEM_M5 LENGTH AFTER: 287\n",
      "AEM_M6 LENGTH BEFORE: 1213\n",
      "AEM_M6 : huge values = 1 negative values = 0 nan values = 11\n",
      "AEM_M6 LENGTH AFTER: 1201\n",
      "AEM_H0 LENGTH BEFORE: 298\n",
      "AEM_H0 : huge values = 0 negative values = 0 nan values = 0\n",
      "AEM_H0 LENGTH AFTER: 298\n",
      "ALL LENGTH BEFORE: 0\n",
      "Globaly : huge values = 0 negative values = 0 nan values = 0\n",
      "ALL LENGTH AFTER: 0\n",
      "Results loaded for Joule Heating      2020-08-31 09:25:52.646846 \n",
      "\n",
      "AEM_L0 has a only 0 items\n",
      "AEM_L1 has a only 0 items\n",
      "AEM_L2 has a only 0 items\n",
      "-------- Orbit AEM_L3 --------\n",
      "[1.2934118e-10, 1.2358543e-09, 4.4775312e-08, 1.3684321e-08, 5.753379e-09, 2.258063e-08, 2.200603e-08, 4.4596957e-09, 4.080201e-08, 1.06536024e-08, 4.0559565e-09, 1.1767505e-09, 2.6552485e-09, 1.6693175e-09, 7.626236e-09, 5.2000694e-08, 1.9139936e-08, 5.476386e-09, 3.7337498e-09, 8.3316865e-09, 1.3144792e-08, 1.9534196e-09, 6.0421987e-09, 9.158028e-09, 3.4699307e-10, 3.6115222e-09, 6.800803e-09, 1.7545916e-09, 1.8004701e-09, 2.2699975e-09, 5.400846e-09, 7.45251e-09, 1.4666865e-09, 3.159227e-09, 1.3378855e-08, 3.6773137e-08, 1.3744219e-08, 1.351344e-08, 2.648565e-09, 2.918044e-09, 3.9892103e-09, 1.9303934e-09, 1.931845e-09, 3.9786907e-09, 4.9721127e-10, 1.7612496e-08, 1.2976221e-08, 4.161787e-09, 6.180335e-10, 9.59743e-09]\n",
      "-------- Orbit AEM_L4 --------\n",
      "[1.5527217e-08, 1.1031158e-09, 7.3408246e-10, 2.94898e-10, 1.872618e-08, 1.4042737e-09, 1.3552737e-07, 3.171553e-09, 2.4480457e-10, 2.0940534e-09, 8.989203e-10, 4.72451e-09, 1.1629837e-08, 1.11966845e-08, 1.8134474e-09, 1.6233136e-07, 4.2865578e-09, 3.5787378e-09, 1.6060072e-08, 3.684789e-08, 1.8101586e-08, 3.6857593e-08, 1.6545513e-09, 2.3882118e-08, 3.595979e-08, 9.1903596e-10, 4.523447e-08, 5.3094895e-10, 7.478713e-09, 2.4414823e-09, 1.7018299e-09, 5.083126e-10, 5.3506866e-09, 5.9465002e-08, 8.700032e-10, 8.6880256e-08, 1.8822874e-08, 3.9761744e-08, 1.9287418e-07, 9.397916e-10, 1.16086454e-07, 1.4339588e-10, 3.2004527e-10, 7.194908e-09, 2.2939673e-08, 9.5942205e-09, 1.7262775e-09, 3.2716926e-08, 3.6867714e-08, 1.03295985e-08]\n",
      "-------- Orbit AEM_L5 --------\n",
      "[5.748553e-08, 2.5647832e-08, 7.312599e-08, 2.233553e-09, 5.907628e-09, 3.301737e-09, 1.0567829e-09, 3.0028488e-08, 3.3563592e-09, 3.6264154e-08, 4.6896798e-09, 1.7462446e-08, 1.3897928e-08, 9.856912e-09, 2.097531e-09, 1.0792547e-09, 2.9395861e-09, 6.9181723e-09, 5.161613e-09, 5.0613014e-08, 7.3408724e-10, 1.0663822e-10, 1.27190845e-08, 1.8464136e-11, 2.096498e-10, 7.628808e-10, 4.5590456e-09, 4.8138737e-09, 7.635795e-10, 3.0994202e-10, 4.274434e-09, 9.208682e-08, 2.821141e-10, 7.878903e-09, 7.003066e-08, 1.1376127e-08, 2.9638764e-11, 1.2200241e-09, 6.440206e-08, 1.8995145e-08, 1.6638253e-08, 5.1983107e-10, 2.2022142e-09, 1.6928612e-09, 4.283055e-08, 1.5296326e-08, 1.6476813e-08, 5.0159585e-08, 1.1897566e-08, 1.2292077e-08]\n",
      "-------- Orbit AEM_L6 --------\n",
      "[3.5736267e-09, 1.7181225e-08, 1.8542435e-08, 1.6681339e-09, 1.2537408e-09, 3.9317873e-09, 2.4308733e-09, 3.325935e-10, 1.7982086e-09, 4.583746e-09, 4.6001545e-09, 2.6612648e-08, 7.604291e-11, 1.5760091e-09, 7.4027966e-09, 1.820504e-09, 8.945648e-09, 6.7601738e-09, 1.24350255e-08, 2.0397959e-08, 1.9262607e-09, 1.2748254e-09, 7.240377e-10, 1.6732402e-08, 5.5406115e-09, 5.298495e-10, 4.90812e-09, 3.6998729e-09, 2.5988601e-08, 3.4550034e-09, 9.512595e-09, 2.4444662e-09, 3.0645386e-10, 2.8007885e-09, 1.1331298e-09, 1.54742e-09, 2.7997555e-09, 6.8467516e-09, 1.4948371e-08, 4.493277e-09, 4.5478696e-09, 4.45666e-09, 7.1803496e-09, 1.5242062e-08, 1.5461918e-09, 9.754909e-10, 4.1398973e-08, 5.408413e-09, 9.171956e-11, 2.510163e-09]\n",
      "-------- Orbit AEM_L7 --------\n",
      "[1.6564652e-08, 8.682893e-11, 3.0070204e-08, 3.3058423e-09, 2.0214674e-08, 4.3234e-08, 3.4248202e-08, 5.247106e-09, 1.6903819e-08, 3.1284961e-09, 3.3966996e-09, 1.6664215e-08, 1.1383634e-08, 3.4829274e-08, 1.17488685e-08, 1.0794524e-08, 1.8053598e-08, 3.820337e-09, 3.4323022e-09, 1.9043567e-09, 5.0095252e-09, 3.4560232e-09, 2.770813e-11, 2.667035e-08, 7.720774e-09, 4.3269677e-09, 3.7401127e-10, 4.6744675e-10, 6.4908114e-09, 1.467391e-08, 1.3327964e-09, 6.874968e-11, 6.577514e-08, 1.4111085e-08, 3.3203443e-10, 1.1320912e-09, 5.561516e-08, 8.423793e-09, 1.2223847e-08, 2.497124e-09, 8.938044e-09, 1.215122e-10, 2.0344403e-10, 1.6414047e-08, 8.957117e-10, 4.9564237e-09, 3.0801455e-09, 2.2385272e-08, 7.0606307e-09, 5.9687144e-09]\n",
      "-------- Orbit AEM_L8 --------\n",
      "[5.3494484e-09, 2.6834709e-08, 5.0089017e-08, 6.7064834e-09, 5.5213393e-11, 2.4832595e-08, 2.8722955e-09, 1.7774265e-09, 1.800929e-09, 1.0939772e-09, 4.6271023e-09, 1.0963666e-09, 8.753472e-11, 6.195278e-09, 3.3606643e-08, 3.1758554e-10, 1.8060142e-10, 6.1588414e-09, 4.831739e-09, 9.052681e-10, 1.492501e-09, 5.7144944e-10, 9.572172e-09, 1.4384709e-08, 3.412333e-08, 1.013269e-09, 5.7491872e-11, 8.355397e-09, 2.1773e-08, 1.8279117e-08, 1.8208418e-09, 6.4524144e-08, 1.3652296e-09, 5.7270444e-10, 2.8839642e-09, 1.15776944e-10, 1.2345724e-09, 3.653689e-10, 6.9976713e-09, 1.4574264e-08, 5.1800106e-09, 5.0174616e-09, 4.4354145e-08, 3.1688487e-09, 1.8976603e-09, 6.812325e-10, 1.6119788e-09, 1.8303082e-09, 1.0275762e-09, 3.474817e-08]\n",
      "-------- Orbit AEM_L9 --------\n",
      "[6.664935e-10, 9.290537e-10, 1.9334687e-08, 8.61647e-11, 6.3343064e-09, 1.3481872e-08, 2.1627447e-09, 7.504002e-09, 3.9924015e-09, 4.8424496e-09, 1.1796711e-08, 1.2073183e-08, 9.2791606e-09, 5.4597127e-09, 6.2602177e-09, 3.9170445e-08, 6.7898887e-09, 1.2864462e-10, 1.7186685e-09, 7.2984174e-11, 5.2486513e-09, 6.5038575e-10, 5.795131e-09, 5.7049148e-09, 6.4193624e-09, 3.5335008e-09, 5.340809e-10, 1.0856901e-09, 2.4857388e-10, 1.9823798e-08, 2.6619817e-08, 1.7767006e-10, 8.923991e-10, 1.0681617e-10, 2.562855e-09, 2.3599922e-09, 1.7353072e-09, 5.5237287e-10, 2.554461e-10, 1.6907082e-08, 3.7011723e-09, 1.1109666e-08, 7.980718e-09, 2.3998564e-10, 4.5750777e-09, 1.4093102e-09, 2.94064e-09, 2.4769427e-09, 5.4560636e-09, 7.044264e-10]\n",
      "AEM_M0 has a only 0 items\n",
      "AEM_M1 has a only 0 items\n",
      "-------- Orbit AEM_M2 --------\n",
      "[1.4964389e-08, 6.6006143e-09, 7.0362223e-09, 5.0815414e-09, 5.9387704e-09, 1.0810105e-07, 1.6110111e-09, 4.157939e-09, 5.334025e-09, 2.4638913e-10, 1.9321275e-08, 1.0490999e-08, 2.195874e-08, 2.5294854e-08, 1.7829114e-08, 1.3761124e-08, 1.903333e-09, 8.3516266e-10, 5.170347e-09, 1.1782679e-09, 1.6804279e-07, 7.3282456e-11, 3.5809569e-09, 2.1406978e-09, 2.5016826e-08, 3.0863658e-09, 3.0192552e-08, 4.1504627e-08, 1.2476514e-07, 2.0944322e-08, 1.0173208e-08, 1.9766762e-08, 6.9298616e-09, 6.3251973e-09, 5.855247e-09, 6.6165214e-08, 1.1572329e-08, 6.6274e-09, 2.9506394e-08, 5.1992264e-09, 1.4180896e-08, 4.5900497e-09, 1.987425e-08, 1.0327064e-07, 9.0575654e-08, 3.0391003e-08, 5.055718e-10, 1.8761481e-09, 5.9755564e-08, 1.54218e-08]\n",
      "-------- Orbit AEM_M3 --------\n",
      "[3.728511e-08, 3.966611e-08, 3.3713978e-09, 1.9440108e-07, 2.3714095e-09, 4.3752717e-09, 2.6756851e-08, 5.7819555e-10, 2.7888472e-08, 7.541325e-08, 4.169485e-09, 8.5870755e-10, 3.731029e-09, 1.3777592e-09, 1.1504459e-08, 5.896552e-08, 1.6173223e-08, 1.0683894e-08, 5.7809713e-09, 6.227226e-09, 1.1359084e-08, 9.716482e-09, 5.9307332e-08, 5.6758836e-08, 8.315709e-09, 1.9320026e-09, 3.3753678e-10, 4.511849e-08, 1.0616348e-09, 4.5867523e-09, 7.162712e-08, 8.675178e-09, 1.4770806e-08, 1.3143092e-08, 2.6215703e-09, 4.487169e-09, 4.4347246e-08, 1.905261e-08, 9.068969e-09, 1.4753237e-08, 2.6099995e-08, 1.1448557e-09, 3.7710413e-10, 1.3290932e-08, 1.3848317e-10, 7.542237e-09, 7.933407e-08, 4.8070086e-09, 2.9354558e-08, 8.062944e-08]\n",
      "-------- Orbit AEM_M4 --------\n",
      "[1.8045657e-08, 5.6396946e-08, 4.081577e-08, 8.535746e-09, 9.423792e-08, 2.992003e-08, 1.4055475e-08, 1.177143e-09, 1.37254625e-08, 1.33925475e-08, 1.6773614e-08, 5.5420898e-08, 1.274789e-08, 6.9023565e-09, 1.3573498e-07, 4.14826e-08, 1.5149757e-09, 1.745542e-08, 4.725336e-08, 2.5900384e-09, 6.0977825e-08, 2.21878e-09, 1.3858353e-08, 1.4269883e-08, 6.7887056e-09, 5.4029044e-08, 8.428695e-08, 5.4400893e-09, 1.9188436e-08, 2.4287399e-08, 2.247636e-08, 1.08951056e-07, 7.574133e-10, 1.9438282e-09, 1.4640722e-09, 5.5835563e-09, 9.4158334e-09, 1.03563815e-08, 8.415987e-09, 2.5289135e-09, 1.3461945e-09, 1.9448105e-09, 6.046083e-09, 2.0291149e-09, 3.396385e-08, 4.3227914e-08, 2.4906583e-08, 6.9664874e-09, 4.4555364e-09, 3.12282e-10]\n",
      "-------- Orbit AEM_M5 --------\n",
      "[2.3649533e-09, 1.425328e-10, 1.4933331e-08, 5.3373034e-10, 7.0836412e-09, 8.377114e-09, 2.7459934e-09, 2.3589678e-08, 1.0379779e-08, 7.498709e-09, 1.0003485e-09, 7.972051e-08, 6.385513e-09, 7.1958235e-09, 3.098411e-08, 7.2623823e-09, 1.5159827e-08, 5.279815e-09, 6.969807e-09, 6.2107084e-09, 8.761518e-09, 3.0674887e-09, 5.7189946e-09, 5.3810862e-09, 3.6026837e-08, 1.4272998e-08, 4.6729185e-09, 7.299731e-08, 2.5208817e-09, 6.072374e-10, 8.604946e-10, 5.747408e-09, 8.492951e-09, 1.8506746e-08, 6.229752e-10, 1.3800591e-08, 3.0354497e-10, 5.4265787e-09, 7.999219e-09, 8.132789e-09, 2.8643292e-08, 2.0016461e-08, 1.3793321e-09, 5.4537663e-09, 5.3913447e-09, 2.0062607e-09, 1.2199846e-08, 4.1313157e-08, 4.936804e-10, 3.012016e-09]\n",
      "-------- Orbit AEM_M6 --------\n",
      "[1.7779922e-08, 2.561817e-10, 2.6498685e-09, 4.5516613e-09, 5.1372253e-09, 2.0641373e-09, 6.6759833e-09, 3.3015244e-08, 1.2377586e-09, 3.3320656e-08, 3.48777e-09, 2.201993e-09, 5.0535385e-09, 2.8748726e-09, 9.276248e-11, 2.24184e-09, 5.137922e-09, 4.9925206e-09, 2.5148651e-08, 2.6509879e-09, 2.1097972e-09, 4.68497e-10, 9.176508e-09, 4.3144603e-09, 5.6515232e-09, 1.1626117e-09, 3.4373318e-10, 1.1023884e-09, 1.6772036e-08, 2.8799374e-09, 2.1398221e-10, 1.2726328e-09, 1.6026096e-10, 5.4627805e-09, 3.8879115e-08, 3.3124894e-10, 1.6084709e-08, 1.3593583e-09, 1.6242457e-09, 3.0614994e-10, 1.870697e-10, 9.704304e-10, 1.0257363e-08, 6.8408905e-09, 4.761199e-08, 2.3418314e-09, 8.3551015e-09, 5.8326703e-09, 3.7785095e-09, 2.9497826e-09]\n",
      "-------- Orbit AEM_H0 --------\n",
      "[6.1043166e-09, 2.709268e-09, 4.1277235e-11, 1.9282236e-09, 9.381697e-09, 9.410712e-09, 2.917884e-09, 7.670067e-09, 1.7902556e-07, 3.9152432e-09, 5.3151822e-08, 3.201661e-08, 8.50644e-09, 1.4074435e-08, 7.475396e-09, 4.3966338e-08, 3.0454983e-09, 7.8009194e-08, 5.2238076e-09, 7.299084e-08, 5.979223e-08, 2.126967e-09, 1.5267632e-08, 8.9313566e-08, 1.1476082e-08, 3.8371963e-09, 1.8129096e-08, 2.0718522e-09, 1.7073884e-07, 2.3138935e-07, 1.0394903e-08, 3.587741e-08, 1.02034576e-07, 9.038244e-09, 5.8174137e-09, 3.313243e-08, 1.372127e-08, 9.0018695e-08, 8.364081e-10, 7.539988e-09, 7.537703e-08, 8.921387e-08, 7.690223e-08, 3.218569e-09, 2.7804465e-08, 9.913264e-08, 1.0076455e-08, 2.8325322e-09, 3.2816377e-08, 2.8113735e-08]\n",
      "Data reduces to a sample of 50\n",
      "ORBIT\n",
      "  AEM_L0  Mean = 0.000e+00  StDev = 0.000e+00  Median = 0.000e+00  MAD = 0.000e+00  points = 0\n",
      "  AEM_L1  Mean = 0.000e+00  StDev = 0.000e+00  Median = 0.000e+00  MAD = 0.000e+00  points = 0\n",
      "  AEM_L2  Mean = 0.000e+00  StDev = 0.000e+00  Median = 0.000e+00  MAD = 0.000e+00  points = 0\n",
      "  AEM_L3  Mean = 9.731e-09  StDev = 1.174e-08  Median = 4.930e-09  MAD = 3.331e-09  points = 50\n",
      "  AEM_L4  Mean = 2.530e-08  StDev = 4.223e-08  Median = 7.337e-09  MAD = 6.817e-09  points = 50\n",
      "  AEM_L5  Mean = 1.665e-08  StDev = 2.263e-08  Median = 5.535e-09  MAD = 5.289e-09  points = 50\n",
      "  AEM_L6  Mean = 7.076e-09  StDev = 8.603e-09  Median = 3.816e-09  MAD = 2.552e-09  points = 50\n",
      "  AEM_L7  Mean = 1.202e-08  StDev = 1.438e-08  Median = 6.230e-09  MAD = 5.641e-09  points = 50\n",
      "  AEM_L8  Mean = 9.834e-09  StDev = 1.464e-08  Median = 2.878e-09  MAD = 2.492e-09  points = 50\n",
      "  AEM_L9  Mean = 6.029e-09  StDev = 7.602e-09  Median = 3.617e-09  MAD = 2.932e-09  points = 50\n",
      "  AEM_M0  Mean = 0.000e+00  StDev = 0.000e+00  Median = 0.000e+00  MAD = 0.000e+00  points = 0\n",
      "  AEM_M1  Mean = 0.000e+00  StDev = 0.000e+00  Median = 0.000e+00  MAD = 0.000e+00  points = 0\n",
      "  AEM_M2  Mean = 2.459e-08  StDev = 3.584e-08  Median = 1.033e-08  MAD = 8.442e-09  points = 50\n",
      "  AEM_M3  Mean = 2.407e-08  StDev = 3.404e-08  Median = 1.020e-08  MAD = 8.545e-09  points = 50\n",
      "  AEM_M4  Mean = 2.467e-08  StDev = 2.996e-08  Median = 1.356e-08  MAD = 1.119e-08  points = 50\n",
      "  AEM_M5  Mean = 1.206e-08  StDev = 1.630e-08  Median = 6.678e-09  MAD = 4.235e-09  points = 50\n",
      "  AEM_M6  Mean = 7.351e-09  StDev = 1.070e-08  Median = 2.915e-09  MAD = 2.335e-09  points = 50\n",
      "  AEM_H0  Mean = 3.872e-08  StDev = 5.079e-08  Median = 1.260e-08  MAD = 1.050e-08  points = 50\n",
      "AEM_L0 WikipediaZ = NaN\n",
      "AEM_L1 WikipediaZ = NaN\n",
      "AEM_L2 WikipediaZ = NaN\n",
      "AEM_L3 WikipediaZ = 0.45432204822517863\n",
      "AEM_L4 WikipediaZ = 4.962712661135462\n",
      "AEM_L5 WikipediaZ = 2.207884068204249\n",
      "AEM_L6 WikipediaZ = -2.7367485890536747\n",
      "AEM_L7 WikipediaZ = -0.9374507768552307\n",
      "AEM_L8 WikipediaZ = 1.7502201064811227\n",
      "AEM_L9 WikipediaZ = -1.821840556961878\n",
      "AEM_M0 WikipediaZ = NaN\n",
      "AEM_M1 WikipediaZ = NaN\n",
      "AEM_M2 WikipediaZ = 0.6519760081273241\n",
      "AEM_M3 WikipediaZ = 0.02718597252738628\n",
      "AEM_M4 WikipediaZ = -0.010750616885327626\n",
      "AEM_M5 WikipediaZ = -1.030014507149361\n",
      "AEM_M6 WikipediaZ = -0.37837701443623895\n",
      "AEM_H0 WikipediaZ = -0.6331707246038426\n",
      "\n",
      "Z-test results for region AEM :\n",
      "    AEM_L3    0 <Kp< 2    115 <Alt< 120    Z of means = -0.281    Z of medians = 2.037\n",
      "    AEM_L4    0 <Kp< 2    120 <Alt< 125    Z of means = -1.956    Z of medians = -3.508\n",
      "    AEM_L5    0 <Kp< 2    125 <Alt< 130    Z of means = -1.251    Z of medians = -0.413\n",
      "    AEM_L6    0 <Kp< 2    130 <Alt< 135    Z of means = 2.218    Z of medians = 4.443\n",
      "    AEM_L7    0 <Kp< 2    135 <Alt< 140    Z of means = 0.668    Z of medians = 1.871\n",
      "    AEM_L8    0 <Kp< 2    140 <Alt< 145    Z of means = -1.113    Z of medians = -3.516\n",
      "    AEM_L9    0 <Kp< 2    145 <Alt< 150    Z of means = 1.409    Z of medians = 2.451\n",
      "    AEM_M2    2 <Kp< 4    114 <Alt< 122    Z of means = -0.409    Z of medians = -1.115\n",
      "    AEM_M3    2 <Kp< 4    122 <Alt< 129    Z of means = -0.019    Z of medians = 0.361\n",
      "    AEM_M4    2 <Kp< 4    129 <Alt< 136    Z of means = 0.007    Z of medians = -1.183\n",
      "    AEM_M5    2 <Kp< 4    136 <Alt< 143    Z of means = 0.776    Z of medians = 1.536\n",
      "    AEM_M6    2 <Kp< 4    143 <Alt< 150    Z of means = 0.279    Z of medians = 0.309\n",
      "    AEM_H0    4 <Kp< 9    100 <Alt< 150    Z of means = 0.493    Z of medians = -0.689\n",
      "\n",
      "Wilcoxon-test results for region AEM :\n",
      "    AEM_L3   0 <Kp< 2   115 <Alt< 120   Wplus = 622  Wminus = 653   W = -31  W-score = -0.14962581945442527\n",
      "    AEM_L4   0 <Kp< 2   120 <Alt< 125   Wplus = 766  Wminus = 509   W = 257  W-score = 1.240446309670558\n",
      "    AEM_L5   0 <Kp< 2   125 <Alt< 130   Wplus = 705  Wminus = 570   W = 135  W-score = 0.6515963105273359\n",
      "    AEM_L6   0 <Kp< 2   130 <Alt< 135   Wplus = 456  Wminus = 819   W = -363  W-score = -1.7520700794179476\n",
      "    AEM_L7   0 <Kp< 2   135 <Alt< 140   Wplus = 570  Wminus = 705   W = -135  W-score = -0.6515963105273359\n",
      "    AEM_L8   0 <Kp< 2   140 <Alt< 145   Wplus = 832  Wminus = 443   W = 389  W-score = 1.8775627021861752\n",
      "    AEM_L9   0 <Kp< 2   145 <Alt< 150   Wplus = 451  Wminus = 824   W = -373  W-score = -1.8003364727903428\n",
      "    AEM_M2   2 <Kp< 4   114 <Alt< 122   Wplus = 666  Wminus = 609   W = 57  W-score = 0.2751184422226529\n",
      "    AEM_M3   2 <Kp< 4   122 <Alt< 129   Wplus = 608  Wminus = 617   W = -9  W-score = -0.04476282581717944\n",
      "    AEM_M4   2 <Kp< 4   129 <Alt< 136   Wplus = 609  Wminus = 666   W = -57  W-score = -0.2751184422226529\n",
      "    AEM_M5   2 <Kp< 4   136 <Alt< 143   Wplus = 516  Wminus = 709   W = -193  W-score = -0.959913931412848\n",
      "    AEM_M6   2 <Kp< 4   143 <Alt< 150   Wplus = 621  Wminus = 654   W = -33  W-score = -0.15927909812890434\n",
      "    AEM_H0   4 <Kp< 9   100 <Alt< 150   Wplus = 612  Wminus = 663   W = -51  W-score = -0.24615860619921578\n",
      "\n",
      "scipy-ranksums-test results for region AEM :\n",
      "  AEM_L3 0 <Kp< 2 115 <Alt< 120 DataLen: 106 & 106 TestStatistic = 0.0 Pvalue = 1.0\n",
      "  AEM_L4 0 <Kp< 2 120 <Alt< 125 DataLen: 1345 & 1345 TestStatistic = 0.0 Pvalue = 1.0\n",
      "  AEM_L5 0 <Kp< 2 125 <Alt< 130 DataLen: 633 & 633 TestStatistic = 0.0 Pvalue = 1.0\n",
      "  AEM_L6 0 <Kp< 2 130 <Alt< 135 DataLen: 410 & 410 TestStatistic = 0.0 Pvalue = 1.0\n",
      "  AEM_L7 0 <Kp< 2 135 <Alt< 140 DataLen: 303 & 303 TestStatistic = 0.0 Pvalue = 1.0\n",
      "  AEM_L8 0 <Kp< 2 140 <Alt< 145 DataLen: 345 & 345 TestStatistic = 0.0 Pvalue = 1.0\n",
      "  AEM_L9 0 <Kp< 2 145 <Alt< 150 DataLen: 1075 & 1075 TestStatistic = 0.0 Pvalue = 1.0\n",
      "  AEM_M2 2 <Kp< 4 114 <Alt< 122 DataLen: 651 & 651 TestStatistic = 0.0 Pvalue = 1.0\n",
      "  AEM_M3 2 <Kp< 4 122 <Alt< 129 DataLen: 1064 & 1064 TestStatistic = 0.0 Pvalue = 1.0\n",
      "  AEM_M4 2 <Kp< 4 129 <Alt< 136 DataLen: 439 & 439 TestStatistic = 0.0 Pvalue = 1.0\n",
      "  AEM_M5 2 <Kp< 4 136 <Alt< 143 DataLen: 287 & 287 TestStatistic = 0.0 Pvalue = 1.0\n",
      "  AEM_M6 2 <Kp< 4 143 <Alt< 150 DataLen: 1201 & 1201 TestStatistic = 0.0 Pvalue = 1.0\n",
      "  AEM_H0 4 <Kp< 9 100 <Alt< 150 DataLen: 298 & 298 TestStatistic = 0.0 Pvalue = 1.0\n",
      "\n",
      "mannwhitneyu-test results for region AEM :\n",
      "  AEM_L3 0 <Kp< 2 115 <Alt< 120 DataLen: 106 & 106\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 5618.0 Pvalue = 0.9991066545568796\n",
      "     Continuity=True Alternative=less:        TestStatistic = 5618.0 Pvalue = 0.5004466727215602\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 5618.0 Pvalue = 0.5004466727215602\n",
      "     Continuity=False Alternative=two-sided:   TestStatistic = 5618.0 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 5618.0 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 5618.0 Pvalue = 0.5\n",
      "  AEM_L4 0 <Kp< 2 120 <Alt< 125 DataLen: 1345 & 1345\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 904512.5 Pvalue = 0.9999801928657305\n",
      "     Continuity=True Alternative=less:        TestStatistic = 904512.5 Pvalue = 0.5000099035671348\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 904512.5 Pvalue = 0.5000099035671348\n",
      "     Continuity=False Alternative=two-sided:   TestStatistic = 904512.5 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 904512.5 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 904512.5 Pvalue = 0.5\n",
      "  AEM_L5 0 <Kp< 2 125 <Alt< 130 DataLen: 633 & 633\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 200344.5 Pvalue = 0.999938664900038\n",
      "     Continuity=True Alternative=less:        TestStatistic = 200344.5 Pvalue = 0.5000306675499809\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 200344.5 Pvalue = 0.5000306675499809\n",
      "     Continuity=False Alternative=two-sided:   TestStatistic = 200344.5 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 200344.5 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 200344.5 Pvalue = 0.5\n",
      "  AEM_L6 0 <Kp< 2 130 <Alt< 135 DataLen: 410 & 410\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 84050.0 Pvalue = 0.9998823623823336\n",
      "     Continuity=True Alternative=less:        TestStatistic = 84050.0 Pvalue = 0.5000588188088332\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 84050.0 Pvalue = 0.5000588188088332\n",
      "     Continuity=False Alternative=two-sided:   TestStatistic = 84050.0 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 84050.0 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 84050.0 Pvalue = 0.5\n",
      "  AEM_L7 0 <Kp< 2 135 <Alt< 140 DataLen: 303 & 303\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 45904.5 Pvalue = 0.9998148748238259\n",
      "     Continuity=True Alternative=less:        TestStatistic = 45904.5 Pvalue = 0.5000925625880871\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 45904.5 Pvalue = 0.5000925625880871\n",
      "     Continuity=False Alternative=two-sided:   TestStatistic = 45904.5 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 45904.5 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 45904.5 Pvalue = 0.5\n",
      "  AEM_L8 0 <Kp< 2 140 <Alt< 145 DataLen: 345 & 345\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 59512.5 Pvalue = 0.9998476143977637\n",
      "     Continuity=True Alternative=less:        TestStatistic = 59512.5 Pvalue = 0.5000761928011181\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 59512.5 Pvalue = 0.5000761928011181\n",
      "     Continuity=False Alternative=two-sided:   TestStatistic = 59512.5 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 59512.5 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 59512.5 Pvalue = 0.5\n",
      "  AEM_L9 0 <Kp< 2 145 <Alt< 150 DataLen: 1075 & 1075\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 577812.5 Pvalue = 0.9999722813445416\n",
      "     Continuity=True Alternative=less:        TestStatistic = 577812.5 Pvalue = 0.5000138593277291\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 577812.5 Pvalue = 0.5000138593277291\n",
      "     Continuity=False Alternative=two-sided:   TestStatistic = 577812.5 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 577812.5 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 577812.5 Pvalue = 0.5\n",
      "  AEM_M2 2 <Kp< 4 114 <Alt< 122 DataLen: 651 & 651\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 211900.5 Pvalue = 0.9999411904472862\n",
      "     Continuity=True Alternative=less:        TestStatistic = 211900.5 Pvalue = 0.5000294047763569\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 211900.5 Pvalue = 0.5000294047763569\n",
      "     Continuity=False Alternative=two-sided:   TestStatistic = 211900.5 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 211900.5 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 211900.5 Pvalue = 0.5\n",
      "  AEM_M3 2 <Kp< 4 122 <Alt< 129 DataLen: 1064 & 1064\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 566048.0 Pvalue = 0.9999718504553575\n",
      "     Continuity=True Alternative=less:        TestStatistic = 566048.0 Pvalue = 0.5000140747723212\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 566048.0 Pvalue = 0.5000140747723212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Continuity=False Alternative=two-sided:   TestStatistic = 566048.0 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 566048.0 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 566048.0 Pvalue = 0.5\n",
      "  AEM_M4 2 <Kp< 4 129 <Alt< 136 DataLen: 439 & 439\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 96360.5 Pvalue = 0.9998938200357346\n",
      "     Continuity=True Alternative=less:        TestStatistic = 96360.5 Pvalue = 0.5000530899821327\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 96360.5 Pvalue = 0.5000530899821327\n",
      "     Continuity=False Alternative=two-sided:   TestStatistic = 96360.5 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 96360.5 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 96360.5 Pvalue = 0.5\n",
      "  AEM_M5 2 <Kp< 4 136 <Alt< 143 DataLen: 287 & 287\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 41184.5 Pvalue = 0.9997991893035331\n",
      "     Continuity=True Alternative=less:        TestStatistic = 41184.5 Pvalue = 0.5001004053482334\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 41184.5 Pvalue = 0.5001004053482334\n",
      "     Continuity=False Alternative=two-sided:   TestStatistic = 41184.5 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 41184.5 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 41184.5 Pvalue = 0.5\n",
      "  AEM_M6 2 <Kp< 4 143 <Alt< 150 DataLen: 1201 & 1201\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 721200.5 Pvalue = 0.9999765263346461\n",
      "     Continuity=True Alternative=less:        TestStatistic = 721200.5 Pvalue = 0.500011736832677\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 721200.5 Pvalue = 0.500011736832677\n",
      "     Continuity=False Alternative=two-sided:   TestStatistic = 721200.5 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 721200.5 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 721200.5 Pvalue = 0.5\n",
      "  AEM_H0 4 <Kp< 9 100 <Alt< 150 DataLen: 298 & 298\n",
      "     Continuity=True Alternative=two-sided:   TestStatistic = 44402.0 Pvalue = 0.9998101987409277\n",
      "     Continuity=True Alternative=less:        TestStatistic = 44402.0 Pvalue = 0.5000949006295362\n",
      "     Continuity=True Alternative=greater:     TestStatistic = 44402.0 Pvalue = 0.5000949006295362\n",
      "     Continuity=False Alternative=two-sided:   TestStatistic = 44402.0 Pvalue = 1.0\n",
      "     Continuity=False Alternative=less:        TestStatistic = 44402.0 Pvalue = 0.5\n",
      "     Continuity=False Alternative=greater:     TestStatistic = 44402.0 Pvalue = 0.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../SourceCode/')\n",
    "import DaedalusGlobals as DaedalusGlobals\n",
    "import Conversions as Conversions\n",
    "\n",
    "import os\n",
    "from os import path\n",
    "import statistics\n",
    "import random \n",
    "import copy\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import ranksums\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import calendar\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import ipywidgets as w\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset \n",
    "from numba import cuda\n",
    "import threading\n",
    "\n",
    "import plotly\n",
    "import chart_studio.plotly as py \n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import matplotlib.cm\n",
    "import matplotlib.pyplot as matplt\n",
    "\n",
    "\n",
    "# colors used at plotting\n",
    "MyColors = [\"#217ca3\", \"#e29930\", \"#919636\", \"#af1c1c\", \"#e7552c\", \"#1b4b5a\", \"#e4535e\", \"#aebd38\", \"#ffbb00\", \"#2c7873\"]\n",
    "def Hex_to_RGB(  HexColor ): # \"#e29930\" -->\n",
    "    RGB = tuple(int(HexColor.lstrip('#')[i:i+2], 16) for i in (0, 2, 4))\n",
    "    return str(RGB).strip('(').strip(')').strip()\n",
    "\n",
    "# GUI elements with global scope\n",
    "style1 = {'description_width':'170px'}\n",
    "layout1 = {'width':'780px'}\n",
    "style2 = {'description_width':'95px'}\n",
    "layout2 = {'width':'160px'}\n",
    "OrbitPreviewImage = w.Image( format='png', visible=False )\n",
    "OrbitPreviewImage.layout.visibility = 'hidden'\n",
    "ExecutionTitle_Text = w.Text(value=\"\", description='Execution title:', style=style1, layout=layout1)\n",
    "ExecutionDescr_Text = w.Text(value=\"\", description='Execution description:', style=style1, layout=layout1)\n",
    "Warning_HTML = w.HTML( value =\"\", color=\"Red\", visible=False )\n",
    "tiegcmFolder_Dropdown    = w.Dropdown( options=[\"/home/NAS/TIEGCM_DATA_2/TIEGCM_Lifetime_2015_to_2018_JH_QD/\"], description='TIEGCM files: ', style=style1, layout=layout1)\n",
    "BinGroups_Dropdown       = w.Dropdown( options=[\"AEM\", \"AFM\", \"AEE\", \"AED\", \"EEJ\", \"EPB\", \"SQ\", \"CF\", \"PCF\"], description='Area of study: ', style=style1, layout=layout1)\n",
    "#OrbitFilename_Dropdown  = w.Dropdown( options=sorted(glob.glob(DaedalusGlobals.Orbit_Files_Path + \"DAED_ORB_Lifetime*.csv\")), description='Along orbit filename: ', style=style1, layout=layout1)\n",
    "OrbitFilesPath_Dropdown  = w.Dropdown( options=list(), description='Orbit Files Path: ', style=style1, layout=layout1)\n",
    "SavedFilenames_Dropdown  = w.Dropdown( options=list(),  description='', style=style1, layout=layout1)\n",
    "SavedFilenames2_Dropdown = w.Dropdown( options=sorted(glob.glob(DaedalusGlobals.CoverageResults_Files_Path + \"*.ValuesPerBinResults.nc\")),  description='', style=style1, layout=layout1)\n",
    "Variable_DropDown         = w.Dropdown( options=[\"Joule Heating\", \"Electric Field North\", \"Electric Field East\", \"Pedersen Conductivity\", \"Hall Conductivity\", \"Convection Heating\", \"Wind Correction\", \"JH/mass\", \"JH/pressure\" ],  description='Variable', style=style1, layout=layout1)\n",
    "Plot_JHvsMagLat_Checkbox       = w.Checkbox(value=True, description=\"Plot variable vs Magnetic Latitude\", style=style1, layout=layout1 )\n",
    "Plot_JHvsMLT_Checkbox          = w.Checkbox(value=True, description=\"Plot variable vs Magnetic Local Time\", style=style1, layout=layout1 )\n",
    "Plot_JHvsAltitude_Checkbox     = w.Checkbox(value=True, description=\"Plot variable vs Altitude\", style=style1, layout=layout1 )\n",
    "Plot_AltitudeVsMagLat_Checkbox = w.Checkbox(value=True, description=\"Plot Altitude vs Magnetic Latitude\", style=style1, layout=layout1 )\n",
    "Plot_JHdistribution_Checkbox   = w.Checkbox(value=True, description=\"Plot distribution per bin\", style=style1, layout=layout1 )\n",
    "Plot_AltProfilesCanonical_Checkbox = w.Checkbox(value=True, description=\"Plot Altitude profiles (canonical binning)\", style=style1, layout=layout1 )\n",
    "Plot_AltProfilesNatural_Checkbox   = w.Checkbox(value=True, description=\"Plot Altitude profiles (natural binning)\", style=style1, layout=layout1 )\n",
    "Plot_HeightIntegrated_Checkbox = w.Checkbox(value=True, description=\"Plot height-integated distribution (result filename just denotes the region)\", style=style1, layout=layout1 )\n",
    "Plot_ColorSpreads_Checkbox     = w.Checkbox(value=True, description=\"Plot color-spread plots\", style=style1, layout=layout1 )\n",
    "Plot_PDFperSubBin_Checkbox     = w.Checkbox(value=True, description=\"Plot Probability Density per sub-bin\", style=style1, layout=layout1 )\n",
    "Test_statistical_Checkbox   = w.Checkbox(value=True, description=\"Execute statistical test for the 2 data sets, tiegcm & orbit\", style=style1, layout=layout1 )\n",
    "RegressionOptions_Dropdown  = w.Dropdown( options=[\"None\", \"Polynomial - degree 1\", \"Polynomial - degree 2\", \"Polynomial - degree 3\", \"Polynomial - degree 4\", \"Polynomial - degree 5\", \"Polynomial - degree 6\", \"Power law\", \"Logarithmic\", \"Euler\", \"Maxwell\"], value=\"Euler\", description='Regression Analysis', style=style1, layout=layout1)\n",
    "\n",
    "# set options for the saved result files\n",
    "L = glob.glob(DaedalusGlobals.CoverageResults_Files_Path + \"*.ValuesPerBinResults.nc\")\n",
    "L += glob.glob(DaedalusGlobals.CoverageResults_Files_Path + \"*MultiFileResults/\")\n",
    "L += [\"/home/balukid/old_onlyOhmic.TRO.TIEGCM_Lifetime_2015_to_2018_JH_QD.MultiFileResults/\"]\n",
    "L = sorted(L)\n",
    "SavedFilenames_Dropdown.options = L\n",
    "SavedFilenamesDuplicate_Dropdown = w.Dropdown( options=L,  description='Orbit results', style=style1, layout=layout1)\n",
    "\n",
    "# set options for orbit locations\n",
    "L = list()\n",
    "L.append( \"/home/NAS/Data_Files/InterpolatedData/TIEGCM_Lifetime_2015_to_2018_CAMP03/1HzIntepolatedDATA/\" )\n",
    "L.append( \"/home/NAS/Data_Files/InterpolatedData/TIEGCM_Lifetime_2015_to_2018_CAMP02_115km/\" )\n",
    "L.append( \"/home/NAS/Data_Files/InterpolatedData/Lifetime_10sTricubic/\" )\n",
    "L.append( \"/home/NAS/Data_Files/InterpolatedData/Lifetime_10sTricubic_2sats/\" )\n",
    "OrbitFilesPath_Dropdown.options = L\n",
    "\n",
    "\n",
    "# Properties of the current calculation\n",
    "CALCULATIONS_Title = \"\"\n",
    "CALCULATIONS_Description =\"\"\n",
    "CALCULATIONS_RegionName = \"\"\n",
    "CALCULATIONS_OrbitFilesPath = \"\"\n",
    "CALCULATIONS_ResultsFilename = \"\"\n",
    "CALCULATIONS_TIEGCMfolder = \"\"\n",
    "CALCULATIONS_ExecutionDuration = 0\n",
    "SELECTED_VARIABLE           = \"\"\n",
    "SELECTED_VARIABLE_longname  = \"\"\n",
    "SELECTED_VARIABLE_shortname = \"\"\n",
    "SELECTED_VARIABLE_units     = \"\"\n",
    "# The following lists store data about each hit\n",
    "all_JH_values       = list()\n",
    "all_MagLat_values   = list()\n",
    "all_MLT_values      = list()\n",
    "all_Altitude_values = list()\n",
    "all_Lat_values      = list()\n",
    "all_Kp_values       = list() \n",
    "all_Time_values     = list()\n",
    "all_HittedBin_IDs   = list()\n",
    "all_EEX_values      = list()\n",
    "all_EEY_values      = list()\n",
    "all_Pedersen_values = list()\n",
    "all_Density_values  = list()\n",
    "all_Lev_values      = list()\n",
    "all_Hall_values     = list()\n",
    "all_ConvectionHeating_values = list()\n",
    "all_WindHeating_values = list()\n",
    "\n",
    "# utility: converts a number to its 2-digit string representation\n",
    "def num_to_2digit_str( n ):\n",
    "    s = str(n)\n",
    "    if len(s) == 1:\n",
    "        s = '0' + s\n",
    "    return s\n",
    "\n",
    "# utility: takes a string containing numbers and places spaces instead of the leading zeros \n",
    "def ConvertLeadingZerosToSpaces( str ):\n",
    "    result = \"\"\n",
    "    leading_zone = True\n",
    "    for c in str:\n",
    "        if leading_zone:\n",
    "            if c == '0':\n",
    "                result = result + ' '\n",
    "            else:\n",
    "                result = result + c\n",
    "                leading_zone = False\n",
    "        else:\n",
    "            result = result + c\n",
    "    if result.strip().startswith('.')  and  result.startswith(' '): result = result[:result.rfind(' ')] + '0' + result.strip()\n",
    "    if result.strip() == \"\": result = result[ :-1 ] + '0'\n",
    "    if (result.startswith('.')) : result = '0' + result            \n",
    "    return result\n",
    "\n",
    "# Parses a string representing a date and returns a corresponding datetime object. Example: Jan 01 2015 00:01:10.000000000\n",
    "def parseDaedalusDate( dateString ):\n",
    "    result = None\n",
    "    try:\n",
    "        result = datetime.strptime(dateString[0:24], '%b %d %Y %H:%M:%S.%f')\n",
    "    except:\n",
    "        try:\n",
    "            result = datetime.strptime(dateString, '%b %d %Y %H:%M:%S.%f')\n",
    "        except:\n",
    "            try:\n",
    "                result = datetime.strptime(dateString, '%d %b %Y %H:%M:%S.%f')\n",
    "            except:\n",
    "                result = None\n",
    "    return result\n",
    "        \n",
    "\n",
    "# utility: returns a color of a colormap as list of r,g,b,a values representing a value inside a range\n",
    "def getColor( Value, minValue, maxValue, ColormapName ):\n",
    "    cmap = matplotlib.cm.get_cmap( ColormapName )\n",
    "    norm = matplotlib.colors.Normalize(vmin=minValue, vmax=maxValue)\n",
    "    rgba = cmap( norm(Value) )\n",
    "    s = \"rgba\" + str(rgba) \n",
    "    return s\n",
    "\n",
    "# Define a class which can describe a bin\n",
    "class Bin:\n",
    "    ID             = \"\"\n",
    "    Description    = \"\"\n",
    "    MLT_min        = 0 # Magnetic Local Time (hour & min of the 24-hour day) (string)\n",
    "    MLT_max        = 0 # Magnetic Local Time (hour & min of the 24-hour day) (string)\n",
    "    MagLat_min     = 0 # Magnetic Latitude (degrees)\n",
    "    MagLat_max     = 0 # Magnetic Latitude (degrees)\n",
    "    Altitude_min   = 0 # Satellite's Altitude measured from Earth's surface (km)\n",
    "    Altitude_max   = 0 # Satellite's Altitude measured from Earth's surface (km)\n",
    "    Kp_min         = 0 #\n",
    "    Kp_max         = 0 #\n",
    "    Lat_min        = 0\n",
    "    Lat_max        = 0\n",
    "    NumOfBins      = 0 # How many parts will the Altitude range be splitted in\n",
    "    CumulativeTime = 0 # (sec)\n",
    "    DesirableCumulativeTime = 0 # (sec)\n",
    "    JH_min      = 99999 # the minimum JH value inside the bin\n",
    "    JH_max      = 0     # the maximum JH value inside the bin\n",
    "    JH_mean     = 0     # the mean JH value inside the bin\n",
    "    JH_median   = 0     # the median JH value inside the bin (=50th percentile)\n",
    "    JH_variance = 0     # the variance of JH value inside the bin (variance = (1/(N-1)) * Sum{1->N}(X-MeanVariance)^2  )\n",
    "    JH_medianVariance = 0\n",
    "    JH_medianAbsDev = 0\n",
    "    # Data:\n",
    "    JH_values         = list() # here will be stored all Joule Heating values in order to calculate the variance at the end\n",
    "    JH_distribution   = list() # the item 0 holds the number of points which have 0<JH<JH_max/100 etc\n",
    "    MagLat_values     = list() #  these values correspond to the JH_values\n",
    "    MLT_values        = list() #  these values correspond to the JH_values\n",
    "    Altitude_values   = list() #  these values correspond to the JH_values\n",
    "    Kp_values         = list() #  these values correspond to the JH_values\n",
    "    Time_values       = list() #  these values correspond to the JH_values\n",
    "    EEX_values        = list()\n",
    "    EEY_values        = list()\n",
    "    Pedersen_values   = list()\n",
    "    Density_values    = list()\n",
    "    Lev_values        = list()\n",
    "    Hall_values       = list()\n",
    "    ConvectionHeating_values = list()\n",
    "    WindHeating_values = list()\n",
    "    \n",
    "    def __init__(self, ID, Description, MLT_min, MLT_max, MagLat_min, MagLat_max, Altitude_min, Altitude_max, Lat_min, Lat_max, Kp_min, Kp_max, DesirableCumulativeTime):\n",
    "        self.ID             = ID\n",
    "        self.Description    = Description\n",
    "        self.MLT_min        = MLT_min \n",
    "        self.MLT_max        = MLT_max\n",
    "        self.MagLat_min     = MagLat_min\n",
    "        self.MagLat_max     = MagLat_max\n",
    "        self.Altitude_min   = Altitude_min\n",
    "        self.Altitude_max   = Altitude_max\n",
    "        self.Lat_min        = Lat_min\n",
    "        self.Lat_max        = Lat_max                \n",
    "        self.Kp_min         = Kp_min\n",
    "        self.Kp_max         = Kp_max\n",
    "        self.DesirableCumulativeTime = DesirableCumulativeTime\n",
    "        self.JH_values       = list()\n",
    "        self.JH_distribution = [0] * 100\n",
    "        self.MagLat_values   = list()\n",
    "        self.MLT_values      = list()\n",
    "        self.Altitude_values = list()\n",
    "        self.Lat_values       = list()\n",
    "        self.Kp_values       = list()\n",
    "        self.Time_values     = list()\n",
    "        self.EEX_values        = list()\n",
    "        self.EEY_values        = list()\n",
    "        self.Pedersen_values   = list()\n",
    "        self.Density_values    = list()\n",
    "        self.Lev_values        = list()\n",
    "        self.Hall_values       = list()\n",
    "        self.ConvectionHeating_values = list()\n",
    "        self.WindHeating_values = list()\n",
    "\n",
    "    def reset(self):\n",
    "        self.JH_min      = 99999\n",
    "        self.JH_mean     = 0\n",
    "        self.JH_median   = 0\n",
    "        self.JH_variance = 0\n",
    "        self.JH_medianVariance = 0\n",
    "        self.JH_medianAbsDev = 0\n",
    "        self.JH_values       = list()\n",
    "        self.MagLat_values   = list()\n",
    "        self.MLT_values      = list()\n",
    "        self.Altitude_values = list()\n",
    "        self.Lat_values       = list()\n",
    "        self.Kp_values       = list()\n",
    "        self.Time_values     = list()\n",
    "        self.EEX_values        = list()\n",
    "        self.EEY_values        = list()\n",
    "        self.Pedersen_values   = list()\n",
    "        self.Density_values    = list()\n",
    "        self.Lev_values        = list()\n",
    "        self.Hall_values       = list()        \n",
    "        self.ConvectionHeating_values = list()\n",
    "        self.WindHeating_values = list()\n",
    "        \n",
    "    def getInfo(self):\n",
    "        s  = self.ID.ljust(8, ' ') + \": \"\n",
    "        s += \"{:02.0f}\".format(self.MLT_min)      + \"<MLT<=\"    + \"{:02.0f}\".format(self.MLT_max)      + \" \"\n",
    "        s += \"{:03.0f}\".format(self.MagLat_min)   + \"<MagLat<=\" + \"{:03.0f}\".format(self.MagLat_max)   + \" \"\n",
    "        s += \"{:03.0f}\".format(self.Altitude_min) + \"<Alt<=\"    + \"{:03.0f}\".format(self.Altitude_max) + \" \"\n",
    "        s += str(self.Kp_min)             + \"<Kp<=\"     + str(self.Kp_max)       + \" \"\n",
    "        if self.JH_min == 99999:\n",
    "            s += \" JHmin=\" + \"         \"\n",
    "        else:\n",
    "            s += \" JHmin=\" + \"{:.3e}\".format(self.JH_min) #ConvertLeadingZerosToSpaces( \"{:09.3f}\".format(self.JH_min) )\n",
    "        s += \" JHmean=\" + \"{:.3e}\".format(self.JH_mean) #ConvertLeadingZerosToSpaces( \"{:09.3f}\".format(self.JH_mean) )\n",
    "        s += \" JHvariance=\" + \"{:.3e}\".format(self.JH_variance) #ConvertLeadingZerosToSpaces( \"{:09.3f}\".format(self.JH_variance) )\n",
    "        ##\n",
    "        str_JH = \"\"\n",
    "        for i in range(0, len(self.JH_values) ):            \n",
    "            str_JH += str( self.JH_values[i] )\n",
    "            if i < len(self.JH_values)-1: str_JH += ','\n",
    "        s += \" JH_values=\" + str_JH # ''.join(str(e) for e in self.JH_values)\n",
    "        ##\n",
    "        return s\n",
    "    \n",
    "    def printMe(self):\n",
    "        print( self.getInfo()[:220] )\n",
    "\n",
    "\n",
    "Bins = list() # this list holds the definitions of all bins\n",
    "def InitializeBins():\n",
    "    global Bins\n",
    "    Bins = list()\n",
    "    #                ID        Description                          MLT      MagLat    Altitude                Lat      Kp       DesiredTime(sec)\n",
    "    Bins.append( Bin(\"AEM_L0\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   100, 105,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEM_L1\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   105, 110,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEM_L2\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   110, 115,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEM_L3\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   115, 120,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEM_L4\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   120, 125,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEM_L5\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   125, 130,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEM_L6\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   130, 135,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEM_L7\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   135, 140,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEM_L8\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   140, 145,               -90,90,  0, 2,   50*60 ) )    \n",
    "    Bins.append( Bin(\"AEM_L9\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   145, 150,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEM_M0\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   100, 107,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AEM_M1\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   107, 114,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AEM_M2\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   114, 122,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AEM_M3\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   122, 129,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AEM_M4\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   129, 136,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AEM_M5\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   136, 143,               -90,90,  2, 4,   30*60 ) )    \n",
    "    Bins.append( Bin(\"AEM_M6\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   143, 150,               -90,90,  2, 4,   30*60 ) )    \n",
    "    Bins.append( Bin(\"AEM_H0\", \"Auroral E region, midnight sector\", 21, 3,   60, 75,   100, 150,               -90,90,  4, 9,   20*60 ) )\n",
    "\n",
    "    Bins.append( Bin(\"AAA_L1\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   100, 105,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AAA_L2\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   105, 110,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AAA_L3\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   110, 115,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AAA_L4\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   115, 120,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AAA_L5\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   120, 125,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AAA_L6\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   125, 130,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AAA_L7\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   130, 135,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AAA_L8\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   135, 140,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AAA_L9\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   140, 145,               -90,90,  0, 2,   50*60 ) )    \n",
    "    Bins.append( Bin(\"AAA_La\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   145, 150,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AAA_Lb\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   150, 155,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AAA_Lc\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   155, 160,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AAA_M1\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   100, 110,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AAA_M2\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   110, 120,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AAA_M3\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   120, 130,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AAA_M4\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   130, 140,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AAA_M5\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   140, 150,               -90,90,  2, 4,   30*60 ) )    \n",
    "    Bins.append( Bin(\"AAA_M6\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   150, 160,               -90,90,  2, 4,   30*60 ) )    \n",
    "    Bins.append( Bin(\"AAA_H1\", \"Auroral E region, midnight sector\", 12, 12,   50, 85,   100, 160,               -90,90,  4, 9,   20*60 ) )\n",
    "    \n",
    "    Bins.append( Bin(\"AFM_L1\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   150, 185,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AFM_L2\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   185, 220,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AFM_L3\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   220, 255,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AFM_L4\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   255, 290,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AFM_L5\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   290, 325,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AFM_L6\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   325, 360,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AFM_L7\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   360, 395,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AFM_L8\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   395, 430,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AFM_L9\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   430, 465,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AFM_L10\",\"Auroral F region, midnight sector\", 21, 3,   60, 75,   465, 500,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AFM_M1\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   150.0, 237.5,           -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AFM_M2\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   237.5, 325.0,           -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AFM_M3\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   325.0, 412.5,           -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AFM_M4\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   412.5, 500.0,           -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AFM_H1\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   150, 265,               -90,90,  4, 9,   20*60 ) )\n",
    "    Bins.append( Bin(\"AFM_H2\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   265, 380,               -90,90,  4, 9,   20*60 ) )\n",
    "    Bins.append( Bin(\"AFM_H3\", \"Auroral F region, midnight sector\", 21, 3,   60, 75,   380, 500,               -90,90,  4, 9,   20*60 ) )\n",
    "    \n",
    "    Bins.append( Bin(\"AEE_L1\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   115, 120,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEE_L2\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   120, 125,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEE_L3\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   125, 130,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEE_L4\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   130, 135,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEE_L5\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   135, 140,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEE_L6\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   140, 145,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEE_L7\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   145, 150,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AEE_M1\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   115, 122,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AEE_M2\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   122, 129,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AEE_M3\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   129, 136,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AEE_M4\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   136, 143,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AEE_M5\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   143, 150,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AEE_H1\", \"Auroral E region, evening sector\",  15, 21,  60, 75,   115, 150,               -90,90,  4, 9,   20*60 ) )\n",
    "\n",
    "    Bins.append( Bin(\"AED_L1\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   115, 120,                 -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AED_L2\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   120, 125,                 -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AED_L3\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   125, 130,                 -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AED_L4\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   130, 135,                 -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AED_L5\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   135, 140,                 -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AED_L6\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   140, 145,                 -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AED_L7\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   145, 150,                 -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"AED_M1\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   115, 122,                 -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AED_M2\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   122, 129,                 -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AED_M3\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   129, 136,                 -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AED_M4\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   136, 143,                 -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AED_M5\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   143, 150,                 -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"AED_H1\", \"Auroral E region, dawn sector\",     3, 9,   60, 75,   115, 150,                 -90,90,  4, 9,   20*60 ) )\n",
    "    \n",
    "    Bins.append( Bin(\"EEJ_A1\", \"Equatorial E-region\",             10, 13,  -7,  7,   115,   127,                -90,90,  0, 9,   10*60 ) )\n",
    "    Bins.append( Bin(\"EEJ_A2\", \"Equatorial E-region\",             10, 13,  -7,  7,   127,   139,                -90,90,  0, 9,   10*60 ) )\n",
    "    Bins.append( Bin(\"EEJ_A3\", \"Equatorial E-region\",             10, 13,  -7,  7,   139,   150,                -90,90,  0, 9,   10*60 ) )\n",
    "\n",
    "    Bins.append( Bin(\"EPB_A1\", \"Equatorial Plasma Bubbles\",       18,  4, -30, 30,   150, 185,                  -90,90,  0, 9,   150*60 ) )\n",
    "    Bins.append( Bin(\"EPB_A2\", \"Equatorial Plasma Bubbles\",       18,  4, -30, 30,   185, 220,                  -90,90,  0, 9,   150*60 ) )\n",
    "    Bins.append( Bin(\"EPB_A3\", \"Equatorial Plasma Bubbles\",       18,  4, -30, 30,   220, 255,                  -90,90,  0, 9,   150*60 ) )\n",
    "    Bins.append( Bin(\"EPB_A4\", \"Equatorial Plasma Bubbles\",       18,  4, -30, 30,   255, 290,                  -90,90,  0, 9,   150*60 ) )\n",
    "    Bins.append( Bin(\"EPB_A5\", \"Equatorial Plasma Bubbles\",       18,  4, -30, 30,   290, 325,                  -90,90,  0, 9,   150*60 ) )\n",
    "    Bins.append( Bin(\"EPB_A6\", \"Equatorial Plasma Bubbles\",       18,  4, -30, 30,   325, 360,                  -90,90,  0, 9,   150*60 ) )\n",
    "    Bins.append( Bin(\"EPB_A7\", \"Equatorial Plasma Bubbles\",       18,  4, -30, 30,   360, 395,                  -90,90,  0, 9,   150*60 ) )\n",
    "    Bins.append( Bin(\"EPB_A8\", \"Equatorial Plasma Bubbles\",       18,  4, -30, 30,   395, 430,                  -90,90,  0, 9,   150*60 ) )\n",
    "    Bins.append( Bin(\"EPB_A9\", \"Equatorial Plasma Bubbles\",       18,  4, -30, 30,   430, 465,                  -90,90,  0, 9,   150*60 ) )\n",
    "    Bins.append( Bin(\"EPB_A10\",\"Equatorial Plasma Bubbles\",       18,  4, -30, 30,   465, 500,                  -90,90,  0, 9,   150*60 ) )\n",
    "\n",
    "    Bins.append( Bin(\"SQ_A1\",  \"Sq & midlat F region currents\",    6, 19, -60, 60,   150, 185,                  -90,90,  0, 3,   150*60 ) )\n",
    "    Bins.append( Bin(\"SQ_A2\",  \"Sq & midlat F region currents\",    6, 19, -60, 60,   185, 220,                  -90,90,  0, 3,   150*60 ) )\n",
    "    Bins.append( Bin(\"SQ_A3\",  \"Sq & midlat F region currents\",    6, 19, -60, 60,   220, 255,                  -90,90,  0, 3,   150*60 ) )\n",
    "    Bins.append( Bin(\"SQ_A4\",  \"Sq & midlat F region currents\",    6, 19, -60, 60,   255, 290,                  -90,90,  0, 3,   150*60 ) )\n",
    "    Bins.append( Bin(\"SQ_A5\",  \"Sq & midlat F region currents\",    6, 19, -60, 60,   290, 325,                  -90,90,  0, 3,   150*60 ) )\n",
    "    Bins.append( Bin(\"SQ_A6\",  \"Sq & midlat F region currents\",    6, 19, -60, 60,   325, 360,                  -90,90,  0, 3,   150*60 ) )\n",
    "    Bins.append( Bin(\"SQ_A7\",  \"Sq & midlat F region currents\",    6, 19, -60, 60,   360, 395,                  -90,90,  0, 3,   150*60 ) )\n",
    "    Bins.append( Bin(\"SQ_A8\",  \"Sq & midlat F region currents\",    6, 19, -60, 60,   395, 430,                  -90,90,  0, 3,   150*60 ) )\n",
    "    Bins.append( Bin(\"SQ_A9\",  \"Sq & midlat F region currents\",    6, 19, -60, 60,   430, 465,                  -90,90,  0, 3,   150*60 ) )\n",
    "    Bins.append( Bin(\"SQ_A10\", \"Sq & midlat F region currents\",    6, 19, -60, 60,   465, 500,                  -90,90,  0, 3,   150*60 ) )\n",
    "    \n",
    "    Bins.append( Bin(\"CF_L1\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   140, 185,                -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"CF_L2\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   185, 230,                -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"CF_L3\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   230, 275,                -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"CF_L4\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   275, 320,                -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"CF_L5\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   320, 365,                -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"CF_L6\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   365, 410,                -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"CF_L7\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   410, 455,                -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"CF_L8\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   455, 500,                -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"CF_M1\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   140, 230,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"CF_M2\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   230, 320,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"CF_M3\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   320, 410,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"CF_M4\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   410, 500,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"CF_H1\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   140, 260,               -90,90,  4, 9,   20*60 ) )\n",
    "    Bins.append( Bin(\"CF_H2\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   260, 380,               -90,90,  4, 9,   20*60 ) )\n",
    "    Bins.append( Bin(\"CF_H3\", \"Dayside Cusp F-region\",            10, 14,   70,  80,   380, 500,               -90,90,  4, 9,   20*60 ) )\n",
    "    \n",
    "    Bins.append( Bin(\"PCF_L1\", \"Polar cap F-region\",              14, 10,   70,  90,   140, 185,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"PCF_L2\", \"Polar cap F-region\",              14, 10,   70,  90,   185, 230,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"PCF_L3\", \"Polar cap F-region\",              14, 10,   70,  90,   230, 275,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"PCF_L4\", \"Polar cap F-region\",              14, 10,   70,  90,   275, 320,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"PCF_L5\", \"Polar cap F-region\",              14, 10,   70,  90,   320, 365,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"PCF_L6\", \"Polar cap F-region\",              14, 10,   70,  90,   365, 410,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"PCF_L7\", \"Polar cap F-region\",              14, 10,   70,  90,   410, 455,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"PCF_L8\", \"Polar cap F-region\",              14, 10,   70,  90,   455, 500,               -90,90,  0, 2,   50*60 ) )\n",
    "    Bins.append( Bin(\"PCF_M1\", \"Polar cap F-region\",              14, 10,   70,  90,   140, 230,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"PCF_M2\", \"Polar cap F-region\",              14, 10,   70,  90,   230, 320,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"PCF_M3\", \"Polar cap F-region\",              14, 10,   70,  90,   320, 410,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"PCF_M4\", \"Polar cap F-region\",              14, 10,   70,  90,   410, 500,               -90,90,  2, 4,   30*60 ) )\n",
    "    Bins.append( Bin(\"PCF_H1\", \"Polar cap F-region\",              14, 10,   70,  90,   140, 260,               -90,90,  4, 9,   20*60 ) )\n",
    "    Bins.append( Bin(\"PCF_H2\", \"Polar cap F-region\",              14, 10,   70,  90,   260, 380,               -90,90,  4, 9,   20*60 ) )\n",
    "    Bins.append( Bin(\"PCF_H3\", \"Polar cap F-region\",              14, 10,   70,  90,   380, 500,               -90,90,  4, 9,   20*60 ) )\n",
    "    \n",
    "    Bins.append( Bin(\"TRO_01\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,   80,  85,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_02\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,   85,  90,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_03\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,   90,  95,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_04\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,   95, 100,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_05\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  100, 105,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_06\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  105, 110,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_07\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  110, 115,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_08\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  115, 120,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_09\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  120, 125,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_10\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  125, 130,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_11\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  130, 135,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_12\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  135, 140,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_13\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  140, 145,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_14\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  145, 150,                 60,90,  0, 2,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_15\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,   80,  87,                 60,90,  2, 4,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_16\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,   87,  94,                 60,90,  2, 4,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_17\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,   94, 101,                 60,90,  2, 4,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_18\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  101, 108,                 60,90,  2, 4,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_19\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  108, 115,                 60,90,  2, 4,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_20\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  115, 122,                 60,90,  2, 4,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_21\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  122, 129,                 60,90,  2, 4,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_22\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  129, 136,                 60,90,  2, 4,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_23\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  136, 143,                 60,90,  2, 4,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_24\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,  143, 150,                 60,90,  2, 4,   20*60 ) )\n",
    "    Bins.append( Bin(\"TRO_25\", \"EISCAT Tromso radar scan region\",  0, 24,  -90,  90,   80, 150,                 60,90,  4, 9,   20*60 ) )\n",
    "    \n",
    "    #Bins.append( Bin(\"TST_00\", \"Test region\",                      0, 24,  -90,  90,   80, 150,                 60,90,  0, 9,   20*60 ) )\n",
    "    binGroupNames = list()\n",
    "    for B in Bins:\n",
    "        aGroupName = B.ID[ : B.ID.find(\"_\") ]\n",
    "        if aGroupName not in binGroupNames: binGroupNames.append( aGroupName )\n",
    "    BinGroups_Dropdown.options = binGroupNames\n",
    "    \n",
    "InitializeBins()\n",
    "\n",
    "# tries to identify the bin according to the given argument and returns its description. If it fails it returns the argument.\n",
    "# examples: \"PCF_H2\"->\"Polar cap F-region\"   \"PCF\"->\"Polar cap F-region\"\n",
    "def getBinDescription( str ):\n",
    "    result = \"\"\n",
    "    for B in Bins:\n",
    "        if B.ID == str: result = B.Description\n",
    "    if len(result)==0:\n",
    "        for B in Bins:\n",
    "            if B.ID.startswith( str ): result = B.Description\n",
    "    if len(result)==0: result = str\n",
    "    #\n",
    "    return result\n",
    "\n",
    "\n",
    "def createBinsForTheWholeEarth():\n",
    "    n = 1\n",
    "    for Kp_min in [0, 2, 4]:\n",
    "        if Kp_min == 0:\n",
    "            Kp_max = 2\n",
    "        elif Kp_min == 2:\n",
    "            Kp_max = 4\n",
    "        elif Kp_min == 4:\n",
    "            Kp_max = 9\n",
    "        ####matc\n",
    "        for MLT_min in range(0, 24, 4):\n",
    "            for MagLat_min in range(-180, 180, 20):\n",
    "                for Alt_min in range(115, 250, 25):\n",
    "                    n = n + 1\n",
    "                    Bins.append( Bin(\"E\"+str(n), \"\",            MLT_min, MLT_min+4,   MagLat_min, MagLat_min+15,   Alt_min, Alt_min+25,               Kp_min, Kp_max,   20*60 ) )                    \n",
    "    print ( len(Bins) + \" Bins covering the whole Earth.\")    \n",
    "#createBinsForTheWholeEarth()\n",
    "\n",
    "# cheks if certain MLT lies in a certain range. Created in order to take account ranges like 22-2\n",
    "def is_MLT_inside_range( MLT, MLT_min, MLT_max ):\n",
    "    if MLT_min < MLT_max: # example: from 13 to 18 hour\n",
    "        return (MLT > MLT_min  and  MLT <= MLT_max)\n",
    "    elif MLT_min == MLT_max: # example: from 12 until 12 the other day\n",
    "        return True\n",
    "    else: # example: from 22 to 3 hour\n",
    "        return (MLT > MLT_min  or   MLT <= MLT_max)\n",
    "\n",
    "    \n",
    "    \n",
    "# returns: the bin object which matches the arguments\n",
    "def GetMatchedBin( MLT, MagLat, Altitude, Kp, Latitude ):\n",
    "    MatchedBin = None\n",
    "    for B in Bins:\n",
    "        if Latitude >= B.Lat_min  and  Latitude <= B.Lat_max:\n",
    "            if is_MLT_inside_range(MLT, B.MLT_min, B.MLT_max):\n",
    "                if MagLat   > B.MagLat_min    and  MagLat   <= B.MagLat_max:\n",
    "                    if Altitude > B.Altitude_min  and  Altitude <= B.Altitude_max:\n",
    "                        Kp_min_to_check = B.Kp_min\n",
    "                        if Kp_min_to_check == 0: Kp_min_to_check = -1\n",
    "                        if Kp       > Kp_min_to_check and  Kp       <= B.Kp_max:\n",
    "                            MatchedBin = B\n",
    "                            break\n",
    "    return MatchedBin\n",
    "\n",
    "\n",
    "# returns: the bin object which matches the arguments\n",
    "def getBinByItsProperties( MLT_min, MLT_max, MagLat_min, MagLat_max, Altitude_min, Altitude_max, Kp_min, Kp_max ):\n",
    "    CorrectBin = None\n",
    "    for B in Bins:\n",
    "        if             MLT_min      == B.MLT_min       and  MLT_max      == B.MLT_max:\n",
    "            if         MagLat_min   == B.MagLat_min    and  MagLat_max   == B.MagLat_max:\n",
    "                if     Altitude_min == B.Altitude_min  and  Altitude_max == B.Altitude_max:\n",
    "                    if Kp_min       == B.Kp_min        and  Kp_max       == B.Kp_max:\n",
    "                        CorrectBin = B\n",
    "                        break\n",
    "    return CorrectBin\n",
    "\n",
    "# returns: the bin object which matches the arguments\n",
    "def getBinByItsID( aBinID ):\n",
    "    CorrectBin = None\n",
    "    for B in Bins:\n",
    "        if  B.ID == aBinID:\n",
    "            CorrectBin = B\n",
    "            break\n",
    "    return CorrectBin\n",
    "\n",
    "\n",
    "        \n",
    "# Save the results in a text file        \n",
    "def SaveResults_TXT( ResultsFilename ):\n",
    "    global CALCULATIONS_Title, CALCULATIONS_Description, CALCULATIONS_RegionName, CALCULATIONS_OrbitFilesPath, CALCULATIONS_TIEGCMfolder, CALCULATIONS_ExecutionDuration\n",
    "    global all_JH_values, all_MagLat_values, all_MLT_values, all_Altitude_values\n",
    "    nowstr = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")    \n",
    "    F = open(ResultsFilename, 'w')\n",
    "    F.write( \"# -- JOULE HEATING per BIN RESULTS -- \" + \"\\n\"  )\n",
    "    F.write( \"# Date of execution: \" + nowstr + \"\\n\" )\n",
    "    F.write( \"# Title: \" + CALCULATIONS_Title + \"\\n\" )\n",
    "    F.write( \"# Region: \" + CALCULATIONS_RegionName + \"\\n\" )\n",
    "    F.write( \"# Orbit Filename: \" + CALCULATIONS_OrbitFilesPath + \"\\n\" )\n",
    "    F.write( \"# Description: \" + CALCULATIONS_Description + \"\\n\")\n",
    "    F.write( \"# DataPath: \" + CALCULATIONS_TIEGCMfolder + \"\\n\")\n",
    "    F.write( \"# Duration of execution: \" + ConvertLeadingZerosToSpaces(\"{0:.0f}\".format(CALCULATIONS_ExecutionDuration)) + \" seconds  or  \" + ConvertLeadingZerosToSpaces(\"{0:.2f}\".format(CALCULATIONS_ExecutionDuration/60))  + \" minutes\" + \"\\n\" )\n",
    "    F.write( \"# \" + \"\\n\")    \n",
    "    for B in Bins:\n",
    "        F.write( B.getInfo() + \"\\n\" )\n",
    "    ##\n",
    "    F.write( \"\\nAll JH values: \" ) \n",
    "    for i in range(0, len(all_JH_values) ):\n",
    "        F.write( str( all_JH_values[i]) )\n",
    "        if i < len(all_JH_values)-1: F.write( ',' )\n",
    "    F.write( \"\\nAll MagLat values: \" ) \n",
    "    for i in range(0, len(all_MagLat_values) ):\n",
    "        F.write( \"{:.4g}\".format( all_MagLat_values[i]) )\n",
    "        if i < len(all_MagLat_values)-1: F.write( ',' )   \n",
    "    F.write( \"\\nAll MLT values: \" ) \n",
    "    for i in range(0, len(all_MLT_values) ):\n",
    "        F.write( \"{:.4g}\".format( all_MLT_values[i]) )\n",
    "        if i < len(all_MLT_values)-1: F.write( ',' ) \n",
    "    F.write( \"\\nAll Altitude values: \" ) \n",
    "    for i in range(0, len(all_Altitude_values) ):\n",
    "        F.write( \"{:.4g}\".format( all_Altitude_values[i]) )\n",
    "        if i < len(all_Altitude_values)-1: F.write( ',' )             \n",
    "    ## write all data separated at bins\n",
    "    F.write(\"\\n\")\n",
    "    for B in Bins:\n",
    "        F.write(\"\\n\")\n",
    "        F.write( \"BIN \" + B.ID + \": MagLat values = \" )\n",
    "        for i in range(0, len(B.MagLat_values) ):\n",
    "            F.write(  \"{:.5g}\".format(B.MagLat_values[i])  )\n",
    "            if i < len(B.MagLat_values)-1: F.write( ',' )\n",
    "        F.write(\"\\n\")\n",
    "        F.write( \"BIN \" + B.ID + \": MLT values = \" )\n",
    "        for i in range(0, len(B.MLT_values) ):\n",
    "            F.write(  \"{:.5g}\".format(B.MLT_values[i])  )\n",
    "            if i < len(B.MLT_values)-1: F.write( ',' )\n",
    "        F.write(\"\\n\")\n",
    "        F.write( \"BIN \" + B.ID + \": Altitude values = \" )\n",
    "        for i in range(0, len(B.Altitude_values) ):\n",
    "            F.write(  \"{:.5g}\".format(B.Altitude_values[i])  )\n",
    "            if i < len(B.Altitude_values)-1: F.write( ',' )\n",
    "    ##\n",
    "    F.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# creates a results NetCDF file and its structure\n",
    "def CreateResults_CDF( ResultsFilename ):\n",
    "    global CALCULATIONS_Title, CALCULATIONS_Description, CALCULATIONS_RegionName, CALCULATIONS_OrbitFilesPath, CALCULATIONS_TIEGCMfolder, CALCULATIONS_ExecutionDuration\n",
    "    global all_JH_values, all_MagLat_values, all_MLT_values, all_Altitude_values, all_Kp_values, all_Time_values, all_EEX_values, all_EEY_values, all_Pedersen_values, all_Density_values, all_Lev_values, all_Hall_values\n",
    "    # save general info\n",
    "    resultsCDF = Dataset( ResultsFilename, 'w' )\n",
    "    resultsCDF.Content         = \"JOULE HEATING per BIN RESULTS. This file contains information about the bins in which the thermosphere is divided according to Magnetic Latitude, Magnetic Local Time, Altitude and Kp-index. We say there is a hit inside a bin when a satellite position or TIEGCM-grid position lies inside the above boundaries. The file contains data for each hit inside a bin. That is the position's MagLat, MLT, Alt, Kp and Joule-Heating value\"\n",
    "    resultsCDF.DateOfCreation  = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    resultsCDF.DateOfUpdate    = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    resultsCDF.Title           = CALCULATIONS_Title\n",
    "    resultsCDF.Region          = CALCULATIONS_RegionName\n",
    "    resultsCDF.OrbitFile       = CALCULATIONS_OrbitFilesPath\n",
    "    resultsCDF.Description     = CALCULATIONS_Description\n",
    "    resultsCDF.DataPath        = CALCULATIONS_TIEGCMfolder\n",
    "    resultsCDF.LastExecDurationSec = 0\n",
    "    resultsCDF.Progress        = \"\"\n",
    "    # save data for each bin spearately \n",
    "    resultsCDF.createDimension( \"SingleSpaceFooDimension\", 1 )\n",
    "    resultsCDF.createDimension('char8', 8)\n",
    "    for B in Bins:\n",
    "        # save general info about the bin\n",
    "        VAR_BinInfo = resultsCDF.createVariable( B.ID, \"S1\", (\"SingleSpaceFooDimension\",) )\n",
    "        VAR_BinInfo.long_name    = \"Information about the bin \" + B.ID + \" (\" + B.Description + \")\"\n",
    "        VAR_BinInfo.MagLat_min   = \"{:02.0f}\".format(B.MagLat_min)\n",
    "        VAR_BinInfo.MagLat_max   = \"{:02.0f}\".format(B.MagLat_max)\n",
    "        VAR_BinInfo.MLT_min      = \"{:02.0f}\".format(B.MLT_min)\n",
    "        VAR_BinInfo.MLT_max      = \"{:02.0f}\".format(B.MLT_max)\n",
    "        VAR_BinInfo.Altitude_min = \"{:02.0f}\".format(B.Altitude_min)\n",
    "        VAR_BinInfo.Altitude_max = \"{:02.0f}\".format(B.Altitude_max)\n",
    "        VAR_BinInfo.Lat_min       = \"{:02.0f}\".format(B.Lat_min)\n",
    "        VAR_BinInfo.Lat_max       = \"{:02.0f}\".format(B.Lat_max)\n",
    "        VAR_BinInfo.Kp_min       = \"{:02.0f}\".format(B.Kp_min)\n",
    "        VAR_BinInfo.Kp_max       = \"{:02.0f}\".format(B.Kp_max)\n",
    "        VAR_BinInfo.JH_mean      = \"{:.3e}\".format(B.JH_mean)\n",
    "        VAR_BinInfo.JH_variance  = \"{:.3e}\".format(B.JH_variance)\n",
    "        VAR_BinInfo.DesirableCumulativeTime = str(B.DesirableCumulativeTime) + \"sec\"\n",
    "        if B.JH_min == 99999: \n",
    "            VAR_BinInfo.JH_min = \"\"\n",
    "        else:\n",
    "            VAR_BinInfo.JH_min = \"{:.3e}\".format(B.JH_min)\n",
    "        # create structure for each bin\n",
    "        resultsCDF.createDimension( B.ID+\"_time_dim\", None )\n",
    "        VAR_BinTimeValues             = resultsCDF.createVariable( B.ID+\"_TimeValues\", \"f4\", (B.ID+\"_time_dim\",) )\n",
    "        VAR_BinTimeValues.description = \"UTC timestamp\"\n",
    "        VAR_BinTimeValues.units       = \"seconds\"\n",
    "        resultsCDF.createDimension( B.ID+\"_jh_dim\", None )\n",
    "        VAR_BinJHvalues = resultsCDF.createVariable( B.ID+\"_JHValues\", \"f4\", (B.ID+\"_jh_dim\",) )\n",
    "        VAR_BinJHvalues.description = \"Ohmic\"\n",
    "        VAR_BinJHvalues.units       = \"W/m3\"\n",
    "        resultsCDF.createDimension( B.ID+\"_maglat_dim\", None )\n",
    "        VAR_BinMagLatValues = resultsCDF.createVariable( B.ID+\"_MagLatValues\", \"f4\", (B.ID+\"_maglat_dim\",) )\n",
    "        VAR_BinMagLatValues.description = \"Magnetic Latitude\"\n",
    "        VAR_BinMagLatValues.units       = \"degrees\"\n",
    "        resultsCDF.createDimension( B.ID+\"_mlt_dim\", None )\n",
    "        VAR_BinMLTValues = resultsCDF.createVariable( B.ID+\"_MLTValues\", \"f4\", (B.ID+\"_mlt_dim\",) )\n",
    "        VAR_BinMLTValues.description = \"Magnetic Local Time\"\n",
    "        VAR_BinMLTValues.units       = \"hours\"\n",
    "        resultsCDF.createDimension( B.ID+\"_alt_dim\", None )\n",
    "        VAR_BinAltitudeValues = resultsCDF.createVariable( B.ID+\"_AltitudeValues\", \"f4\", (B.ID+\"_alt_dim\",) )\n",
    "        VAR_BinAltitudeValues.description = \"Altitude from the surface of the Earth\"\n",
    "        VAR_BinAltitudeValues.units       = \"km\"\n",
    "        resultsCDF.createDimension( B.ID+\"_lat_dim\", None )\n",
    "        VAR_BinLatValues = resultsCDF.createVariable( B.ID+\"_LatValues\", \"f4\", (B.ID+\"_lat_dim\",) )\n",
    "        VAR_BinLatValues.description = \"Latitude\"\n",
    "        VAR_BinLatValues.units       = \"degrees\"\n",
    "        resultsCDF.createDimension( B.ID+\"_kp_dim\", None )\n",
    "        VAR_BinKpValues = resultsCDF.createVariable( B.ID+\"_KpValues\", \"f4\", (B.ID+\"_kp_dim\",) )\n",
    "        VAR_BinKpValues.description = \"Kp index of Sun activity\"\n",
    "        VAR_BinKpValues.units       = \"-\"\n",
    "        resultsCDF.createDimension( B.ID+\"_eex_dim\", None )\n",
    "        VAR_BinEEXValues = resultsCDF.createVariable( B.ID+\"_EEXValues\", \"f4\", (B.ID+\"_eex_dim\",) )\n",
    "        VAR_BinEEXValues.description = \"Electric field strength East. (SI)\"\n",
    "        VAR_BinEEXValues.units       = \"V/m\"\n",
    "        resultsCDF.createDimension( B.ID+\"_eey_dim\", None )\n",
    "        VAR_BinEEYValues = resultsCDF.createVariable( B.ID+\"_EEYValues\", \"f4\", (B.ID+\"_eey_dim\",) )\n",
    "        VAR_BinEEYValues.description = \"Electric field strength North. (SI)\"\n",
    "        VAR_BinEEYValues.units       = \"V/m\"\n",
    "        resultsCDF.createDimension( B.ID+\"_ped_dim\", None )\n",
    "        VAR_BinPedersenValues = resultsCDF.createVariable( B.ID+\"_PedersenValues\", \"f4\", (B.ID+\"_ped_dim\",) )\n",
    "        VAR_BinPedersenValues.description = \"SIGMA_PED\"\n",
    "        VAR_BinPedersenValues.units       = \"S/m\"\n",
    "        resultsCDF.createDimension( B.ID+\"_den_dim\", None )\n",
    "        VAR_BinDensityValues = resultsCDF.createVariable( B.ID+\"_DensityValues\", \"f4\", (B.ID+\"_den_dim\",) )\n",
    "        VAR_BinDensityValues.description = \"Total Density\"\n",
    "        VAR_BinDensityValues.units       = \"g/cm3\"\n",
    "        resultsCDF.createDimension( B.ID+\"_lev_dim\", None )\n",
    "        VAR_BinLevValues = resultsCDF.createVariable( B.ID+\"_LevValues\", \"f4\", (B.ID+\"_lev_dim\",) )\n",
    "        VAR_BinLevValues.description = \"midpoint levels\"\n",
    "        VAR_BinLevValues.units       = \"\"\n",
    "        resultsCDF.createDimension( B.ID+\"_hal_dim\", None )\n",
    "        VAR_BinHallValues = resultsCDF.createVariable( B.ID+\"_HallValues\", \"f4\", (B.ID+\"_hal_dim\",) )\n",
    "        VAR_BinHallValues.description = \"SIGMA_HAL\"\n",
    "        VAR_BinHallValues.units       = \"S/m\"\n",
    "        resultsCDF.createDimension( B.ID+\"_convh_dim\", None )\n",
    "        VAR_BinConvhValues = resultsCDF.createVariable( B.ID+\"_ConvectionHeatingValues\", \"f4\", (B.ID+\"_convh_dim\",) )\n",
    "        VAR_BinConvhValues.description = \"Convection Heating\"\n",
    "        VAR_BinConvhValues.units       = \"W/m3\"\n",
    "        resultsCDF.createDimension( B.ID+\"_windh_dim\", None )\n",
    "        VAR_BinWindhValues = resultsCDF.createVariable( B.ID+\"_WindHeatingValues\", \"f4\", (B.ID+\"_windh_dim\",) )\n",
    "        VAR_BinWindhValues.description = \"Wind Correction\"\n",
    "        VAR_BinWindhValues.units       = \"W/m3\"\n",
    "    ## save data for all hits\n",
    "    resultsCDF.createDimension( \"time_dim\", None )\n",
    "    VAR_TimeValues         = resultsCDF.createVariable(\"allTimeValues\", \"f4\", (\"time_dim\",) )\n",
    "    VAR_TimeValues.description = \"UTC timestamp\"\n",
    "    VAR_TimeValues.units       = \"seconds\"\n",
    "    resultsCDF.createDimension( \"jh_dim\", None )\n",
    "    VAR_JHvalues = resultsCDF.createVariable(\"allJHValues\", \"f4\", (\"jh_dim\",) )\n",
    "    VAR_JHvalues.description = \"Ohmic\"\n",
    "    VAR_JHvalues.units       = \"W/m3\"\n",
    "    resultsCDF.createDimension( \"maglat_dim\", None )\n",
    "    VAR_MagLatValues = resultsCDF.createVariable(\"allMagLatValues\", \"f4\", (\"maglat_dim\",) )\n",
    "    VAR_MagLatValues.description = \"Magnetic Latitude\"\n",
    "    VAR_MagLatValues.units       = \"degrees\"\n",
    "    resultsCDF.createDimension( \"mlt_dim\", None )\n",
    "    VAR_MLTValues = resultsCDF.createVariable(\"allMLTValues\", \"f4\", (\"mlt_dim\",) )\n",
    "    VAR_MLTValues.description = \"Magnetic Local Time\"\n",
    "    VAR_MLTValues.units       = \"hours\"\n",
    "    resultsCDF.createDimension( \"alt_dim\", None )\n",
    "    VAR_AltitudeValues = resultsCDF.createVariable(\"allAltitudeValues\", \"f4\", (\"alt_dim\",) )\n",
    "    VAR_AltitudeValues.description = \"Altitude from the surface of the Earth\"\n",
    "    VAR_AltitudeValues.units       = \"km\"\n",
    "    resultsCDF.createDimension( \"lat_dim\", None )\n",
    "    VAR_LatValues = resultsCDF.createVariable(\"allLatValues\", \"f4\", (\"lat_dim\",) )\n",
    "    VAR_LatValues.description = \"Latitude\"\n",
    "    VAR_LatValues.units       = \"degrees\"\n",
    "    resultsCDF.createDimension( \"kp_dim\", None )\n",
    "    VAR_KpValues = resultsCDF.createVariable(\"allKpValues\", \"f4\", (\"kp_dim\",) )\n",
    "    VAR_KpValues.description = \"Kp index of Sun activity\"\n",
    "    VAR_KpValues.units       = \"-\"\n",
    "    resultsCDF.createDimension( \"bins_dim\", None )\n",
    "    VAR_HittedBinIDs = resultsCDF.createVariable(\"allHittedBinIDs\", \"S1\", (\"bins_dim\",\"char8\",) )\n",
    "    VAR_HittedBinIDs.description = \"The ID of the bin, where the hit occured\"\n",
    "    resultsCDF.createDimension( \"eex_dim\", None )\n",
    "    VAR_EEXvalues = resultsCDF.createVariable(\"allEEXValues\", \"f4\", (\"eex_dim\",) )\n",
    "    VAR_EEXvalues.description = \"Electric field strength East. (SI)\"\n",
    "    VAR_EEXvalues.units       = \"V/m\"\n",
    "    resultsCDF.createDimension( \"eey_dim\", None )\n",
    "    VAR_EEYvalues = resultsCDF.createVariable(\"allEEYValues\", \"f4\", (\"eey_dim\",) )\n",
    "    VAR_EEYvalues.description = \"Electric field strength North. (SI)\"\n",
    "    VAR_EEYvalues.units       = \"V/m\"\n",
    "    resultsCDF.createDimension( \"ped_dim\", None )\n",
    "    VAR_Pedersenvalues = resultsCDF.createVariable(\"allPedersenValues\", \"f4\", (\"ped_dim\",) )\n",
    "    VAR_Pedersenvalues.description = \"Pedersen Conductivity\"\n",
    "    VAR_Pedersenvalues.units       = \"S/m\"\n",
    "    resultsCDF.createDimension( \"den_dim\", None )\n",
    "    VAR_Densityvalues = resultsCDF.createVariable(\"allDensityValues\", \"f4\", (\"den_dim\",) )\n",
    "    VAR_Densityvalues.description = \"Total Density\"\n",
    "    VAR_Densityvalues.units       = \"g/cm3\"\n",
    "    resultsCDF.createDimension( \"lev_dim\", None )\n",
    "    VAR_LevValues = resultsCDF.createVariable(\"allLevValues\", \"f4\", (\"lev_dim\",) )\n",
    "    VAR_LevValues.description = \"midpoint levels\"\n",
    "    VAR_LevValues.units       = \"\"\n",
    "    resultsCDF.createDimension( \"hal_dim\", None )\n",
    "    VAR_Hallvalues = resultsCDF.createVariable(\"allHallValues\", \"f4\", (\"hal_dim\",) )\n",
    "    VAR_Hallvalues.description = \"Hall Conductivity\"\n",
    "    VAR_Hallvalues.units       = \"S/m\"\n",
    "    resultsCDF.createDimension( \"convh_dim\", None )\n",
    "    VAR_ConvhValues = resultsCDF.createVariable(\"allConvectionHeatingValues\", \"f4\", (\"convh_dim\",) )\n",
    "    VAR_ConvhValues.description = \"Convection Heating\"\n",
    "    VAR_ConvhValues.units       = \"W/m3\"\n",
    "    resultsCDF.createDimension( \"windh_dim\", None )\n",
    "    VAR_WindhValues = resultsCDF.createVariable(\"allWindHeatingValues\", \"f4\", (\"windh_dim\",) )\n",
    "    VAR_WindhValues.description = \"Wind Correction\"\n",
    "    VAR_WindhValues.units       = \"W/m3\"\n",
    "    resultsCDF.close()\n",
    "    \n",
    "    \n",
    "# Append the results in a NetCDF file. The data will be saved in ResultsFilename and they come from DataFilename.\n",
    "# DataFilename is needed to check if the file contains already the results of the DataFilename\n",
    "def SaveResults_CDF( ResultsFilename, DataFilename ):\n",
    "    if path.exists( ResultsFilename ) == False:\n",
    "        CreateResults_CDF( ResultsFilename )\n",
    "    # save general info\n",
    "    ErrorMsg = \"\"\n",
    "    resultsCDF = Dataset( ResultsFilename, 'a' )\n",
    "    resultsCDF.DateOfUpdate = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "    if resultsCDF.Region    != CALCULATIONS_RegionName: ErrorMsg = \"Save aborted: NetCDF file has already data about region \" + resultsCDF.Region + \" and you tried to save data about region \" + CALCULATIONS_RegionName        \n",
    "    if resultsCDF.OrbitFile != CALCULATIONS_OrbitFilesPath: ErrorMsg = \"Save aborted: NetCDF file has already data about orbit \" + resultsCDF.OrbitFile + \" and you tried to save data about orbit \" + CALCULATIONS_OrbitFilesPath\n",
    "    if resultsCDF.DataPath  != CALCULATIONS_TIEGCMfolder: ErrorMsg = \"Save aborted: NetCDF file has already data about TIEGCM file \" + resultsCDF.DataPath  + \"and you tried to save data about TIEGCM file \" + CALCULATIONS_TIEGCMfolder        \n",
    "    if len(DataFilename)>0 and resultsCDF.Progress > DataFilename: ErrorMsg = \"Save aborted: NetCDF file contains data about file: \" + resultsCDF.Progress + \" which is later than \" + DataFilename\n",
    "    if len(ErrorMsg) > 0:\n",
    "        print( ErrorMsg )\n",
    "        resultsCDF.close()\n",
    "        return\n",
    "    resultsCDF.LastExecDurationSec = ConvertLeadingZerosToSpaces(\"{0:.0f}\".format(CALCULATIONS_ExecutionDuration)).strip()\n",
    "    # save data for each bin spearately \n",
    "    for B in Bins:\n",
    "        # save data about the hits inside the bin\n",
    "        if len(B.Time_values) > 0:\n",
    "            resultsCDF.variables[B.ID+\"_TimeValues\"][:]      = resultsCDF.variables[B.ID+\"_TimeValues\"][:].tolist() + B.Time_values\n",
    "            resultsCDF.variables[B.ID+\"_JHValues\"][:]        = resultsCDF.variables[B.ID+\"_JHValues\"][:].tolist() + B.JH_values        \n",
    "            resultsCDF.variables[B.ID+\"_MagLatValues\"][:]    = resultsCDF.variables[B.ID+\"_MagLatValues\"][:].tolist() + B.MagLat_values\n",
    "            resultsCDF.variables[B.ID+\"_MLTValues\"][:]       = resultsCDF.variables[B.ID+\"_MLTValues\"][:].tolist() + B.MLT_values\n",
    "            resultsCDF.variables[B.ID+\"_AltitudeValues\"][:]  = resultsCDF.variables[B.ID+\"_AltitudeValues\"][:].tolist() + B.Altitude_values\n",
    "            resultsCDF.variables[B.ID+\"_LatValues\"][:]       = resultsCDF.variables[B.ID+\"_LatValues\"][:].tolist() + B.Lat_values\n",
    "            resultsCDF.variables[B.ID+\"_KpValues\"][:]        = resultsCDF.variables[B.ID+\"_KpValues\"][:].tolist() + B.Kp_values\n",
    "            resultsCDF.variables[B.ID+\"_EEXValues\"][:]       = resultsCDF.variables[B.ID+\"_EEXValues\"][:].tolist() + B.EEX_values        \n",
    "            resultsCDF.variables[B.ID+\"_EEYValues\"][:]       = resultsCDF.variables[B.ID+\"_EEYValues\"][:].tolist() + B.EEY_values\n",
    "            resultsCDF.variables[B.ID+\"_PedersenValues\"][:]  = resultsCDF.variables[B.ID+\"_PedersenValues\"][:].tolist() + B.Pedersen_values\n",
    "            resultsCDF.variables[B.ID+\"_DensityValues\"][:]   = resultsCDF.variables[B.ID+\"_DensityValues\"][:].tolist() + B.Density_values\n",
    "            resultsCDF.variables[B.ID+\"_LevValues\"][:]       = resultsCDF.variables[B.ID+\"_LevValues\"][:].tolist() + B.Lev_values\n",
    "            resultsCDF.variables[B.ID+\"_HallValues\"][:]      = resultsCDF.variables[B.ID+\"_HallValues\"][:].tolist() + B.Hall_values\n",
    "            resultsCDF.variables[B.ID+\"_ConvectionHeatingValues\"][:] = resultsCDF.variables[B.ID+\"_ConvectionHeatingValues\"][:].tolist() + B.ConvectionHeating_values\n",
    "            resultsCDF.variables[B.ID+\"_WindHeatingValues\"][:] = resultsCDF.variables[B.ID+\"_WindHeatingValues\"][:].tolist() + B.WindHeating_values\n",
    "    ## save data for all hits\n",
    "    if len(all_Time_values) > 0:\n",
    "        resultsCDF.variables[\"allTimeValues\"][:]     = resultsCDF.variables[\"allTimeValues\"][:].tolist() + all_Time_values\n",
    "        resultsCDF.variables[\"allJHValues\"][:]       = resultsCDF.variables[\"allJHValues\"][:].tolist() + all_JH_values    \n",
    "        resultsCDF.variables[\"allMagLatValues\"][:]   = resultsCDF.variables[\"allMagLatValues\"][:].tolist() + all_MagLat_values\n",
    "        resultsCDF.variables[\"allMLTValues\"][:]      = resultsCDF.variables[\"allMLTValues\"][:].tolist() + all_MLT_values\n",
    "        resultsCDF.variables[\"allAltitudeValues\"][:] = resultsCDF.variables[\"allAltitudeValues\"][:].tolist() + all_Altitude_values\n",
    "        resultsCDF.variables[\"allLatValues\"][:]      = resultsCDF.variables[\"allLatValues\"][:].tolist() + all_Lat_values\n",
    "        resultsCDF.variables[\"allKpValues\"][:]       = resultsCDF.variables[\"allKpValues\"][:].tolist() + all_Kp_values\n",
    "        #resultsCDF.variables[\"allHittedBinIDs\"][:]   = resultsCDF.variables[\"allHittedBinIDs\"][:].tolist() + netCDF4.stringtochar(np.array(all_HittedBin_IDs[:], 'S8'))\n",
    "        resultsCDF.variables[\"allEEXValues\"][:]      = resultsCDF.variables[\"allEEXValues\"][:].tolist() + all_EEX_values\n",
    "        resultsCDF.variables[\"allEEYValues\"][:]      = resultsCDF.variables[\"allEEYValues\"][:].tolist() + all_EEY_values\n",
    "        resultsCDF.variables[\"allPedersenValues\"][:] = resultsCDF.variables[\"allPedersenValues\"][:].tolist() + all_Pedersen_values\n",
    "        resultsCDF.variables[\"allDensityValues\"][:]  = resultsCDF.variables[\"allDensityValues\"][:].tolist() + all_Density_values\n",
    "        resultsCDF.variables[\"allLevValues\"][:]      = resultsCDF.variables[\"allLevValues\"][:].tolist() + all_Lev_values\n",
    "        resultsCDF.variables[\"allHallValues\"][:]     = resultsCDF.variables[\"allHallValues\"][:].tolist() + all_Hall_values\n",
    "        resultsCDF.variables[\"allConvectionHeatingValues\"][:] = resultsCDF.variables[\"allConvectionHeatingValues\"][:].tolist() + all_ConvectionHeating_values\n",
    "        resultsCDF.variables[\"allWindHeatingValues\"][:] = resultsCDF.variables[\"allWindHeatingValues\"][:].tolist() + all_WindHeating_values\n",
    "    #\n",
    "    resultsCDF.close()    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def LoadResults_CDF( filepath, loadBinValues=True, loadGlobalValues=True, loadTimeValues=True, loadMagLatValues=True, loadMLTvalues=True, loadAltValues=True, loadLatValues=True, loadKpValues=True ):\n",
    "    global CALCULATIONS_Title, CALCULATIONS_Description, CALCULATIONS_RegionName, CALCULATIONS_OrbitFilesPath, CALCULATIONS_TIEGCMfolder, CALCULATIONS_ExecutionDuration\n",
    "    global all_JH_values, all_MagLat_values, all_MLT_values, all_Altitude_values, all_Kp_values, all_Time_values, all_EEX_values, all_EEY_values, all_Pedersen_values, all_Density_values, all_Lev_values, all_Hall_values\n",
    "\n",
    "    # reset values\n",
    "    for B in Bins:\n",
    "        B.reset()\n",
    "    all_JH_values       = list()\n",
    "    all_MagLat_values   = list()\n",
    "    all_MLT_values      = list()\n",
    "    all_Altitude_values = list()\n",
    "    all_Lat_values      = list()\n",
    "    all_Kp_values       = list() \n",
    "    all_Time_values     = list()\n",
    "    all_HittedBin_IDs   = list()\n",
    "    all_EEX_values      = list()\n",
    "    all_EEY_values      = list()\n",
    "    all_Pedersen_values = list()\n",
    "    all_Density_values  = list()\n",
    "    all_Lev_values      = list()\n",
    "    all_Hall_values     = list()\n",
    "    all_ConvectionHeating_values = list()\n",
    "    all_WindHeating_values = list()\n",
    "    \n",
    "    print( \"Started Loading\", filepath, datetime.now() )\n",
    "\n",
    "    # make a list of all the files we are going to load\n",
    "    All_ResultFilenames = list()\n",
    "    if filepath[-1] == '/':\n",
    "        All_ResultFilenames = sorted( glob.glob(filepath+\"*.nc\") )\n",
    "    else:\n",
    "        All_ResultFilenames.append( filepath )\n",
    "    \n",
    "    # load each file into memory\n",
    "    for file_idx in range(0, len(All_ResultFilenames)):\n",
    "        if file_idx % 10 == 0: print( \"Now Loading\", All_ResultFilenames[file_idx] )\n",
    "        #if file_idx == 2: break\n",
    "        resultsCDF = Dataset( All_ResultFilenames[file_idx], 'r' )\n",
    "        #### load general information\n",
    "        if file_idx == 0:\n",
    "            try:\n",
    "                print( \"DateOfCreation:\", resultsCDF.DateOfCreation, \" LastExecDurationSec :\", resultsCDF.LastExecDurationSec , \"sec\" )\n",
    "                #print( \"Title:\", resultsCDF.Title, \" Description:\", resultsCDF.Description )\n",
    "                print( \"Region:\", resultsCDF.Region )\n",
    "                print( \"OrbitFile:\", resultsCDF.OrbitFile )\n",
    "                print( \"TIEGCM data path:\", resultsCDF.DataPath, \"\\n\" )\n",
    "                #print( \"Progress:\", resultsCDF.Progress, \"\\n\" )\n",
    "            except:\n",
    "                pass\n",
    "            CALCULATIONS_Title = resultsCDF.Title\n",
    "            CALCULATIONS_Description = resultsCDF.Description\n",
    "            #CALCULATIONS_ExecutionDuration = resultsCDF.LastExecDurationSec\n",
    "            CALCULATIONS_RegionName = resultsCDF.Region\n",
    "            CALCULATIONS_OrbitFilesPath = resultsCDF.OrbitFile.split()\n",
    "            CALCULATIONS_TIEGCMfolder = resultsCDF.DataPath\n",
    "        #### load data for each bin\n",
    "        if loadBinValues:\n",
    "            for B in Bins:\n",
    "                try:\n",
    "                    if loadTimeValues and len(CALCULATIONS_OrbitFilesPath) > 0: concatLists( B.Time_values, list(resultsCDF.variables[ B.ID+\"_TimeValues\" ][:]) )\n",
    "                    if loadMagLatValues: concatLists( B.MagLat_values, list(resultsCDF.variables[ B.ID+\"_MagLatValues\" ][:]) )\n",
    "                    if loadMLTvalues: concatLists( B.MLT_values, list(resultsCDF.variables[ B.ID+\"_MLTValues\" ][:]) )\n",
    "                    if loadAltValues: concatLists( B.Altitude_values, list(resultsCDF.variables[ B.ID+\"_AltitudeValues\" ][:]) )\n",
    "                    try:\n",
    "                        if loadLatValues: concatLists(B.Lat_values, list(resultsCDF.variables[ B.ID+\"_LatValues\" ][:]) )\n",
    "                    except:\n",
    "                        pass\n",
    "                    if loadKpValues: concatLists(B.Kp_values, list(resultsCDF.variables[ B.ID+\"_KpValues\" ][:]) )\n",
    "                    if SELECTED_VARIABLE == \"Ohmic\":     concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+\"_JHValues\" ][:]) )  #    if SELECTED_VARIABLE == \"Ohmic\":     concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+\"_ConvenctionHeatingValues\" ][:]+resultsCDF.variables[ B.ID+\"_WindHeatingValues\" ][:]) )\n",
    "                    if SELECTED_VARIABLE == \"EEX_si\":    concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+\"_EEXValues\" ][:])*1000 ) #if SELECTED_VARIABLE == \"EEX_si\":    B.EEX_values = list(resultsCDF.variables[ B.ID+\"_EEXValues\" ][:])\n",
    "                    if SELECTED_VARIABLE == \"EEY_si\":    concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+\"_EEYValues\" ][:])*1000 ) #if SELECTED_VARIABLE == \"EEY_si\":    B.EEY_values = list(resultsCDF.variables[ B.ID+\"_EEYValues\" ][:])\n",
    "                    if SELECTED_VARIABLE == \"SIGMA_PED\": concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+\"_PedersenValues\" ][:]) ) #if SELECTED_VARIABLE == \"SIGMA_PED\": B.Pedersen_values = list(resultsCDF.variables[ B.ID+\"_PedersenValues\" ][:])\n",
    "                    if SELECTED_VARIABLE == \"SIGMA_HAL\": concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+\"_HallValues\" ][:]) ) #if SELECTED_VARIABLE == \"SIGMA_HAL\": B.Hall_values = list(resultsCDF.variables[ B.ID+\"_HallValues\" ][:])\n",
    "                    try:\n",
    "                        if SELECTED_VARIABLE == \"Convection_heating\": concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+\"_ConvectionHeatingValues\" ][:]) )\n",
    "                    except:\n",
    "                        if SELECTED_VARIABLE == \"Convection_heating\": concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+\"_ConvenctionHeatingValues\" ][:]) )\n",
    "                    if SELECTED_VARIABLE == \"Wind_heating\": concatLists( B.JH_values, list(resultsCDF.variables[ B.ID+\"_WindHeatingValues\" ][:]) )\n",
    "                except: # data about this region do not exist inside this netcdf file\n",
    "                    continue\n",
    "        #### load collective data about all bins\n",
    "        if loadGlobalValues:\n",
    "            if loadTimeValues and len(CALCULATIONS_OrbitFilesPath) > 0: concatLists( all_Time_values, list(resultsCDF.variables[ \"allTimeValues\" ][:]) )\n",
    "            if loadMagLatValues:  concatLists( all_MagLat_values, list(resultsCDF.variables[ \"allMagLatValues\" ][:]) )\n",
    "            if loadMLTvalues: concatLists( all_MLT_values, list(resultsCDF.variables[ \"allMLTValues\" ][:]) )\n",
    "            if loadAltValues: concatLists( all_Altitude_values, list(resultsCDF.variables[ \"allAltitudeValues\" ][:]) )\n",
    "            try:\n",
    "                if loadLatValues: concatLists( all_Lat_values, list(resultsCDF.variables[ \"allLatValues\" ][:]) )\n",
    "            except:\n",
    "                pass\n",
    "            if loadKpValues: concatLists( all_Kp_values, list(resultsCDF.variables[ \"allKpValues\" ][:]) )\n",
    "            if SELECTED_VARIABLE == \"Ohmic\":     concatLists( all_JH_values, list(resultsCDF.variables[ \"allJHValues\" ][:]) )  #if SELECTED_VARIABLE == \"Ohmic\":     concatLists( all_JH_values, list(resultsCDF.variables[ \"allConvenctionHeatingValues\" ][:] + resultsCDF.variables[ \"allWindHeatingValues\" ][:]) )\n",
    "            if SELECTED_VARIABLE == \"EEX_si\":    concatLists( all_JH_values, list(resultsCDF.variables[ \"allEEXValues\" ][:]*1000) )#if SELECTED_VARIABLE == \"EEX_si\":    all_EEX_values = list(resultsCDF.variables[ \"allEEXValues\" ][:])\n",
    "            if SELECTED_VARIABLE == \"EEY_si\":    concatLists( all_JH_values, list(resultsCDF.variables[ \"allEEYValues\" ][:]*1000) )#if SELECTED_VARIABLE == \"EEY_si\":    all_EEY_values = list(resultsCDF.variables[ \"allEEYValues\" ][:])\n",
    "            if SELECTED_VARIABLE == \"SIGMA_PED\": concatLists( all_JH_values, list(resultsCDF.variables[ \"allPedersenValues\" ][:]) )#if SELECTED_VARIABLE == \"SIGMA_PED\": all_Pedersen_values = list(resultsCDF.variables[ \"allPedersenValues\" ][:])\n",
    "            if SELECTED_VARIABLE == \"SIGMA_HAL\": concatLists( all_JH_values, list(resultsCDF.variables[ \"allHallValues\" ][:]) )#if SELECTED_VARIABLE == \"SIGMA_HAL\": all_Hall_values = list(resultsCDF.variables[ \"allHallValues\" ][:])\n",
    "            if SELECTED_VARIABLE == \"JH/mass\":   concatLists( all_JH_values, list(resultsCDF.variables[ \"allJHValues\" ][:]/(1000*resultsCDF.variables[ \"allDensityValues\" ][:]) ) )\n",
    "            if SELECTED_VARIABLE == \"JH/pressure\": \n",
    "                #newVals = np.zeros( len(resultsCDF.variables[ \"allJHValues\" ]) )\n",
    "                #for i in range( 0, len(resultsCDF.variables[ \"allJHValues\" ]) ):\n",
    "                #    newVals[i] = resultsCDF.variables[ \"allJHValues\" ][i]/(0.00005*math.exp(-resultsCDF.variables[ \"allLevValues\" ][i]) )  \n",
    "                #concatLists( all_JH_values, list(newVals) )\n",
    "                #print( \"QQQQ \", resultsCDF.variables[ \"allJHValues\" ][1], resultsCDF.variables[ \"allJHValues\" ][1000] )\n",
    "                #print( \"QQQQ \", resultsCDF.variables[ \"allAltitudeValues\" ][1],  resultsCDF.variables[ \"allAltitudeValues\" ][1000] )\n",
    "                concatLists( all_JH_values, list(resultsCDF.variables[ \"allJHValues\" ][:]/(0.00005*np.exp(-resultsCDF.variables[ \"allLevValues\" ][:]) ) ) )\n",
    "            try:\n",
    "                if SELECTED_VARIABLE == \"Convection_heating\": concatLists( all_JH_values, list(resultsCDF.variables[ \"allConvectionHeatingValues\" ][:]) )\n",
    "            except:\n",
    "                if SELECTED_VARIABLE == \"Convection_heating\": concatLists( all_JH_values, list(resultsCDF.variables[ \"allConvenctionHeatingValues\" ][:]) )\n",
    "            if SELECTED_VARIABLE == \"Wind_heating\": concatLists( all_JH_values, list(resultsCDF.variables[ \"allWindHeatingValues\" ][:]) )\n",
    "        #### close and go on\n",
    "        resultsCDF.close()\n",
    "    ########\n",
    "    # !!!! remove incorrect huge or negative Ohmic values\n",
    "    if (SELECTED_VARIABLE == \"Ohmic\")  and  (\"Hz\" in filepath or \"Tricubic\" in filepath):\n",
    "        # for each bin\n",
    "        for B in Bins:\n",
    "            if len(B.JH_values): print(B.ID, \"LENGTH BEFORE:\", len(B.JH_values))\n",
    "            huge_values = 0\n",
    "            negative_values = 0\n",
    "            nan_values = 0\n",
    "            found_at_current_round = True\n",
    "            while found_at_current_round:\n",
    "                found_at_current_round = False\n",
    "                for t in range(0, len(B.JH_values)):\n",
    "                    if B.JH_values[t] > 100 or B.JH_values[t] == float(\"inf\"):  huge_values += 1\n",
    "                    if B.JH_values[t] < 0   or B.JH_values[t] == float(\"-inf\"): negative_values += 1\n",
    "                    if np.isnan(B.JH_values[t]): nan_values += 1\n",
    "                    if B.JH_values[t]>100 or B.JH_values[t]<0 or np.isnan(B.JH_values[t]) or B.JH_values[t]==float(\"inf\") or B.JH_values[t]==float(\"-inf\"):\n",
    "                        found_at_current_round = True\n",
    "                        del B.JH_values[t]\n",
    "                        if len(B.Time_values) > 0: del B.Time_values[t]\n",
    "                        if len(B.MagLat_values) > 0: del B.MagLat_values[t]\n",
    "                        if len(B.MLT_values) > 0: del B.MLT_values[t]\n",
    "                        if len(B.Altitude_values) > 0: del B.Altitude_values[t]\n",
    "                        if len(B.Lat_values) > 0: del B.Lat_values[t]\n",
    "                        if len(B.Kp_values) > 0: del B.Kp_values[t]\n",
    "                        break\n",
    "            if len(B.JH_values): print( B.ID, \":\",  \"huge values =\", huge_values, \"negative values =\", negative_values, \"nan values =\", nan_values )\n",
    "            if len(B.JH_values): print(B.ID, \"LENGTH AFTER:\", len(B.JH_values))\n",
    "        # for arrays with all the data\n",
    "        print(\"ALL\", \"LENGTH BEFORE:\", len(all_JH_values))\n",
    "        huge_values = 0\n",
    "        negative_values = 0\n",
    "        nan_values = 0\n",
    "        found_at_current_round = True\n",
    "        while found_at_current_round:\n",
    "            found_at_current_round = False\n",
    "            for t in range(0, len(all_JH_values)):\n",
    "                if all_JH_values[t] > 100 or all_JH_values[t] == float(\"inf\"):  huge_values += 1\n",
    "                if all_JH_values[t] < 0   or all_JH_values[t] == float(\"-inf\"): negative_values += 1\n",
    "                if np.isnan(all_JH_values[t]): nan_values += 1\n",
    "                if all_JH_values[t]>100 or all_JH_values[t]<0 or np.isnan(all_JH_values[t]) or all_JH_values[t]==float(\"inf\") or all_JH_values[t]==float(\"-inf\"):\n",
    "                    found_at_current_round = True\n",
    "                    del all_JH_values[t]\n",
    "                    if len(all_Time_values) > 0: del all_Time_values[t]\n",
    "                    if len(all_MagLat_values) > 0: del all_MagLat_values[t]\n",
    "                    if len(all_MLT_values) > 0: del all_MLT_values[t]\n",
    "                    if len(all_Altitude_values) > 0: del all_Altitude_values[t]\n",
    "                    if len(all_Lat_values) > 0: del all_Lat_values[t]\n",
    "                    if len(all_Kp_values) > 0: del all_Kp_values[t]\n",
    "                    break\n",
    "        print( \"Globaly\", \":\",  \"huge values =\", huge_values, \"negative values =\", negative_values, \"nan values =\", nan_values )\n",
    "        print(\"ALL\", \"LENGTH AFTER:\", len(all_JH_values))\n",
    "    else:\n",
    "        print( \"NO correct value check:\", SELECTED_VARIABLE , filepath )\n",
    "    ########\n",
    "    CalculateStatsOnData()\n",
    "    print( \"Results loaded for\", SELECTED_VARIABLE_longname, \"    \", datetime.now(), \"\\n\" )\n",
    "\n",
    "    \n",
    "def concatLists( a, b ):\n",
    "    for item in b:\n",
    "        a.append( item )    \n",
    "    \n",
    "    \n",
    "    \n",
    "def LoadResults( filename ):\n",
    "    global CALCULATIONS_Title, CALCULATIONS_Description, CALCULATIONS_RegionName, CALCULATIONS_OrbitFilesPath, CALCULATIONS_TIEGCMfolder, CALCULATIONS_ExecutionDuration\n",
    "    global all_JH_values, all_MagLat_values, all_MLT_values, all_Altitude_values\n",
    "    if len(filename) > 0:\n",
    "        CALCULATIONS_ResultsFilename = ResultsFilename = filename\n",
    "        with open(CALCULATIONS_ResultsFilename, 'r') as F:\n",
    "            for line in F:\n",
    "                if line[0:1] == '#': # this line contains a comment, print it as it is.\n",
    "                    print ( line[1:len(line)-1] )\n",
    "                    if line.startswith(\"# Title:\"): CALCULATIONS_Title = line[8:].strip()\n",
    "                    if line.startswith(\"# Description:\"): CALCULATIONS_Description = line[14:].strip()\n",
    "                    if line.startswith(\"# Region:\"): CALCULATIONS_RegionName = line[9:].strip()\n",
    "                    if line.startswith(\"# Orbit Filename:\"): CALCULATIONS_OrbitFilesPath = line[17:].strip()\n",
    "                    if line.startswith(\"# DataPath\"): CALCULATIONS_TIEGCMfolder = line[10:].strip()\n",
    "                elif line.startswith( \"All JH values\" ) :\n",
    "                    all_JH_values = line[line.find(\":\")+1:].split(',')\n",
    "                    all_JH_values = [float(i) for i in all_JH_values]\n",
    "                elif line.startswith( \"All MagLat values\" ) :\n",
    "                    all_MagLat_values = line[line.find(\":\")+1:].split(',')\n",
    "                    all_MagLat_values = [float(i) for i in all_MagLat_values]\n",
    "                elif line.startswith( \"All MLT values\" ) :\n",
    "                    all_MLT_values = line[line.find(\":\")+1:].split(',')\n",
    "                    all_MLT_values = [float(i) for i in all_MLT_values]\n",
    "                elif line.startswith( \"All Altitude values\" ) :\n",
    "                    all_Altitude_values = line[line.find(\":\")+1:].split(',')\n",
    "                    all_Altitude_values = [float(i) for i in all_Altitude_values]                    \n",
    "                elif line.startswith( \"BIN\" ):\n",
    "                    head_of_line = line[0:20]\n",
    "                    bin_id = head_of_line[ 4: head_of_line.find(':') ]\n",
    "                    B = getBinByItsID( bin_id )\n",
    "                    data_str = line[line.find(\"=\")+1:-1].strip()\n",
    "                    if len( data_str ) > 0:\n",
    "                        values = data_str.split(',')\n",
    "                        values = [float(i) for i in values]\n",
    "                    else:\n",
    "                        values = list()\n",
    "                    if   \"MagLat\"   in head_of_line: \n",
    "                        B.MagLat_values   = values\n",
    "                    elif \"MLT\"      in head_of_line: \n",
    "                        B.MLT_values      = values\n",
    "                    elif \"Altitude\" in head_of_line: \n",
    "                        B.Altitude_values = values    \n",
    "                else: # this line contains bin info, print it and store them in the correct bin.\n",
    "                    s = line[:220]\n",
    "                    if s[-1] == '\\n': s = s[:-1]\n",
    "                    print ( s )\n",
    "                    aBinID = line[:line.find(\":\")].strip()\n",
    "                    ##\n",
    "                    str_JH = line[line.find(\"JH_values=\")+10:-1]\n",
    "                    if len( str_JH.strip() ) > 0:\n",
    "                        aBinJH_values = str_JH.split(',')\n",
    "                        aBinJH_values = [float(i) for i in aBinJH_values]\n",
    "                        for B in Bins:\n",
    "                            if B.ID == aBinID:\n",
    "                                B.JH_values = aBinJH_values\n",
    "                                break\n",
    "        F.close()\n",
    "        CalculateStatsOnData()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "@cuda.jit\n",
    "def Match(MAGLATs, MLTs, ALTs, KPs, JHs,   MagLat_min, MagLat_max, MLT_min,MLT_max, Altitude_min,Altitude_max, Kp_min,Kp_max,   out):\n",
    "    length_time =  60\n",
    "    length_lev  =  57\n",
    "    length_lat  =  72\n",
    "    length_lon  = 144\n",
    "    num_of_blocks  = cuda.gridDim.x   # number of blocks in the grid\n",
    "    num_of_threads = cuda.blockDim.x  # number of threads per block\n",
    "    BlockIDX  = cuda.blockIdx.x  # this is the unique block ID within the 1D grid\n",
    "    ThreadIDX = cuda.threadIdx.x # this is the unique thread ID within a 1D block\n",
    "    #start = tx + ty * block_size\n",
    "    #stride = block_size * grid_size\n",
    "    BlockStep  = int(length_lat/num_of_blocks)+1\n",
    "    ThreadStep = int(length_lon/num_of_threads)+1\n",
    "    for idx_lat in range( BlockIDX*BlockStep,  BlockIDX*BlockStep + BlockStep):\n",
    "        if idx_lat >= length_lat: continue\n",
    "        for idx_lon in range( ThreadIDX*ThreadStep,  ThreadIDX*ThreadStep + ThreadStep):\n",
    "            if idx_lon >= length_lon: continue\n",
    "            for idx_lev in range(0, length_lev):\n",
    "                if idx_lev >= length_lev: continue\n",
    "                for idx_time in range(0, length_time):\n",
    "                    if idx_time >= length_time: continue\n",
    "                    if MAGLATs[idx_time, idx_lev, idx_lat, idx_lon]      >= MagLat_min       and MAGLATs[idx_time, idx_lev, idx_lat, idx_lon] <= MagLat_max:\n",
    "                        if ALTs[idx_time, idx_lev, idx_lat, idx_lon] >= Altitude_min     and ALTs[idx_time, idx_lev, idx_lat, idx_lon]    <= Altitude_max:\n",
    "                            if KPs[idx_time] >= Kp_min and KPs[idx_time] <= Kp_max:\n",
    "                                is_MLT_in_range = False\n",
    "                                if MLT_min <= MLT_max: # example: from 13 to 18 hour\n",
    "                                    if MLTs[idx_time, idx_lev, idx_lat, idx_lon] >= MLT_min and MLTs[idx_time, idx_lev, idx_lat, idx_lon] <= MLT_max: is_MLT_in_range = True\n",
    "                                else: # example: from 22 to 3 hour\n",
    "                                    if MLTs[idx_time, idx_lev, idx_lat, idx_lon] > MLT_min or MLTs[idx_time, idx_lev, idx_lat, idx_lon] <= MLT_max: is_MLT_in_range = True\n",
    "                                if is_MLT_in_range: out[idx_time, idx_lev, idx_lat, idx_lon] = JHs[idx_time, idx_lev, idx_lat, idx_lon]\n",
    "\n",
    "def AssignJouleHeatingValuesToBins_CUDA( DataFilesPath ): # MagLat MagLoacalTime Kp Alt\n",
    "    startSecs = time.time()        \n",
    "    MagLat_min =  1000\n",
    "    MagLat_max = -1000\n",
    "    MLT_min    =  1000\n",
    "    MLT_max    = -1000\n",
    "    Altitude_min    =  1000\n",
    "    Altitude_max    = -1000\n",
    "    Lat_min     =  1000\n",
    "    Lat_max     = -1000\n",
    "    Kp_min     =  1000\n",
    "    Kp_max     = -1000\n",
    "    for B in Bins:\n",
    "        B.reset()\n",
    "        if B.MagLat_min < MagLat_min: MagLat_min = B.MagLat_min \n",
    "        if B.MagLat_max > MagLat_max: MagLat_max = B.MagLat_max\n",
    "        if B.MLT_min < MLT_min: MLT_min = B.MLT_min \n",
    "        if B.MLT_max > MLT_max: MLT_max = B.MLT_max\n",
    "        if B.Altitude_min < Altitude_min: Altitude_min = B.Altitude_min \n",
    "        if B.Altitude_max > Altitude_max: Altitude_max = B.Altitude_max\n",
    "        if B.Kp_min < Kp_min: Kp_min = B.Kp_min \n",
    "        if B.Kp_max > Kp_max: Kp_max = B.Kp_max            \n",
    "        \n",
    "    Matches = 0\n",
    "    \n",
    "    AllDataFiles = sorted( glob.glob( DataFilesPath + \"*/*.nc\", recursive=True ) )\n",
    "    for currentDataFile in AllDataFiles:\n",
    "        print( \"Reading\", currentDataFile )\n",
    "        try:\n",
    "            CDFroot = Dataset( currentDataFile, 'r' )\n",
    "        except:\n",
    "            print ( \"WRONG FORMAT:\", currentDataFile )\n",
    "            continue\n",
    "        try:\n",
    "            FileStartTimeStamp = calendar.timegm( datetime.strptime( CDFroot.variables['time'].units[14:],  \"%Y-%m-%d %H:%M:%S\" ).utctimetuple() ) # ex: \"minutes since 2015-1-1 0:0:0\"    FileStartTimeStamp = calendar.timegm( datetime.strptime( \"minutes since 2015-1-1 0:0:0\"[14:],  \"%Y-%m-%d %H:%M:%S\" ).utctimetuple() )\n",
    "        except:\n",
    "            print ( \"WRONG CONTENTS:\", currentDataFile )\n",
    "            continue            \n",
    "        length_time = CDFroot.variables['Ohmic'].shape[0]\n",
    "        length_lev  = CDFroot.variables['Ohmic'].shape[1]\n",
    "        length_lat  = CDFroot.variables['Ohmic'].shape[2]\n",
    "        length_lon  = CDFroot.variables['Ohmic'].shape[3]\n",
    "        \n",
    "        # Load or calculate all basic values from the netcdf file\n",
    "        print (\"Loading file into memory\")\n",
    "        TIMEs   = CDFroot.variables['time'][:] # minutes since the start time\n",
    "        LATs    = CDFroot.variables['lat'][:] \n",
    "        MAGLATs = CDFroot.variables['mlat_qdf'][:, :, :, :] \n",
    "        MLTs    = CDFroot.variables['mlt_qdf'][:, :, :, :]         \n",
    "        ALTs    = CDFroot.variables['ZGMID'][:, :, :, :] / 100000 # it is stored in cm inside the file\n",
    "        KPs     = CDFroot.variables['Kp'][:]\n",
    "        JHs     = CDFroot.variables['Ohmic'][:, :, :, :]\n",
    "        EEXs    = CDFroot.variables['EEX_si'][:, :, :, :] \n",
    "        EEYs    = CDFroot.variables['EEY_si'][:, :, :, :] \n",
    "        PEDs    = CDFroot.variables['SIGMA_PED'][:, :, :, :] \n",
    "        HALs    = CDFroot.variables['SIGMA_HAL'][:, :, :, :] \n",
    "\n",
    "        \n",
    "        print( \"Invoking CUDA\" )\n",
    "        MAGLATs = np.array( MAGLATs, dtype=\"float32\" )\n",
    "        MLTs = np.array( MLTs, dtype=\"float32\" )        \n",
    "        ALTs = np.array( ALTs, dtype=\"float32\" )\n",
    "        KPs = np.array( KPs, dtype=\"float32\" )\n",
    "        JHs = np.array( JHs, dtype=\"float32\" )\n",
    "        out = np.zeros(  [length_time, length_lev, length_lat, length_lon]  )\n",
    "        blocks_per_grid = (16)\n",
    "        threads_per_block = (32)\n",
    "        Match[blocks_per_grid, threads_per_block](MAGLATs, MLTs, ALTs, KPs, JHs,   MagLat_min, MagLat_max, MLT_min,MLT_max, Altitude_min,Altitude_max, Kp_min,Kp_max,   out)\n",
    "        #device_out.copy_to_host()\n",
    "        print( \"Positions in Bins:\", np.count_nonzero(out), \"/\" , out.size)\n",
    "        \n",
    "        for idx_lat in range(0, length_lat):\n",
    "            for idx_lon in range(0, length_lon):\n",
    "                for idx_lev in range(0, length_lev):\n",
    "                    for idx_time in range(0, length_time):\n",
    "                        if out[idx_time, idx_lev, idx_lat ,idx_lon] != 0:\n",
    "                            current_MLT      = MLTs[idx_time, idx_lev, idx_lat ,idx_lon]\n",
    "                            current_MagLat   = MAGLATs[idx_time, idx_lev, idx_lat ,idx_lon]\n",
    "                            current_Altitude = ALTs[idx_time, idx_lev, idx_lat ,idx_lon]\n",
    "                            current_Kp       = KPs[idx_time]\n",
    "                            current_Lat      = LATs[ idx_lat ]\n",
    "                            matchedBin = GetMatchedBin( current_MLT, current_MagLat, current_Altitude, current_Kp, current_Lat )\n",
    "                            if matchedBin is not None:\n",
    "                                current_timestamp = FileStartTimeStamp + TIMEs[idx_time]*120*60\n",
    "                                current_JH = JHs[idx_time, idx_lev, idx_lat ,idx_lon] #CDFroot.variables['Joule Heating'][idx_time, idx_lev, idx_lat, idx_lon]\n",
    "                                matchedBin.JH_values.append( current_JH )\n",
    "                                matchedBin.MagLat_values.append( current_MagLat )\n",
    "                                matchedBin.MLT_values.append( current_MLT )\n",
    "                                matchedBin.Altitude_values.append( current_Altitude )\n",
    "                                matchedBin.Kp_values.append( current_Kp )\n",
    "                                matchedBin.Time_values.append( current_timestamp )    \n",
    "                                matchedBin.EEX_values.append( EEXs[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                matchedBin.EEY_values.append( EEYs[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                matchedBin.Pedersen_values.append( PEDs[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                matchedBin.Hall_values.append( HALs[ idx_time, idx_lev, idx_lat, idx_lon ] )                                 \n",
    "                                all_JH_values.append( current_JH )\n",
    "                                all_MagLat_values.append( current_MagLat )\n",
    "                                all_MLT_values.append( current_MLT )\n",
    "                                all_Altitude_values.append( current_Altitude )\n",
    "                                all_Kp_values.append( current_Kp )\n",
    "                                all_Time_values.append( current_timestamp )                                \n",
    "                                all_HittedBin_IDs.append( matchedBin.ID )\n",
    "                                all_EEX_values.append( EEXs[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                all_EEY_values.append( EEYs[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                all_Pedersen_values.append( PEDs[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                all_Hall_values.append( HALs[ idx_time, idx_lev, idx_lat, idx_lon ] )                                \n",
    "                                Matches += 1\n",
    "        \n",
    "        CDFroot.close()\n",
    "        print( Matches, \" matches so far.\" )\n",
    "    finishSecs = time.time()\n",
    "    print( finishSecs-startSecs, \" sec\")    \n",
    "    print( Matches, \"points have been assigned into bins\" )\n",
    "\n",
    "            \n",
    "#######################            #######################            #######################            \n",
    "                    #######################            #######################            \n",
    "def AssignJouleHeatingValuesToBins( DataFilesPath ):\n",
    "    global all_JH_values, all_MagLat_values, all_MLT_values, all_Altitude_values, all_Lat_values, all_Kp_values, all_Time_values, all_HittedBin_IDs  , all_EEX_values, all_EEY_values, all_Pedersen_values, all_Hall_values\n",
    "    startSecs = time.time()\n",
    "    MagLat_min =  1000\n",
    "    MagLat_max = -1000\n",
    "    MLT_min    =  1000\n",
    "    MLT_max    = -1000\n",
    "    Altitude_min    =  1000\n",
    "    Altitude_max    = -1000\n",
    "    Lat_min     =  1000\n",
    "    Lat_max     = -1000    \n",
    "    Kp_min     =  1000\n",
    "    Kp_max     = -1000\n",
    "    for B in Bins:\n",
    "        B.reset()\n",
    "        if B.MagLat_min < MagLat_min: MagLat_min = B.MagLat_min \n",
    "        if B.MagLat_max > MagLat_max: MagLat_max = B.MagLat_max\n",
    "        if B.MLT_min < MLT_min: MLT_min = B.MLT_min \n",
    "        if B.MLT_max > MLT_max: MLT_max = B.MLT_max\n",
    "        if B.Altitude_min < Altitude_min: Altitude_min = B.Altitude_min \n",
    "        if B.Altitude_max > Altitude_max: Altitude_max = B.Altitude_max\n",
    "        if B.Lat_min < Lat_min: Lat_min = B.Lat_min \n",
    "        if B.Lat_max > Lat_max: Lat_max = B.Lat_max                        \n",
    "        if B.Kp_min < Kp_min: Kp_min = B.Kp_min \n",
    "        if B.Kp_max > Kp_max: Kp_max = B.Kp_max            \n",
    "        \n",
    "    Matches = 0\n",
    "\n",
    "    # read the results file and find out until which TIEGCM file's data have been processed into it\n",
    "    ResultsFilename = DaedalusGlobals.CoverageResults_Files_Path + BinGroups_Dropdown.value + \".\" + CALCULATIONS_TIEGCMfolder[CALCULATIONS_TIEGCMfolder[:-1].rfind('/')+1:-1] + \".ValuesPerBinResults.nc\"\n",
    "    if path.exists( ResultsFilename ):\n",
    "        resultsCDF = Dataset( ResultsFilename, 'r' )\n",
    "        Progress = resultsCDF.Progress.strip()\n",
    "        resultsCDF.close()\n",
    "        if len(Progress) == 0:\n",
    "            skip = False\n",
    "        else:\n",
    "            skip = True\n",
    "    else:\n",
    "        CreateResults_CDF( ResultsFilename )\n",
    "        skip = False\n",
    "    \n",
    "    AllDataFiles = sorted( glob.glob( DataFilesPath + \"*/*.nc\", recursive=True ) )\n",
    "    for currentDataFile in AllDataFiles:\n",
    "        # skip the files which have already been processed inti the results file\n",
    "        if skip == True: \n",
    "            if currentDataFile.strip()==Progress: skip = False\n",
    "            print( \"\\nSkiping Data file:\", currentDataFile)\n",
    "            continue # <<< this file has been parsed, go on\n",
    "        # reset state\n",
    "        all_JH_values       = list()\n",
    "        all_MagLat_values   = list() \n",
    "        all_MLT_values      = list() \n",
    "        all_Altitude_values = list() \n",
    "        all_Lat_values      = list()\n",
    "        all_Kp_values       = list() \n",
    "        all_Time_values     = list()\n",
    "        all_HittedBin_IDs   = list()\n",
    "        all_EEX_values      = list()\n",
    "        all_EEY_values      = list()\n",
    "        all_Pedersen_values = list()\n",
    "        all_Hall_values     = list()\n",
    "        for B in Bins:\n",
    "            B.reset()\n",
    "            \n",
    "        # parse TIEGCM file\n",
    "        print( \"Reading\", currentDataFile )\n",
    "        try:\n",
    "            CDFroot = Dataset( currentDataFile, 'r' )\n",
    "        except:\n",
    "            print ( \"WRONG FORMAT:\", currentDataFile )\n",
    "            continue\n",
    "        try:\n",
    "            FileStartTimeStamp = calendar.timegm( datetime.strptime( CDFroot.variables['time'].units[14:],  \"%Y-%m-%d %H:%M:%S\" ).utctimetuple() ) # ex: \"minutes since 2015-1-1 0:0:0\"\n",
    "        except:\n",
    "            print ( \"WRONG CONTENTS:\", currentDataFile )\n",
    "            continue                    \n",
    "        length_time = CDFroot.variables['Ohmic'].shape[0]\n",
    "        length_lev  = CDFroot.variables['Ohmic'].shape[1]\n",
    "        length_lat  = CDFroot.variables['Ohmic'].shape[2]\n",
    "        length_lon  = CDFroot.variables['Ohmic'].shape[3]\n",
    "        # Load or calculate all basic values from the netcdf file\n",
    "        print (\"Loading file into memory\")\n",
    "        TIMEs   = CDFroot.variables['time'][:] # minutes since the start time\n",
    "        LATs    = CDFroot.variables['lat'][:] \n",
    "        ALTs    = CDFroot.variables['ZGMID'][:, :, :, :] / 100000 # it is stored in cm inside the file\n",
    "        JHs     = CDFroot.variables['Ohmic'][:, :, :, :]\n",
    "        KPs     = CDFroot.variables['Kp'][:]\n",
    "        MAGLATs = CDFroot.variables['mlat_qdf'][:, :, :, :] \n",
    "        MLTs    = CDFroot.variables['mlt_qdf'][:, :, :, :] \n",
    "        EEXs    = CDFroot.variables['EEX_si'][:, :, :, :] \n",
    "        EEYs    = CDFroot.variables['EEY_si'][:, :, :, :] \n",
    "        PEDs    = CDFroot.variables['SIGMA_PED'][:, :, :, :] \n",
    "        HALs    = CDFroot.variables['SIGMA_HAL'][:, :, :, :] \n",
    "\n",
    "        step = 1\n",
    "        for idx_lat in range(0, length_lat, step):\n",
    "            if idx_lat%30==0: print(\"Calculating Lat\",  idx_lat)\n",
    "            for idx_lon in range(0, length_lon, step):\n",
    "                for idx_lev in range(0, length_lev, step):\n",
    "                    for idx_time in range(0, length_time, step):\n",
    "                        in_Altitude_range = in_MagLat_range = in_MLT_range = in_Kp_range = in_Lat_range = False\n",
    "                        \n",
    "                        current_Altitude = ALTs[idx_time, idx_lev, idx_lat, idx_lon]\n",
    "                        if current_Altitude >= Altitude_min and current_Altitude <= Altitude_max:\n",
    "                                in_Altitude_range = True\n",
    "                        \n",
    "                        if in_Altitude_range:\n",
    "                            #current_Latitude  = LATs[ idx_lat ]    current_Longitude = LONs[ idx_lon ]     geodetic_Latitude = Conversions.geo_lat2geod_lat( current_Latitude )    TimeObj = datetime.fromtimestamp( FileStartTimeStamp + 60*TIMEs[idx_time], tz=timezone.utc )       current_MagLat, current_MagLon, current_MLT = Conversions.getMagneticProperties( TimeObj, geodetic_Latitude, current_Longitude, current_Altitude )\n",
    "                            current_MagLat = MAGLATs[ idx_time, idx_lev, idx_lat, idx_lon ]\n",
    "                            if current_MagLat >= MagLat_min and current_MagLat <= MagLat_max:\n",
    "                                in_MagLat_range = True\n",
    "                                \n",
    "                        if in_MagLat_range:\n",
    "                            current_MLT = MLTs[ idx_time, idx_lev, idx_lat, idx_lon ]\n",
    "                            if in_MagLat_range:\n",
    "                                in_MLT_range = is_MLT_inside_range( current_MLT, MLT_min, MLT_max )\n",
    "                        \n",
    "                        if in_MLT_range:\n",
    "                            current_Kp = KPs[idx_time]\n",
    "                            if current_Kp >= Kp_min and current_Kp <= Kp_max:\n",
    "                                in_Kp_range = True   \n",
    "                                \n",
    "                        if in_Kp_range: \n",
    "                            current_Lat = LATs[ idx_lat ]\n",
    "                            if current_Lat >= Lat_min and current_Lat <= Lat_max: in_Lat_range = True   \n",
    "                        ##\n",
    "                        if in_Lat_range:\n",
    "                            matchedBin = GetMatchedBin( current_MLT, current_MagLat, current_Altitude, current_Kp, current_Lat )\n",
    "                            if matchedBin is not None:\n",
    "                                current_time = int( FileStartTimeStamp + TIMEs[idx_time]*120*60 )\n",
    "                                current_JH = JHs[idx_time, idx_lev, idx_lat ,idx_lon] #CDFroot.variables['Joule Heating'][idx_time, idx_lev, idx_lat, idx_lon]\n",
    "                                matchedBin.JH_values.append( current_JH )\n",
    "                                matchedBin.MagLat_values.append( current_MagLat )\n",
    "                                matchedBin.MLT_values.append( current_MLT )\n",
    "                                matchedBin.Altitude_values.append( current_Altitude )\n",
    "                                matchedBin.Kp_values.append( current_Kp )\n",
    "                                matchedBin.Time_values.append( current_time )\n",
    "                                matchedBin.EEX_values.append( EEXs[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                matchedBin.EEY_values.append( EEYs[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                matchedBin.Pedersen_values.append( PEDs[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                matchedBin.Hall_values.append( HALs[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                all_JH_values.append( current_JH )\n",
    "                                all_MagLat_values.append( current_MagLat )\n",
    "                                all_MLT_values.append( current_MLT )\n",
    "                                all_Altitude_values.append( current_Altitude )\n",
    "                                all_Kp_values.append( current_Kp )\n",
    "                                all_Time_values.append( current_time )\n",
    "                                all_HittedBin_IDs.append( matchedBin.ID )\n",
    "                                all_EEX_values.append( EEXs[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                all_EEY_values.append( EEYs[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                all_Pedersen_values.append( PEDs[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                all_Hall_values.append( HALs[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                Matches += 1\n",
    "                            else:\n",
    "                                print( \"PARADOX at:\", current_MLT, current_MagLat, current_Altitude, current_Kp, \" :: \", idx_time, idx_lev, idx_lat, idx_lon )\n",
    "                #break\n",
    "            #break\n",
    "        CDFroot.close()\n",
    "        SaveResults_CDF( ResultsFilename, currentDataFile )\n",
    "    finishSecs = time.time()\n",
    "    print( finishSecs-startSecs, \" sec\")    \n",
    "    print( Matches, \"points have been assigned into bins\" )\n",
    "    return ResultsFilename\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "TIEGCM_filesPath: the folder which has all TIEGCM netcdf files describing Earth's enviroment during the orbit's duration\n",
    "OrbitFilesPath: the folder which has all netCDF files which contain all the positions of the satellite \n",
    "'''    \n",
    "def AssignJouleHeatingValuesToBins_AlongOrbit( TIEGCM_filesPath, Orbit_filesPath ): # MagLat MagLoacalTime Kp Alt \n",
    "    # initialize\n",
    "    MagLat_min =  1000\n",
    "    MagLat_max = -1000\n",
    "    MLT_min    =  1000\n",
    "    MLT_max    = -1000\n",
    "    Altitude_min    =  1000\n",
    "    Altitude_max    = -1000\n",
    "    Lat_min     =  1000\n",
    "    Lat_max     = -1000\n",
    "    Kp_min     =  1000\n",
    "    Kp_max     = -1000\n",
    "    for B in Bins:\n",
    "        B.reset()\n",
    "        if B.MagLat_min < MagLat_min: MagLat_min = B.MagLat_min \n",
    "        if B.MagLat_max > MagLat_max: MagLat_max = B.MagLat_max\n",
    "        if B.MLT_min < MLT_min: MLT_min = B.MLT_min \n",
    "        if B.MLT_max > MLT_max: MLT_max = B.MLT_max\n",
    "        if B.Altitude_min < Altitude_min: Altitude_min = B.Altitude_min \n",
    "        if B.Altitude_max > Altitude_max: Altitude_max = B.Altitude_max\n",
    "        if B.Lat_min < Lat_min: Lat_min = B.Lat_min \n",
    "        if B.Lat_max > Lat_max: Lat_max = B.Lat_max                                \n",
    "        if B.Kp_min < Kp_min: Kp_min = B.Kp_min \n",
    "        if B.Kp_max > Kp_max: Kp_max = B.Kp_max                    \n",
    "    # miscellaneous\n",
    "    currentfilenumber = -1        \n",
    "    Matches = 0\n",
    "    Errors  = 0\n",
    "    # information about the TIEGCM files\n",
    "    TIEGCMfilenamePrefix  = \"tiegcm2.0_res2.5_3years_sech_\" \n",
    "    TIEGCMfilenamePostfix = \"_JH_QD_AllVars\"\n",
    "\n",
    "    # read orbit file\n",
    "    current_timestamp_offset = 0 # increases after each satellite position is parsed\n",
    "    AllOrbitFiles = sorted( glob.glob( Orbit_filesPath + \"*Batch*.nc\" ) )\n",
    "    for currentOrbitFile in AllOrbitFiles:\n",
    "        current_timestamp_offset = 0 # reseted ONLY when the orbits of 2 satellites are inside the folder (one file each)\n",
    "        print( \"\\nReading Orbit file:\", currentOrbitFile )\n",
    "        try:\n",
    "            Orbit_CDF = Dataset( currentOrbitFile, 'r' )\n",
    "        except:\n",
    "            print ( \"WRONG FORMAT:\", currentDataFile )\n",
    "            continue\n",
    "        # Load data from the netCDF file\n",
    "        ORBIT_Times      = Orbit_CDF.variables['time'][:]\n",
    "        ORBIT_MagLats    = Orbit_CDF.variables['DaedalusMagneticLatitude'][:]\n",
    "        ORBIT_MLTs       = Orbit_CDF.variables['DaedalusMLT'][:]\n",
    "        ORBIT_Altitudes  = Orbit_CDF.variables['ZGMID'][:] / 100000\n",
    "        ORBIT_Lats       = Orbit_CDF.variables['lat'][:]\n",
    "        ORBIT_Ohmic      = Orbit_CDF.variables['Ohmic'][:]\n",
    "        ORBIT_Density    = Orbit_CDF.variables['DEN'][:]\n",
    "        try:\n",
    "            ORBIT_Lev    = Orbit_CDF.variables['lev'][:]\n",
    "        except:\n",
    "            ORBIT_Lev    = list()\n",
    "        try:\n",
    "            ORBIT_ConvH  = Orbit_CDF.variables['Convection_heating'][:]\n",
    "        except:\n",
    "            ORBIT_ConvH  = Orbit_CDF.variables['Convenction_heating'][:]\n",
    "        ORBIT_WindH      = Orbit_CDF.variables['Wind_heating'][:]\n",
    "        try: \n",
    "            ORBIT_EEX    = Orbit_CDF.variables['EEX_si'][:] \n",
    "        except: \n",
    "            ORBIT_EEX    = list()\n",
    "        try: \n",
    "            ORBIT_EEY    = Orbit_CDF.variables['EEY_si'][:] \n",
    "        except: \n",
    "            ORBIT_EEY    = list()  \n",
    "        try: \n",
    "            ORBIT_Pedersen = Orbit_CDF.variables['SIGMA_PED'][:] \n",
    "        except: \n",
    "            ORBIT_Pedersen = list()            \n",
    "        try: \n",
    "            ORBIT_Hall    = Orbit_CDF.variables['SIGMA_HAL'][:] \n",
    "        except: \n",
    "            ORBIT_Hall    = list()\n",
    "            \n",
    "        try:\n",
    "            orbit_start_datetime = datetime.strptime(Orbit_CDF.variables['time'].UNITS[14:], '%d %b %Y %H:%M:%S.%f')\n",
    "        except:\n",
    "            orbit_start_datetime = datetime.strptime(\"Seconds Since 1 Jan 2015 00:00:00.000\"[14:], '%d %b %Y %H:%M:%S.%f')\n",
    "            print(\"!!! ERROR while reading units of time inside NetCDF file. Assumed default value: 'Seconds Since 1 Jan 2015 00:00:00.000'\")\n",
    "        orbit_start_timestamp = calendar.timegm(orbit_start_datetime.utctimetuple())\n",
    "        orbit_timestamp_step = ORBIT_Times[1] - ORBIT_Times[0]\n",
    "        print( \"orbit_timestamp_step =\", orbit_timestamp_step )\n",
    "        num_of_positions =  len(ORBIT_Times)\n",
    "        # read the satellite positions and try to fill the bins\n",
    "        for idx in range(0, num_of_positions): # for each satellite position\n",
    "            if idx % 200000 == 0: print (\"Checking sat position No\", idx, \"of\", num_of_positions)\n",
    "            in_Altitude_range = in_MagLat_range = in_MLT_range = in_Lat_range = in_Kp_range = False\n",
    "                      \n",
    "            # check if this position lies inside some bin\n",
    "            current_Altitude = ORBIT_Altitudes[ idx ]\n",
    "            if current_Altitude >= Altitude_min and current_Altitude <= Altitude_max: in_Altitude_range = True\n",
    "            #\n",
    "            if in_Altitude_range:\n",
    "                current_MagLat = ORBIT_MagLats[ idx ]\n",
    "                if current_MagLat >= MagLat_min and current_MagLat <= MagLat_max: in_MagLat_range = True\n",
    "            #\n",
    "            if in_MagLat_range:\n",
    "                current_MLT = ORBIT_MLTs[ idx ]\n",
    "                in_MLT_range = is_MLT_inside_range( current_MLT, MLT_min, MLT_max )\n",
    "                \n",
    "            # \n",
    "            if in_MLT_range: \n",
    "                current_Lat = ORBIT_Lats[ idx ]\n",
    "                if current_Lat >= Lat_min and current_Lat <= Lat_max: in_Lat_range = True\n",
    "                    \n",
    "            if in_Lat_range==False:\n",
    "                current_MagLat = ORBIT_MagLats[ idx ]\n",
    "                current_MLT = ORBIT_MLTs[ idx ]\n",
    "                current_Lat = ORBIT_Lats[ idx ]\n",
    "                if idx % 200000 == 0: print( \"ALT:\",current_Altitude, \"MAGLAT:\", current_MagLat, \"MLT:\", current_MLT, \"LAT:\",current_Lat )\n",
    "\n",
    "            # The position is probably inside a bin (only kp remains to be checked). \n",
    "            # Open the corresponding TIEGCM file to read the kp and if position is in bin then calculate JH\n",
    "            if in_Lat_range:\n",
    "                current_timestamp = orbit_start_timestamp + current_timestamp_offset\n",
    "                current_datetime  = datetime.utcfromtimestamp( current_timestamp )\n",
    "                \n",
    "                # Locate the corresponding TIEGCM file and timestep inside the file\n",
    "                # one TIEGCM file contains 60 timesteps, 1 per 120min. The file's duration is 5 days. Each year consists of 74 files (the last file is smaller)\n",
    "                start_of_current_year_datetime  = datetime.strptime(\"01 Jan \" + str(current_datetime.year) + \" 00:00:00\", '%d %b %Y %H:%M:%S')\n",
    "                start_of_current_year_timestamp = calendar.timegm(start_of_current_year_datetime.utctimetuple())\n",
    "                newfilenumber = int(  ( (current_timestamp - start_of_current_year_timestamp)/(60*120) ) / 60  ) \n",
    "                tmp = (current_timestamp - start_of_current_year_timestamp)/(60*120) - newfilenumber*60 \n",
    "                timestep_number = int( tmp )\n",
    "                if tmp - float(timestep_number) > 0.5: timestep_number += 1 # select the nearest neighbor\n",
    "                if  ( current_timestamp==start_of_current_year_timestamp  or  (current_timestamp - start_of_current_year_timestamp)/(60*120) ) % 60  !=  0: newfilenumber += 1 # file numbers start from 1\n",
    "                if current_datetime.year == 2016: newfilenumber += 74\n",
    "                if current_datetime.year == 2017: newfilenumber += 148\n",
    "                \n",
    "                # open the TIEGCM file if necessary\n",
    "                if currentfilenumber < 0   or   currentfilenumber != newfilenumber:\n",
    "                    if currentfilenumber >= 0: tiegcm_CDF.close()\n",
    "                    TIEGCMfilename = TIEGCM_filesPath + \"TIEGCM_\" + str(current_datetime.year) + \"/\" + TIEGCMfilenamePrefix + \"{:03.0f}\".format(newfilenumber) + TIEGCMfilenamePostfix + \".nc\"\n",
    "                    currentfilenumber = newfilenumber\n",
    "                    print(  \"Opening TIEGCMfile:\", TIEGCMfilename)\n",
    "                    try:\n",
    "                        tiegcm_CDF = Dataset( TIEGCMfilename, 'r' )\n",
    "                    except:\n",
    "                        print ( \"FILE NOT FOUND OR WRONG FORMAT:\", TIEGCMfilename )\n",
    "                        continue\n",
    "                        \n",
    "                # read Kp from the tiegcm file\n",
    "                try:\n",
    "                    current_Kp = tiegcm_CDF.variables['Kp'][timestep_number]\n",
    "                except:\n",
    "                    #print(\"%%%%%%%%%%%%%%%%%%%%%\")\n",
    "                    #print(len(tiegcm_CDF.variables['Kp']), timestep_number)\n",
    "                    #print( current_datetime, current_timestamp, start_of_current_year_timestamp )\n",
    "                    #print(TIEGCMfilename)\n",
    "                    #print(\"%%%%%%%%%%%%%%%%%%%%%\")\n",
    "                    try:\n",
    "                        current_Kp = tiegcm_CDF.variables['Kp'][timestep_number-1]\n",
    "                    except:\n",
    "                        print( \"!!!! !!!! Timestep Error\",  timestep_number, \"of\", len(tiegcm_CDF.variables['Kp']) )\n",
    "                        continue\n",
    "                    \n",
    "                if current_Kp >= Kp_min and current_Kp <= Kp_max:\n",
    "                    in_Kp_range = True \n",
    "                    \n",
    "                # if the satellite position matches a bin then mark it as a hit and remember the JH values \n",
    "                if in_MagLat_range and in_MLT_range and in_Altitude_range and in_Kp_range:\n",
    "                    matchedBin = GetMatchedBin( current_MLT, current_MagLat, current_Altitude, current_Kp, current_Lat )\n",
    "                    if matchedBin is not None:\n",
    "                        # for this position locate the neighbor latitudes at the TIEGCM file. \n",
    "                        #lat1_idx, lat2_idx, lat1_val, lat2_val = findNeighborValues( TIEGCM_Lats, current_GeogLat )\n",
    "                        # for this position locate the neighbor longitudes at the TIEGCM file.\n",
    "                        #lon1_idx, lon2_idx, lon1_val, lon2_val = findNeighborValues( TIEGCM_Lons, current_Lon )\n",
    "                        # for this position locate the neighbor Altitudes at the TIEGCM file. \n",
    "                        #lev1_idx, lev2_idx, lev1_val, lev2_val = findNeighborValues( CDFroot.variables['ZGMID'][time_idx, :, lat_idx, lon_idx], current_Altitude )\n",
    "                        current_JH = ORBIT_Ohmic[ idx ]\n",
    "                        #if math.isnan(current_JH): \n",
    "                        #    print( \"Found JH equal with None at file \", TIEGCMfilename, \"timestep=\", timestep_number, \"altitude=\", ORBIT_Altitudes[idx], idx )\n",
    "                        #    Errors += 1\n",
    "                        #    if Errors > 20 *100000:\n",
    "                        #        print(\"Too many errors. Aborting\")\n",
    "                        #        return\n",
    "                        #    else:\n",
    "                        #        continue\n",
    "                        # save \n",
    "                        matchedBin.JH_values.append( current_JH )\n",
    "                        matchedBin.MagLat_values.append( current_MagLat )\n",
    "                        matchedBin.MLT_values.append( current_MLT )\n",
    "                        matchedBin.Altitude_values.append( current_Altitude )\n",
    "                        matchedBin.Lat_values.append( current_Lat )\n",
    "                        matchedBin.Kp_values.append( current_Kp )\n",
    "                        matchedBin.Time_values.append( current_timestamp )\n",
    "                        matchedBin.EEX_values.append( ORBIT_EEX[ idx ] ) \n",
    "                        matchedBin.EEY_values.append( ORBIT_EEY[ idx ] ) \n",
    "                        matchedBin.Pedersen_values.append( ORBIT_Pedersen[ idx ] ) \n",
    "                        matchedBin.Density_values.append( ORBIT_Density[ idx ] ) \n",
    "                        if len(ORBIT_Lev) > 0: matchedBin.Lev_values.append( ORBIT_Lev[ idx ] )\n",
    "                        matchedBin.ConvectionHeating_values.append( ORBIT_ConvH[ idx ] )\n",
    "                        matchedBin.WindHeating_values.append( ORBIT_WindH[ idx ] )\n",
    "                        if len(ORBIT_Hall) > 0: \n",
    "                            matchedBin.Hall_values.append( ORBIT_Hall[ idx ] ) \n",
    "                        all_JH_values.append( current_JH )\n",
    "                        all_MagLat_values.append( current_MagLat )\n",
    "                        all_MLT_values.append( current_MLT )\n",
    "                        all_Altitude_values.append( current_Altitude )\n",
    "                        all_Lat_values.append( current_Lat )\n",
    "                        all_Kp_values.append( current_Kp )\n",
    "                        all_Time_values.append( current_timestamp )\n",
    "                        all_HittedBin_IDs.append( matchedBin.ID )\n",
    "                        all_EEX_values.append( ORBIT_EEX[ idx ] )\n",
    "                        all_EEY_values.append( ORBIT_EEY[ idx ] )\n",
    "                        all_Pedersen_values.append( ORBIT_Pedersen[ idx ] )\n",
    "                        all_Density_values.append( ORBIT_Density[ idx ] )\n",
    "                        if len(ORBIT_Lev) > 0: all_Lev_values.append( ORBIT_Lev[ idx ] )\n",
    "                        all_ConvectionHeating_values.append( ORBIT_ConvH[ idx ] )\n",
    "                        all_WindHeating_values.append( ORBIT_WindH[ idx ] )\n",
    "                        if len(ORBIT_Hall) > 0: all_Hall_values.append( ORBIT_Hall[ idx ] )\n",
    "                        Matches += 1\n",
    "                    else:\n",
    "                        print( \"PARADOX at:\", current_MLT, current_MagLat, current_Altitude, current_Kp, \" :: \", time_idx, lev_idx, lat_idx, lon_idx )\n",
    "            current_timestamp_offset += orbit_timestamp_step\n",
    "    # clean up\n",
    "    print( Matches, \"satellite positions where matched inside bins.\" )\n",
    "    try:\n",
    "        CDFroot.close()\n",
    "    except:\n",
    "        print (\".\")\n",
    "    \n",
    "    \n",
    "    \n",
    "'''\n",
    "TIEGCM_filesPath: the folder which has all TIEGCM netcdf files describing Earth's enviroment during the orbit's duration\n",
    "OrbitFilename: csv file containing all the positions of the satellite \n",
    "'''    \n",
    "def AssignJouleHeatingValuesToBins_AlongOrbit_forCSVorbit( TIEGCM_filesPath, OrbitFilename ): # MagLat MagLoacalTime Kp Alt \n",
    "    # initialize\n",
    "    MagLat_min =  1000\n",
    "    MagLat_max = -1000\n",
    "    MLT_min    =  1000\n",
    "    MLT_max    = -1000\n",
    "    Altitude_min    =  1000\n",
    "    Altitude_max    = -1000\n",
    "    Kp_min     =  1000\n",
    "    Kp_max     = -1000\n",
    "    for B in Bins:\n",
    "        B.reset()\n",
    "        if B.MagLat_min < MagLat_min: MagLat_min = B.MagLat_min \n",
    "        if B.MagLat_max > MagLat_max: MagLat_max = B.MagLat_max\n",
    "        if B.MLT_min < MLT_min: MLT_min = B.MLT_min \n",
    "        if B.MLT_max > MLT_max: MLT_max = B.MLT_max\n",
    "        if B.Altitude_min < Altitude_min: Altitude_min = B.Altitude_min \n",
    "        if B.Altitude_max > Altitude_max: Altitude_max = B.Altitude_max\n",
    "        if B.Kp_min < Kp_min: Kp_min = B.Kp_min \n",
    "        if B.Kp_max > Kp_max: Kp_max = B.Kp_max            \n",
    "        \n",
    "    # information about the TIEGCM files\n",
    "    TIEGCMfilenamePrefix  = \"tiegcm2.0_res2.5_3years_sech_\" \n",
    "    TIEGCMfilenamePostfix = \"_JH_QD_AllVars\"\n",
    "    CDFroot = Dataset( TIEGCM_filesPath + TIEGCMfilenamePrefix + \"002\" + TIEGCMfilenamePostfix + \".nc\", 'r' )  # open a tiegcm file\n",
    "    TIEGCM_StartTimeStamp  = calendar.timegm( datetime.strptime( CDFroot.variables['time'].units[14:],  \"%Y-%m-%d %H:%M:%S\" ).utctimetuple() ) # ex: \"minutes since 2015-1-1 0:0:0\"\n",
    "    #TIEGCM_StartTimeStamp  = calendar.timegm( datetime.strptime( \"minutes since 2015-1-1 0:0:0\"[14:],  \"%Y-%m-%d %H:%M:%S\" ).utctimetuple() ) \n",
    "    TIEGCM_TimeStep_sec    = (CDFroot.variables['time'][1] - CDFroot.variables['time'][0]) * 60 # every how many seconds a measurement is stored in the file\n",
    "    TIEGCM_NumOfTimeSteps  = len( CDFroot.variables['time'][:] ) # the number of timesteps stored in the file\n",
    "    TIEGCM_Lats = CDFroot.variables['lat'][:]\n",
    "    TIEGCM_Lons = CDFroot.variables['lon'][:]\n",
    "    CDFroot.close()\n",
    "    # miscellaneous\n",
    "    currentfilenumber = -1\n",
    "    Matches = 0\n",
    "    time_idx = lat_idx = lon_idx = lev_idx = -1\n",
    "    print( \"TIEGCM UNIVERSE:\")\n",
    "    print( \"    Start Time =\", \"(UTC:\"+str(TIEGCM_StartTimeStamp)+\")\", datetime.fromtimestamp(TIEGCM_StartTimeStamp) )\n",
    "    print( \"    Time-step  =\", str(TIEGCM_TimeStep_sec)+\"sec\" + \" #steps/file =\", TIEGCM_NumOfTimeSteps, \" Duration/file =\", str(TIEGCM_NumOfTimeSteps*TIEGCM_TimeStep_sec/(60*60))+\"hours\", \"\\n\" )\n",
    "    \n",
    "    # read orbit file\n",
    "    with open( OrbitFilename ) as CSVfile:        \n",
    "        CSVreader = csv.reader( CSVfile )\n",
    "        # locate the column numnbers of interest inside the csv file\n",
    "        CSVheader = next( CSVreader )\n",
    "        Time_col     = CSVheader.index( \"Epoch(UTCG)\" ) #CSVheader.index( \"Daedalus.EpochText\" )\n",
    "        Lat_col      = CSVheader.index( \"Lat_GEOD(deg)\" ) #CSVheader.index( \"Daedalus.Latitude\" )\n",
    "        Lon_col      = CSVheader.index( \"Lon_GEOD(deg)\" ) #CSVheader.index( \"Daedalus.Longitude\" )\n",
    "        Altitude_col = CSVheader.index( \"Height_WGS84 (km)\" ) #CSVheader.index( \"Daedalus.Height\" )\n",
    "        MagLat_col   = CSVheader.index( \"Daedalus.Magnetic Latitude\" )\n",
    "        MLT_col      = CSVheader.index( \"Daedalus.MLT\" )\n",
    "        # read the satellite positions and try to fill the bins\n",
    "        line_count = 0\n",
    "        for row in CSVreader: # for each satellite position\n",
    "            line_count += 1\n",
    "            if line_count % 200000 == 0: print (\"Checking sat position No\", line_count, \"of\", row[Time_col])\n",
    "            current_GeodLat = float( row[Lat_col] )\n",
    "            current_GeogLat = float( row[Lat_col] ) # TODO: read correct column from orbit file\n",
    "            current_Lon = float( row[Lon_col] )\n",
    "            current_Altitude = float( row[Altitude_col] )\n",
    "            in_Altitude_range = in_MagLat_range = in_MLT_range = in_Kp_range = False\n",
    "                      \n",
    "            # check if this position lies inside some bin\n",
    "            current_Altitude = float( row[Altitude_col] )\n",
    "            if current_Altitude >= Altitude_min and current_Altitude <= Altitude_max:\n",
    "                in_Altitude_range = True\n",
    "            #\n",
    "            if in_Altitude_range:\n",
    "                current_MagLat = float( row[MagLat_col] )\n",
    "                if current_MagLat >= MagLat_min and current_MagLat <= MagLat_max:\n",
    "                    in_MagLat_range = True\n",
    "            #\n",
    "            if in_MagLat_range:\n",
    "                current_MLT = float( row[MLT_col] )\n",
    "                in_MLT_range = is_MLT_inside_range( current_MLT, MLT_min, MLT_max )\n",
    "\n",
    "            # The position is probably inside a bin (only kp remains to be checked). \n",
    "            # Open the corresponding TIEGCM file to read the kp and if position is in bin then calculate JH\n",
    "            if in_MLT_range:\n",
    "                current_time = parseDaedalusDate( row[Time_col] )\n",
    "                current_timestamp = calendar.timegm(current_time.utctimetuple())\n",
    "                if current_time == None:\n",
    "                    print( \"ERROR during coverage calculation while reading\", OrbitFilename, \": Wrong time format:\", row[Time_col], \"at line\", line_count )\n",
    "                    return # <<<<\n",
    "                # TODO remove after testing:\n",
    "                if current_time.year > 2024:  current_time = current_time - relativedelta(years=13)\n",
    "                # open the correct TIEGCM file according to time\n",
    "                current_timestep_number = (current_timestamp - TIEGCM_StartTimeStamp) / TIEGCM_TimeStep_sec\n",
    "                newfilenumber = int(( current_timestep_number ) / TIEGCM_NumOfTimeSteps) + 1\n",
    "                \n",
    "                #print( \"ZAZA\", \"orbit t=\", current_time , \"timestep_num=\", current_timestep_number, \"  filenum=\", newfilenumber )\n",
    "                if newfilenumber<=1 or newfilenumber > 73: continue # TODO del this line\n",
    "                    \n",
    "                if currentfilenumber < 0   or   currentfilenumber != newfilenumber:\n",
    "                    if currentfilenumber >= 0: CDFroot.close()\n",
    "                    TIEGCMfilename = TIEGCM_filesPath + TIEGCMfilenamePrefix + \"{:03.0f}\".format(newfilenumber) + TIEGCMfilenamePostfix + \".nc\"\n",
    "                    currentfilenumber = newfilenumber\n",
    "                    print(  \"Opening TIEGCMfile:\", TIEGCMfilename)\n",
    "                    try:\n",
    "                        CDFroot = Dataset( TIEGCMfilename, 'r' )\n",
    "                    except:\n",
    "                        print ( \"FILE NOT FOUND OR WRONG FORMAT:\", TIEGCMfilename )\n",
    "                        continue\n",
    "                # calculate the time-step inside the TIEGCM which corresponds to the satellite time \n",
    "                time_idx = int(  current_timestep_number - (newfilenumber-1)*TIEGCM_NumOfTimeSteps  )\n",
    "                # read Kp from the tiegcm file\n",
    "                \n",
    "                current_Kp = CDFroot.variables['Kp'][time_idx]\n",
    "                if current_Kp >= Kp_min and current_Kp <= Kp_max:\n",
    "                    in_Kp_range = True \n",
    "                # if the satellite position matches a bin then mark it as a hit and remember the JH values \n",
    "                if in_MagLat_range and in_MLT_range and in_Altitude_range and in_Kp_range:\n",
    "                    matchedBin = GetMatchedBin( current_MLT, current_MagLat, current_Altitude, current_Kp )\n",
    "                    if matchedBin is not None:\n",
    "                        # for this position locate the neighbor latitudes at the TIEGCM file. \n",
    "                        lat1_idx, lat2_idx, lat1_val, lat2_val = findNeighborValues( TIEGCM_Lats, current_GeogLat )\n",
    "                        # for this position locate the neighbor longitudes at the TIEGCM file.\n",
    "                        lon1_idx, lon2_idx, lon1_val, lon2_val = findNeighborValues( TIEGCM_Lons, current_Lon )\n",
    "                        # for this position locate the neighbor Altitudes at the TIEGCM file. \n",
    "                        lev1_idx, lev2_idx, lev1_val, lev2_val = findNeighborValues( CDFroot.variables['ZGMID'][time_idx, :, lat_idx, lon_idx], current_Altitude )\n",
    "                        # TODO: TRILINEAR INTERPOLATION\n",
    "                        current_JH  = CDFroot.variables['Ohmic'][time_idx, lev1_idx, lat1_idx, lon1_idx] \n",
    "                        current_EEX = CDFroot.variables['EEX_si'][time_idx, lev1_idx, lat1_idx, lon1_idx] \n",
    "                        current_EEY = CDFroot.variables['EEY_si'][time_idx, lev1_idx, lat1_idx, lon1_idx] \n",
    "                        current_PED = CDFroot.variables['SIGMA_PED'][time_idx, lev1_idx, lat1_idx, lon1_idx] \n",
    "                        current_HAL = CDFroot.variables['SIGMA_HAL'][time_idx, lev1_idx, lat1_idx, lon1_idx] \n",
    "                        # save \n",
    "                        matchedBin.JH_values.append( current_JH )\n",
    "                        matchedBin.MagLat_values.append( current_MagLat )\n",
    "                        matchedBin.MLT_values.append( current_MLT )\n",
    "                        matchedBin.Altitude_values.append( current_Altitude )\n",
    "                        matchedBin.Kp_values.append( current_Kp )\n",
    "                        matchedBin.Time_values.append( current_timestamp )\n",
    "                        matchedBin.EEX_values.append( current_EEX ) \n",
    "                        matchedBin.EEY_values.append( current_EEY ) \n",
    "                        matchedBin.Pedersen_values.append( current_PED ) \n",
    "                        matchedBin.Hall_values.append( current_HAL )                         \n",
    "                        all_JH_values.append( current_JH )\n",
    "                        all_MagLat_values.append( current_MagLat )\n",
    "                        all_MLT_values.append( current_MLT )\n",
    "                        all_Altitude_values.append( current_Altitude )\n",
    "                        all_Kp_values.append( current_Kp )\n",
    "                        all_Time_values.append( current_timestamp )\n",
    "                        all_HittedBin_IDs.append( matchedBin.ID )\n",
    "                        all_EEX_values.append( current_EEX )\n",
    "                        all_EEY_values.append( current_EEY )\n",
    "                        all_Pedersen_values.append( current_PED )\n",
    "                        all_Hall_values.append( current_HAL )                        \n",
    "                        Matches += 1\n",
    "                    else:\n",
    "                        print( \"PARADOX at:\", current_MLT, current_MagLat, current_Altitude, current_Kp, \" :: \", time_idx, lev_idx, lat_idx, lon_idx )\n",
    "                        \n",
    "    # clean up\n",
    "    print( Matches, \"satellite positions where matched inside bins.\" )\n",
    "    try:\n",
    "        CDFroot.close()\n",
    "    except:\n",
    "        print (\".\")\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# Finds the neighbor values of <aValue> inside the list.    \n",
    "# aList: a list of floats, with ascending sorting\n",
    "# aValue: a float value\n",
    "# RETURNS:\n",
    "#    the value of the lesser Neighbor, the value of the greater Neighbor, the index of the lesser Neighbor, the index of the greater Neighbor, \n",
    "def findNeighborValues( aList, aValue ):\n",
    "    listlength = len(aList)\n",
    "    stop_idx = -1\n",
    "    for i in range( 0, listlength ):\n",
    "        if aValue < aList[i]:\n",
    "            stop_idx = i\n",
    "            break\n",
    "    if stop_idx == -1: # <aValue> is greater than all the values of the list\n",
    "        LesserNeighborIdx  = listlength - 1\n",
    "        GreaterNeighborIdx = 0\n",
    "    elif stop_idx == 0: # <aValue> is lesser than all the values of the list\n",
    "        LesserNeighborIdx  = listlength - 1\n",
    "        GreaterNeighborIdx = 0\n",
    "    else:\n",
    "        LesserNeighborIdx  = stop_idx-1\n",
    "        GreaterNeighborIdx = stop_idx\n",
    "    #\n",
    "    return LesserNeighborIdx, GreaterNeighborIdx, aList[LesserNeighborIdx], aList[GreaterNeighborIdx]\n",
    "        \n",
    "    \n",
    "    \n",
    "def CalculateStatsOnData():\n",
    "    for B in Bins:\n",
    "        if len(B.JH_values) > 0:\n",
    "            # calculate the mean value\n",
    "            for aJHvalue in B.JH_values:\n",
    "                if B.JH_min > aJHvalue: B.JH_min = aJHvalue\n",
    "                if B.JH_max < aJHvalue: B.JH_max = aJHvalue\n",
    "                B.JH_mean += aJHvalue\n",
    "            B.JH_mean = B.JH_mean / len(B.JH_values)\n",
    "            \n",
    "            # calculate the median value\n",
    "            B.JH_median = np.percentile(B.JH_values, 50)\n",
    "            \n",
    "            # for Variance (around mean):\n",
    "            for aJHvalue in B.JH_values:\n",
    "                B.JH_variance += abs(aJHvalue - B.JH_mean)**2\n",
    "            B.JH_variance = B.JH_variance / len(B.JH_values)\n",
    "            \n",
    "            # for Median Variance (around median):\n",
    "            for aJHvalue in B.JH_values:\n",
    "                B.JH_medianVariance += abs(aJHvalue - B.JH_median)**2\n",
    "            B.JH_medianVariance = B.JH_medianVariance / len(B.JH_values)\n",
    "            \n",
    "            # for Median absolute deviation\n",
    "            AbsoluteDeviations = B.JH_values.copy()\n",
    "            for i in range(0, len(AbsoluteDeviations)):\n",
    "                AbsoluteDeviations[i] = abs(B.JH_median - AbsoluteDeviations[i])\n",
    "            B.JH_medianAbsDev = np.percentile(AbsoluteDeviations, 50)\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "#################### EVENT LISTENERS ###########################\n",
    "def Exec_Btn_Clicked( b ):\n",
    "    global Bins\n",
    "    global CALCULATIONS_Title, CALCULATIONS_Description, CALCULATIONS_RegionName, CALCULATIONS_OrbitFilesPath, CALCULATIONS_TIEGCMfolder, CALCULATIONS_ExecutionDuration\n",
    "    CALCULATIONS_Title         = ExecutionTitle_Text.value\n",
    "    CALCULATIONS_Description   = ExecutionDescr_Text.value\n",
    "    CALCULATIONS_RegionName    = BinGroups_Dropdown.value\n",
    "    CALCULATIONS_OrbitFilesPath = \"\"\n",
    "    CALCULATIONS_TIEGCMfolder      = tiegcmFolder_Dropdown.value\n",
    "    # remove all other bin-groups so that calculation is faster\n",
    "    newBins = list()\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith( BinGroups_Dropdown.value ): newBins.append( B )\n",
    "    Bins = newBins\n",
    "    CALCULATIONS_RegionName = Bins[0].Description + \" (\" + Bins[0].ID[:3] + \")\"\n",
    "    # do it\n",
    "    startSecs = time.time()\n",
    "    print( \"Calculation for TIEGCM grid started.\", datetime.now() )\n",
    "    ResultsFilename = AssignValuesPerBin_MultipleResultFiles(CALCULATIONS_TIEGCMfolder)  #AssignJouleHeatingValuesToBins( CALCULATIONS_TIEGCMfolder )\n",
    "    CalculateStatsOnData()\n",
    "    finishSecs = time.time()   \n",
    "    CALCULATIONS_ExecutionDuration = finishSecs-startSecs\n",
    "    # print info\n",
    "    print( \"Duration\", CALCULATIONS_ExecutionDuration, \"seconds.\" )\n",
    "    print( \"Calculation for TIEGCM grid finshed in \" + str(CALCULATIONS_ExecutionDuration) + \" seconds.\" )\n",
    "    print( \"RESULTS (stored in \" + ResultsFilename + \"):\" )\n",
    "    for B in Bins:\n",
    "        B.printMe()\n",
    "    # re-initialize the bins\n",
    "    InitializeBins()\n",
    "    print( \"Please re-run the notebook and load the results in order to plot them.\" )\n",
    "\n",
    "        \n",
    "def Exec_Btn_alongOrbit_Clicked( b ):\n",
    "    global Bins\n",
    "    global CALCULATIONS_Title, CALCULATIONS_Description, CALCULATIONS_RegionName, CALCULATIONS_OrbitFilesPath, CALCULATIONS_TIEGCMfolder, CALCULATIONS_ExecutionDuration\n",
    "    CALCULATIONS_Title          = ExecutionTitle_Text.value\n",
    "    CALCULATIONS_Description    = ExecutionDescr_Text.value\n",
    "    CALCULATIONS_RegionName     = BinGroups_Dropdown.value\n",
    "    CALCULATIONS_OrbitFilesPath = OrbitFilesPath_Dropdown.value\n",
    "    CALCULATIONS_TIEGCMfolder       = tiegcmFolder_Dropdown.value\n",
    "    ResultsFilename = DaedalusGlobals.CoverageResults_Files_Path + BinGroups_Dropdown.value + \".\" + CALCULATIONS_TIEGCMfolder[CALCULATIONS_TIEGCMfolder[:-1].rfind('/')+1:-1] + \".\" + CALCULATIONS_OrbitFilesPath[CALCULATIONS_OrbitFilesPath[:-1].rfind('/')+1:-1] + \".ValuesPerBinResults.nc\"\n",
    "    if path.exists( ResultsFilename ):\n",
    "        print( \"File \" + ResultsFilename + \" already exists. Cannot continue in order to prevent overwriting useful data.\" )\n",
    "    else:\n",
    "        # remove all other bin-groups so that calculation is faster\n",
    "        newBins = list()\n",
    "        for B in Bins:\n",
    "            if B.ID.startswith( BinGroups_Dropdown.value ): newBins.append( B )\n",
    "        Bins = newBins\n",
    "        # calculate\n",
    "        print( \"Joule-Heating-per-Bin-Along-Orbit calculation started.\", datetime.now() )\n",
    "        print( \"Reading TIEGCM file from\", CALCULATIONS_TIEGCMfolder )\n",
    "        print( \"Results will be stored in\", ResultsFilename, \"\\n\" )\n",
    "        startSecs = time.time()\n",
    "        AssignJouleHeatingValuesToBins_AlongOrbit( CALCULATIONS_TIEGCMfolder, CALCULATIONS_OrbitFilesPath )\n",
    "        CalculateStatsOnData()\n",
    "        finishSecs = time.time()   \n",
    "        CALCULATIONS_ExecutionDuration = finishSecs-startSecs\n",
    "        #SaveResults_TXT( ResultsFilename ) \n",
    "        SaveResults_CDF( ResultsFilename.replace(\".txt\", \".nc\"), \"\" ) \n",
    "        # print info\n",
    "        print( \"Duration\", CALCULATIONS_ExecutionDuration, \"seconds.\" )\n",
    "        print( \"Joule-Heating-per-Bin Calculation finshed in \" + str(CALCULATIONS_ExecutionDuration) + \" seconds.\" )\n",
    "        print( \"RESULTS (stored in \" + ResultsFilename + \"):\" )\n",
    "        for B in Bins:\n",
    "            B.printMe()\n",
    "        # re-initialize the bins\n",
    "        InitializeBins()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def Load_Btn_Clicked( b ):\n",
    "    global SELECTED_VARIABLE, SELECTED_VARIABLE_longname, SELECTED_VARIABLE_shortname, SELECTED_VARIABLE_units  \n",
    "    # set the selected variable as user has chosen\n",
    "    if Variable_DropDown.value == \"Joule Heating\":\n",
    "        SELECTED_VARIABLE = \"Ohmic\"\n",
    "        SELECTED_VARIABLE_longname  = \"Joule Heating\"\n",
    "        SELECTED_VARIABLE_shortname = \"JH\"\n",
    "        SELECTED_VARIABLE_units     = \"W/m3\"        \n",
    "    elif Variable_DropDown.value == \"Electric Field North\":\n",
    "        SELECTED_VARIABLE = \"EEY_si\"\n",
    "        SELECTED_VARIABLE_longname  = \"Electric Field North\"\n",
    "        SELECTED_VARIABLE_shortname = \"EF(N)\"\n",
    "        SELECTED_VARIABLE_units     = \"mV/m\"\n",
    "    elif Variable_DropDown.value == \"Electric Field East\":\n",
    "        SELECTED_VARIABLE = \"EEX_si\"\n",
    "        SELECTED_VARIABLE_longname  = \"Electric Field East\"\n",
    "        SELECTED_VARIABLE_shortname = \"ED(E)\"\n",
    "        SELECTED_VARIABLE_units     = \"mV/m\"\n",
    "    elif Variable_DropDown.value == \"Pedersen Conductivity\":\n",
    "        SELECTED_VARIABLE = \"SIGMA_PED\"\n",
    "        SELECTED_VARIABLE_longname  = \"Pedersen Conductivity\"\n",
    "        SELECTED_VARIABLE_shortname = \"Pedersen\"\n",
    "        SELECTED_VARIABLE_units     = \"S/m\"\n",
    "    elif Variable_DropDown.value == \"Hall Conductivity\":\n",
    "        SELECTED_VARIABLE = \"SIGMA_HAL\"\n",
    "        SELECTED_VARIABLE_longname  = \"Hall Conductivity\"\n",
    "        SELECTED_VARIABLE_shortname = \"Hall\"\n",
    "        SELECTED_VARIABLE_units     = \"S/m\"\n",
    "    elif Variable_DropDown.value == \"Convection Heating\":\n",
    "        SELECTED_VARIABLE = \"Convection_heating\"\n",
    "        SELECTED_VARIABLE_longname  = \"Convection Heating\"\n",
    "        SELECTED_VARIABLE_shortname = \"Conv.h.\"\n",
    "        SELECTED_VARIABLE_units     = \"W/m3\"\n",
    "    elif Variable_DropDown.value == \"Wind Correction\":\n",
    "        SELECTED_VARIABLE = \"Wind_heating\"\n",
    "        SELECTED_VARIABLE_longname  = \"Wind Correction\"\n",
    "        SELECTED_VARIABLE_shortname = \"Wind.Cor.\"\n",
    "        SELECTED_VARIABLE_units     = \"W/m3\"            \n",
    "    elif Variable_DropDown.value == \"JH/mass\":\n",
    "        SELECTED_VARIABLE = \"JH/mass\"\n",
    "        SELECTED_VARIABLE_longname  = \"JH/mass\"\n",
    "        SELECTED_VARIABLE_shortname = \"JH/mass\"\n",
    "        SELECTED_VARIABLE_units     = \"W/kg\"            \n",
    "    elif Variable_DropDown.value == \"JH/pressure\":\n",
    "        SELECTED_VARIABLE = \"JH/pressure\"\n",
    "        SELECTED_VARIABLE_longname  = \"JH/pressure\"\n",
    "        SELECTED_VARIABLE_shortname = \"JH/pressure\"\n",
    "        SELECTED_VARIABLE_units     = \"sec^-1\"            \n",
    "        \n",
    "    #### Load\n",
    "    if SavedFilenames_Dropdown.value.endswith( \".txt\" ):\n",
    "        LoadResults( SavedFilenames_Dropdown.value )\n",
    "    #### Plot\n",
    "    if Plot_JHdistribution_Checkbox.value == True:\n",
    "        if SavedFilenames_Dropdown.value.endswith( \".nc\" ) or SavedFilenames_Dropdown.value.endswith( \"/\" ): \n",
    "            LoadResults_CDF( SavedFilenames_Dropdown.value, loadTimeValues=False, loadMagLatValues=False, loadMLTvalues=False, loadAltValues=False, loadLatValues=False, loadKpValues=False )\n",
    "        Plot_Alex_Distribution()\n",
    "        Plot_JH_Distribution_perBin()\n",
    "    elif Plot_JHvsMagLat_Checkbox.value==True or Plot_JHvsMLT_Checkbox.value==True or Plot_JHvsAltitude_Checkbox.value==True or Plot_AltitudeVsMagLat_Checkbox.value==True:\n",
    "        if SavedFilenames_Dropdown.value.endswith( \".nc\" )  or SavedFilenames_Dropdown.value.endswith( \"/\" ): \n",
    "            LoadResults_CDF( SavedFilenames_Dropdown.value )\n",
    "        plotAll()        \n",
    "        plotAll_perKp()\n",
    "    elif Plot_AltProfilesCanonical_Checkbox.value == True:\n",
    "        if SavedFilenames_Dropdown.value.endswith( \".nc\" ) or SavedFilenames_Dropdown.value.endswith( \"/\" ): \n",
    "            LoadResults_CDF( SavedFilenames_Dropdown.value, loadBinValues=False, loadTimeValues=False, loadMagLatValues=False, loadAltValues=True, loadLatValues=False )\n",
    "        #plotAltitudeProfiles_perSeason( False )\n",
    "        #plotAltitudeProfiles_perSeason( True )\n",
    "        plotAltProfilesCanonical_perKpRange()\n",
    "    elif Plot_AltProfilesNatural_Checkbox.value == True:\n",
    "        if SavedFilenames_Dropdown.value.endswith( \".nc\" ) or SavedFilenames_Dropdown.value.endswith( \"/\" ): \n",
    "            LoadResults_CDF( SavedFilenames_Dropdown.value, loadBinValues=True, loadGlobalValues=False, loadTimeValues=False, loadMagLatValues=False, loadAltValues=True, loadLatValues=False )\n",
    "        plotAltProfilesNatural_perKpRange()        \n",
    "    elif Plot_ColorSpreads_Checkbox.value == True:\n",
    "        if SavedFilenames_Dropdown.value.endswith( \".nc\" ) or SavedFilenames_Dropdown.value.endswith( \"/\" ): \n",
    "            LoadResults_CDF( SavedFilenames_Dropdown.value, loadBinValues=False, loadTimeValues=False, loadMagLatValues=True, loadMLTvalues=True, loadAltValues=True, loadLatValues=False )\n",
    "        plotColorSpread_perKpRange()\n",
    "    elif Plot_PDFperSubBin_Checkbox.value == True:\n",
    "        plotPDFperSubBin()\n",
    "    elif Plot_HeightIntegrated_Checkbox.value == True:\n",
    "        plotHeightIntegrated_perKpRange()\n",
    "    elif Test_statistical_Checkbox.value == True:\n",
    "        executeZtest( SavedFilenames_Dropdown.value, SavedFilenamesDuplicate_Dropdown.value )\n",
    "        \n",
    "def CompareResults_Btn_Clicked( b ):\n",
    "    plotComparisonOfResults()\n",
    "            \n",
    "################################################################\n",
    "\n",
    "def tiegcmFolder_Dropdown_onChange(change):\n",
    "    if change['type']=='change' and change['name']=='value' and len(change['new'])>0:\n",
    "        return\n",
    "\n",
    "        \n",
    "def SavedFilenames_Dropdown_onChange(change):\n",
    "    if change['type']=='change' and change['name']=='value' and len(change['new'])>0:\n",
    "        file_size_in_Gigabytes = os.stat(change['new']).st_size / 1024 / 1024 / 1024\n",
    "        if file_size_in_Gigabytes > 5:\n",
    "            Warning_HTML.value= \"<b><font color='red'>File size is \" + '{0:.1f}'.format(file_size_in_Gigabytes) + \" Gigabyte. Ploting will take several minutes.</b>\" \n",
    "            Warning_HTML.visible=True\n",
    "        elif file_size_in_Gigabytes > 1:\n",
    "            Warning_HTML.value= \"<b><font color='red'>File size is \" + '{0:.1f}'.format(file_size_in_Gigabytes) + \" Gigabyte. Ploting will take several seconds.</b>\" \n",
    "            Warning_HTML.visible=True            \n",
    "        else:\n",
    "            Warning_HTML.visible=False\n",
    "\n",
    "\n",
    "\n",
    "def MainTab_Changed( change ):\n",
    "    if change['type']=='change' and change['name']=='selected_index':\n",
    "        if change['new'] == 0:\n",
    "            change = {'type':'change', 'name':'value', 'new':tiegcmFolder_Dropdown.value}\n",
    "        else:\n",
    "            change = {'type':'change', 'name':'value', 'new':SavedFilenames_Dropdown.value}\n",
    "        tiegcmFolder_Dropdown_onChange( change )  \n",
    "            \n",
    "def createGUI():\n",
    "    ## the top level visual elements\n",
    "    MainPanel = w.VBox()    \n",
    "    MainTab = w.Tab() \n",
    "    LoadCoveragePanel           = w.VBox()\n",
    "    CalcCoveragePanel           = w.VBox()\n",
    "    CalcCoverageAlongOrbitPanel = w.VBox()\n",
    "    CompareResultsPanel         = w.VBox()\n",
    "    ## the checkboxes which allow user to select which plots he wants to create\n",
    "    PlotSelectionPanel = w.VBox()\n",
    "    PlotSelectionPanel.children = [Plot_JHvsMagLat_Checkbox, Plot_JHvsMLT_Checkbox, Plot_JHvsAltitude_Checkbox, Plot_AltitudeVsMagLat_Checkbox, w.HBox([Plot_JHdistribution_Checkbox, RegressionOptions_Dropdown]), Plot_AltProfilesCanonical_Checkbox, Plot_AltProfilesNatural_Checkbox, Plot_HeightIntegrated_Checkbox, Plot_ColorSpreads_Checkbox, Plot_PDFperSubBin_Checkbox,Test_statistical_Checkbox ]\n",
    "    ##\n",
    "    MainTab.children = [ CalcCoverageAlongOrbitPanel, CalcCoveragePanel, LoadCoveragePanel ]\n",
    "    MainTab.set_title(0, 'Calc along Orbit')\n",
    "    MainTab.set_title(1, 'Calc for TIEGCMgrid')\n",
    "    MainTab.set_title(2, 'Load Results')\n",
    "    MainTab.set_title(3, 'Compare Results')\n",
    "    MainPanel.children = [ MainTab, OrbitPreviewImage ]    \n",
    "    ## \n",
    "    Exec_Btn = w.Button (description='Calculate for TIEGCM grid',tooltip=\"Click here to calculate\",)\n",
    "    Exec_Btn.style.button_color = 'MediumTurquoise'\n",
    "    Exec_Btn.on_click( Exec_Btn_Clicked )\n",
    "    CalcCoveragePanel.children = [tiegcmFolder_Dropdown, BinGroups_Dropdown, ExecutionTitle_Text, ExecutionDescr_Text, Exec_Btn ] # I removed PlotSelectionPanel\n",
    "    ##\n",
    "    ExecAlongOrbit_Btn = w.Button (description='Calc along Orbit',tooltip=\"Click here to calculate\",)\n",
    "    ExecAlongOrbit_Btn.style.button_color = 'Coral'\n",
    "    ExecAlongOrbit_Btn.on_click( Exec_Btn_alongOrbit_Clicked )\n",
    "    CalcCoverageAlongOrbitPanel.children = [tiegcmFolder_Dropdown, BinGroups_Dropdown, OrbitFilesPath_Dropdown, ExecutionTitle_Text, ExecutionDescr_Text, ExecAlongOrbit_Btn ] # I removed PlotSelectionPanel\n",
    "    ##\n",
    "    Load_Btn = w.Button (description='Load Results from',tooltip=\"Click here to plot\",)\n",
    "    Load_Btn.style.button_color = 'YellowGreen'\n",
    "    Load_Btn.on_click( Load_Btn_Clicked )\n",
    "    L2_horizontal = w.HBox()\n",
    "    L2_horizontal.children = [Load_Btn, SavedFilenames_Dropdown]\n",
    "    LoadCoveragePanel.children = [ w.HBox([Load_Btn, SavedFilenames_Dropdown]), SavedFilenamesDuplicate_Dropdown, Variable_DropDown, Warning_HTML, PlotSelectionPanel ]\n",
    "    ##\n",
    "    CompareResults_Btn = w.Button (description='Compare Results',tooltip=\"Click here to plot\",)\n",
    "    CompareResults_Btn.style.button_color = 'Gold'\n",
    "    CompareResults_Btn.on_click( CompareResults_Btn_Clicked )\n",
    "    CompareResultsPanel.children = [ w.HBox([w.HTML(value=\"TIEGCM results:\"),SavedFilenames_Dropdown]), w.HBox([w.HTML(value=\"Orbit results:\"),SavedFilenames2_Dropdown]), CompareResults_Btn ]\n",
    "    ## Assign event listeners\n",
    "    tiegcmFolder_Dropdown.observe( tiegcmFolder_Dropdown_onChange )\n",
    "    SavedFilenames_Dropdown.observe( SavedFilenames_Dropdown_onChange )\n",
    "    MainTab.observe( MainTab_Changed )\n",
    "    ## display orbit-related image\n",
    "    change = {'type':'change', 'name':'value', 'new':tiegcmFolder_Dropdown.value}\n",
    "    tiegcmFolder_Dropdown_onChange( change )        \n",
    "    return MainPanel\n",
    "# PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT \n",
    "# PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT \n",
    "# PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT PLOT \n",
    "\n",
    "def plotAll():\n",
    "    # choose which bins we are going to work with\n",
    "    if \"(\" in CALCULATIONS_RegionName:\n",
    "        RegionID = CALCULATIONS_RegionName[ CALCULATIONS_RegionName.find('(')+1 : CALCULATIONS_RegionName.rfind(')') ]\n",
    "    else:\n",
    "        RegionID = CALCULATIONS_RegionName\n",
    "    BinsIncludedAtPlot = list()\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID): BinsIncludedAtPlot.append( B )\n",
    "\n",
    "    # remember the Kp ranges of these bins. Each Kp-range will have its own sub-plot\n",
    "    TMP_KpRanges = list()\n",
    "    for B in BinsIncludedAtPlot:\n",
    "        if [B.Kp_min, B.Kp_max] not in TMP_KpRanges: TMP_KpRanges.append( [B.Kp_min, B.Kp_max] )  \n",
    "            \n",
    "    # --- init various plotting parameters ---\n",
    "    max_num_of_points = 10000\n",
    "    plot_step = int(  len(all_JH_values) / max_num_of_points  )\n",
    "    if plot_step <= 0: plot_step = 1\n",
    "    n = max_num_of_points\n",
    "    if n > len(all_JH_values):  n = len(all_JH_values)\n",
    "    print( \"I will plot\", n, \"out of\", len(all_JH_values), \"points (1 per\", plot_step, \")\")\n",
    "    TMP_JH_values       = list()\n",
    "    TMP_MagLat_values   = list()\n",
    "    TMP_MLT_values      = list()\n",
    "    TMP_Altitude_values = list()\n",
    "    for idx in range( 0, len(all_JH_values) ):\n",
    "        if int(idx / 1) % int(plot_step) == 0: \n",
    "            TMP_JH_values.append( all_JH_values[idx] )\n",
    "            TMP_MagLat_values.append( all_MagLat_values[idx] )\n",
    "            TMP_MLT_values.append( all_MLT_values[idx] )\n",
    "            TMP_Altitude_values.append( all_Altitude_values[idx] )\n",
    "    \n",
    "    # handle MLT ranges like 22:00-02:00\n",
    "    MLT_min_toPlot = BinsIncludedAtPlot[0].MLT_min\n",
    "    MLT_max_toPlot = BinsIncludedAtPlot[0].MLT_max\n",
    "    if BinsIncludedAtPlot[0].MLT_min > BinsIncludedAtPlot[0].MLT_max:\n",
    "        MLT_max_toPlot += 24\n",
    "        for i in range(0, len(TMP_MLT_values)):\n",
    "            if TMP_MLT_values[i] < BinsIncludedAtPlot[0].MLT_min: TMP_MLT_values[i] += 24\n",
    "    # define altitude range for X-axis\n",
    "    Altitude_max_toPlot = max(all_Altitude_values)\n",
    "    if Altitude_max_toPlot < 140: Altitude_max_toPlot = 140\n",
    "                \n",
    "    # define max JH value to be plotted\n",
    "    if SELECTED_VARIABLE == \"Ohmic\" or SELECTED_VARIABLE == \"Convection_heating\":\n",
    "        JHmax = 1.4e-7\n",
    "        if CALCULATIONS_RegionName.startswith( \"SQ\" ): JHmax = max(all_JH_values)\n",
    "    else:\n",
    "        JHmax = max(all_JH_values)\n",
    "        \n",
    "    if len(all_MagLat_values) > 0  and  Plot_JHvsMagLat_Checkbox.value==True:\n",
    "        print( \"Plotting \", len(TMP_MagLat_values), \"points\" )\n",
    "        MyColorsIndex = 0\n",
    "        fig = go.Figure()        \n",
    "        fig.add_trace( go.Scatter(name=SELECTED_VARIABLE_longname, x=TMP_MagLat_values, y=TMP_JH_values, mode='markers', marker_size=2) )\n",
    "        BinAnnotations = list()\n",
    "        prevKpMin = -1\n",
    "        BinIdx = 0\n",
    "        for B in BinsIncludedAtPlot:\n",
    "            if len(B.JH_values) > 0:\n",
    "                # choose color for mean line\n",
    "                if prevKpMin >= 0 and prevKpMin != B.Kp_min:\n",
    "                    MyColorsIndex += 1\n",
    "                    if MyColorsIndex>len(MyColors)-1: MyColorsIndex = 0\n",
    "                prevKpMin = B.Kp_min                        \n",
    "                # add visuals for the mean line\n",
    "                fig.add_shape( type=\"line\", x0=B.MagLat_min, y0=B.JH_mean,     x1=B.MagLat_max, y1=B.JH_mean,     line=dict( color=MyColors[MyColorsIndex], width=2, ), )    \n",
    "                # add info as legend for this bin\n",
    "                fig.add_trace( go.Scatter(name=B.ID + \":  \" + str(B.Altitude_min) + \"<Alt<\"+ str(B.Altitude_max) + \"  <b>\" + str(B.Kp_min) + \"<Kp<\" + str(B.Kp_max) + \"</b>\" + \"  Mean=\" + \"{:.3e}\".format(B.JH_mean) + \"  \" + \"Variance=\" + \"{:.3e}\".format(B.JH_variance) + \"  St.Deviation=\" + \"{:.3e}\".format(B.JH_variance**(1/2)) , x=[-1], y=[-1], mode='markers', marker_size=1, marker_color=MyColors[MyColorsIndex]) )\n",
    "                # add bin name above the mean line\n",
    "                BinAnnotations.append( dict( x=B.MagLat_min+((BinIdx+1)/len(BinsIncludedAtPlot))*(B.MagLat_max-B.MagLat_min)*3/4, y=B.JH_mean, xref=\"x\", yref=\"y\", text=B.ID, showarrow=False, yshift=8, font=dict(color=MyColors[MyColorsIndex])) )\n",
    "                # add visuals for standard deviation\n",
    "                fig.add_shape( type=\"line\", x0=B.MagLat_min+((BinIdx+1)/len(BinsIncludedAtPlot))*(B.MagLat_max-B.MagLat_min)*7/8, y0=B.JH_mean+(B.JH_variance)**(1/2)/2,     x1=B.MagLat_min+((BinIdx+1)/len(BinsIncludedAtPlot))*(B.MagLat_max-B.MagLat_min)*7/8, y1=B.JH_mean-(B.JH_variance)**(1/2)/2,     line=dict( color=MyColors[MyColorsIndex], width=1, ), ) \n",
    "                #\n",
    "                BinIdx += 1\n",
    "        fig.update_layout( annotations=BinAnnotations )\n",
    "        fig.update_layout( title=SELECTED_VARIABLE_longname+\" vs Magnetic Latitude - \" + getBinDescription(CALCULATIONS_RegionName), \n",
    "                           width=1000, height=1300, legend_orientation=\"h\", legend= {'itemsizing': 'constant'}) \n",
    "        fig.update_xaxes(range=[min(all_MagLat_values), max(all_MagLat_values)], title=\"Magnetic Latitude (degrees)\")\n",
    "        fig.update_yaxes(range=[min(all_JH_values), JHmax], title=SELECTED_VARIABLE_shortname+\" (\"+SELECTED_VARIABLE_units+\")\", showexponent = 'all', exponentformat = 'e')\n",
    "        plotly.offline.init_notebook_mode(connected=True)\n",
    "        plotly.offline.iplot(fig)\n",
    "    else:\n",
    "        pass\n",
    "        #print( \"There are no points for MagLat plot\" )                \n",
    "\n",
    "    if len(all_MLT_values) > 0  and  Plot_JHvsMLT_Checkbox.value == True:\n",
    "        MyColorsIndex = 0\n",
    "        fig = go.Figure()\n",
    "        print( \"Plotting \", len(TMP_MLT_values), \"points\" )\n",
    "        fig.add_trace( go.Scatter(name=SELECTED_VARIABLE_longname, x=TMP_MLT_values, y=TMP_JH_values, mode='markers', marker_size=2) )\n",
    "        prevKpMin = -1\n",
    "        BinAnnotations = list()\n",
    "        BinIdx = 0\n",
    "        for B in BinsIncludedAtPlot:\n",
    "            if len(B.JH_values) > 0:\n",
    "                # choose color for mean line\n",
    "                if prevKpMin >= 0 and prevKpMin != B.Kp_min:\n",
    "                    MyColorsIndex += 1\n",
    "                    if MyColorsIndex>len(MyColors)-1: MyColorsIndex = 0\n",
    "                prevKpMin = B.Kp_min                        \n",
    "                # add visuals for the mean line             \n",
    "                fig.add_shape( type=\"line\", x0=MLT_min_toPlot, y0=B.JH_mean,     x1=MLT_max_toPlot, y1=B.JH_mean,     line=dict( color=MyColors[MyColorsIndex], width=2, ), )    \n",
    "                # add info as legend for this bin\n",
    "                fig.add_trace( go.Scatter(name=B.ID + \":  \" + str(B.Altitude_min) + \"<Alt<\"+ str(B.Altitude_max) + \"  <b>\" + str(B.Kp_min) + \"<Kp<\" + str(B.Kp_max) + \"</b>\" + \"  Mean=\" + \"{:.3e}\".format(B.JH_mean) + \"  \" + \"Variance=\" + \"{:.3e}\".format(B.JH_variance) + \"St.Deviation=\" + \"{:.3e}\".format(B.JH_variance**(1/2)), x=[-1], y=[-1], mode='markers', marker_size=1, marker_color=MyColors[MyColorsIndex]) )\n",
    "                # add bin name above the mean line\n",
    "                BinAnnotations.append( dict( x=MLT_min_toPlot+((BinIdx+1)/len(BinsIncludedAtPlot))*(MLT_max_toPlot-MLT_min_toPlot)*3/4, y=B.JH_mean, xref=\"x\", yref=\"y\", text=B.ID, showarrow=False, yshift=8, font=dict(color=MyColors[MyColorsIndex])) )\n",
    "                # add visuals for standard deviation\n",
    "                fig.add_shape( type=\"line\", x0=MLT_min_toPlot+((BinIdx+1)/len(BinsIncludedAtPlot))*(MLT_max_toPlot-MLT_min_toPlot)*7/8, y0=B.JH_mean+(B.JH_variance)**(1/2)/2,     x1=MLT_min_toPlot+((BinIdx+1)/len(BinsIncludedAtPlot))*(MLT_max_toPlot-MLT_min_toPlot)*7/8, y1=B.JH_mean-(B.JH_variance)**(1/2)/2,     line=dict( color=MyColors[MyColorsIndex], width=1, ), )\n",
    "                #\n",
    "                BinIdx += 1\n",
    "        fig.update_layout( annotations=BinAnnotations )\n",
    "        fig.update_layout( title=SELECTED_VARIABLE_longname+\" vs Magnetic Local Time - \" + getBinDescription(CALCULATIONS_RegionName), \n",
    "                           width=1000, height=1300, legend_orientation=\"h\", legend= {'itemsizing': 'constant'}) \n",
    "        fig.update_xaxes(range=[MLT_min_toPlot, MLT_max_toPlot], title=\"Magnetic Local Time (hours)\") #fig.update_xaxes(range=[min(TMP_MLT_values), max(TMP_MLT_values)], title=\"Magnetic Local Time (hours)\")\n",
    "        fig.update_yaxes(range=[min(all_JH_values), JHmax], title=SELECTED_VARIABLE_shortname+\" (\"+SELECTED_VARIABLE_units+\")\", showexponent = 'all', exponentformat = 'e')\n",
    "        plotly.offline.init_notebook_mode(connected=True)\n",
    "        plotly.offline.iplot(fig)\n",
    "    else:\n",
    "        pass\n",
    "        #print( \"There are no points for MLT plot\" )        \n",
    "    \n",
    "    if len(TMP_Altitude_values) > 0  and  Plot_JHvsAltitude_Checkbox.value == True:\n",
    "        MyColorsIndex = 0\n",
    "        fig = go.Figure()\n",
    "        print( \"Plotting \", len(TMP_Altitude_values), \"points\" )\n",
    "        fig.add_trace( go.Scatter(name=SELECTED_VARIABLE_longname, x=TMP_Altitude_values, y=TMP_JH_values, mode='markers', marker_size=2) )\n",
    "        prevKpMin = -1\n",
    "        BinAnnotations = list()\n",
    "        BinIdx = 0\n",
    "        for B in BinsIncludedAtPlot:\n",
    "            if len(B.JH_values) > 0:\n",
    "                # choose color for mean line\n",
    "                if prevKpMin >= 0 and prevKpMin != B.Kp_min:\n",
    "                    MyColorsIndex += 1\n",
    "                    if MyColorsIndex>len(MyColors)-1: MyColorsIndex = 0\n",
    "                prevKpMin = B.Kp_min                        \n",
    "                # add visuals for the mean line\n",
    "                fig.add_shape( type=\"line\", x0=B.Altitude_min, y0=B.JH_mean,     x1=B.Altitude_max, y1=B.JH_mean,     line=dict( color=MyColors[MyColorsIndex], width=2, ), )    \n",
    "                # add info as legend for this bin\n",
    "                fig.add_trace( go.Scatter(name=B.ID + \":  \" + str(B.Altitude_min) + \"<Alt<\"+ str(B.Altitude_max) + \"  <b>\" + str(B.Kp_min) + \"<Kp<\" + str(B.Kp_max) + \"</b>\" + \"  Mean=\" + \"{:.3e}\".format(B.JH_mean) + \"  \" + \"Variance=\" + \"{:.3e}\".format(B.JH_variance) + \"  St.Deviation=\" + \"{:.3e}\".format(B.JH_variance**(1/2)), x=[-1], y=[-1], mode='markers', marker_size=1, marker_color=MyColors[MyColorsIndex]) )\n",
    "                # add bin name above the mean line\n",
    "                BinAnnotations.append( dict( x=B.Altitude_min+((BinIdx+1)/len(BinsIncludedAtPlot))*(B.Altitude_max-B.Altitude_min)*3/4, y=B.JH_mean, xref=\"x\", yref=\"y\", text=B.ID, showarrow=False, yshift=8, font=dict(color=MyColors[MyColorsIndex])) )\n",
    "                # add visuals for standard deviation\n",
    "                fig.add_shape( type=\"line\", x0=B.Altitude_min+((BinIdx+1)/len(BinsIncludedAtPlot))*(B.Altitude_max-B.Altitude_min)*7/8, y0=B.JH_mean+(B.JH_variance)**(1/2)/2,     x1=B.Altitude_min+((BinIdx+1)/len(BinsIncludedAtPlot))*(B.Altitude_max-B.Altitude_min)*7/8, y1=B.JH_mean-(B.JH_variance)**(1/2)/2,     line=dict( color=MyColors[MyColorsIndex], width=1, ), )\n",
    "                #\n",
    "                BinIdx += 1\n",
    "        fig.update_layout( annotations=BinAnnotations )\n",
    "        fig.update_layout( title=SELECTED_VARIABLE_longname+\" vs Altitude - \" + getBinDescription(CALCULATIONS_RegionName), \n",
    "                           width=1000, height=1300, legend_orientation=\"h\", legend= {'itemsizing': 'constant'}) \n",
    "        fig.update_xaxes(range=[115, Altitude_max_toPlot], title=\"Altitude (km)\")\n",
    "        fig.update_yaxes(range=[min(all_JH_values), JHmax], title=SELECTED_VARIABLE_shortname+\" (\"+SELECTED_VARIABLE_units+\")\", showexponent = 'all', exponentformat = 'e')\n",
    "        plotly.offline.init_notebook_mode(connected=True)\n",
    "        plotly.offline.iplot(fig)\n",
    "    else:\n",
    "        pass\n",
    "        #print( \"There are no points for Altitude plot\" )\n",
    "    \n",
    "    \n",
    "    if len(TMP_JH_values) > 0  and  Plot_AltitudeVsMagLat_Checkbox.value == True:\n",
    "        MyColorsIndex = 0\n",
    "        fig = go.Figure()\n",
    "        print( \"Plotting \", len(TMP_JH_values), \"points\" )\n",
    "        \n",
    "        colorMean = 0\n",
    "        for n in TMP_JH_values: colorMean += n\n",
    "        colorMean = float( colorMean / len(TMP_JH_values) )\n",
    "        colorMin = float(colorMean / 10)\n",
    "        colorMax = float(colorMean * 10)\n",
    "        fig.add_trace( go.Scatter(name=SELECTED_VARIABLE_longname, x=TMP_MagLat_values, y=TMP_Altitude_values, mode='markers', \n",
    "                       marker=dict( size=2, color=TMP_JH_values, colorscale=\"Jet\", cmin=colorMin, cmax=colorMax, colorbar=dict(title=SELECTED_VARIABLE_shortname+\" (\"+SELECTED_VARIABLE_units+\")\" )) ) )\n",
    "        for B in BinsIncludedAtPlot:\n",
    "            if len(B.JH_values) > 0:\n",
    "                #fig.add_shape( type=\"line\", x0=B.MagLat_min, y0=B.JH_mean,     x1=B.MagLat_max, y1=B.JH_mean,     line=dict( color=MyColors[MyColorsIndex], width=1, ), )    \n",
    "                #fig.add_trace( go.Scatter(name=\"Bin Mean: \" + str(B.Altitude_min) + \"<Alt<\"+ str(B.Altitude_max) + \" <b>\" + str(B.Kp_min) + \"<Kp<\" + str(B.Kp_max) + \"</b> Variance=\" + str(B.JH_variance), x=[-1], y=[-1], mode='markers', marker_size=1, marker_color=MyColors[MyColorsIndex]) )\n",
    "                MyColorsIndex += 1\n",
    "                if MyColorsIndex>len(MyColors)-1: MyColorsIndex = 0\n",
    "        fig.update_layout( title=\"Altitude vs Magnetic Latitude - \" + CALCULATIONS_RegionName, \n",
    "                           width=1000, height=1300, legend_orientation=\"h\", legend= {'itemsizing': 'constant'}) \n",
    "        fig.update_xaxes(range=[min(all_MagLat_values), max(all_MagLat_values)], title=\"Magnetic Latitude (degrees)\" )\n",
    "        fig.update_yaxes(range=[min(all_Altitude_values), max(all_Altitude_values)], title=\"Altitude(km)\")\n",
    "        plotly.offline.init_notebook_mode(connected=True)\n",
    "        plotly.offline.iplot(fig)\n",
    "    else:\n",
    "        pass\n",
    "        #print( \"There are no points for Altitude-MagLat plot\" )                \n",
    "\n",
    "    \n",
    "\n",
    "# PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP \n",
    "# PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP \n",
    "# PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP PERKP \n",
    "\n",
    "def plotAll_perKp():\n",
    "    # choose which bins we are going to work with\n",
    "    if \"(\" in CALCULATIONS_RegionName:\n",
    "        RegionID = CALCULATIONS_RegionName[ CALCULATIONS_RegionName.find('(')+1 : CALCULATIONS_RegionName.rfind(')') ]\n",
    "    else:\n",
    "        RegionID = CALCULATIONS_RegionName\n",
    "    BinsIncludedAtPlot = list()\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID): BinsIncludedAtPlot.append( B )          \n",
    "\n",
    "    # --- init various plotting parameters ---\n",
    "    # handle MLT ranges like 22:00-02:00\n",
    "    MLT_min_toPlot = BinsIncludedAtPlot[0].MLT_min\n",
    "    MLT_max_toPlot = BinsIncludedAtPlot[0].MLT_max\n",
    "    if BinsIncludedAtPlot[0].MLT_min > BinsIncludedAtPlot[0].MLT_max:\n",
    "        MLT_max_toPlot += 24\n",
    "        for i in range(0, len(all_MLT_values)):\n",
    "            if all_MLT_values[i] < BinsIncludedAtPlot[0].MLT_min: all_MLT_values[i] += 24\n",
    "        for B in BinsIncludedAtPlot:\n",
    "            for i in range(0, len(B.MLT_values)):\n",
    "                if B.MLT_values[i] < BinsIncludedAtPlot[0].MLT_min: B.MLT_values[i] += 24\n",
    "    # define altitude range for X-axis\n",
    "    Altitude_max_toPlot = max(all_Altitude_values)\n",
    "    if Altitude_max_toPlot < 140: Altitude_max_toPlot = 140\n",
    "    # define max JH value to be plotted\n",
    "    if SELECTED_VARIABLE == \"Ohmic\" or SELECTED_VARIABLE == \"Convection_heating\":\n",
    "        JHmax = 1.4e-7\n",
    "        if CALCULATIONS_RegionName.startswith( \"SQ\" ): JHmax = max(all_JH_values)\n",
    "    else:\n",
    "        JHmax = max(all_JH_values)\n",
    "\n",
    "    # CONSTRUCT DATA per Kp-range\n",
    "    # remember the Kp ranges of the plot's bins. Each Kp-range will have its own sub-plot\n",
    "    All_KpRanges = list()\n",
    "    for B in BinsIncludedAtPlot:\n",
    "        if [B.Kp_min, B.Kp_max] not in All_KpRanges: \n",
    "            All_KpRanges.append( [B.Kp_min, B.Kp_max] )  \n",
    "    # group data according to Kp-range\n",
    "    JH_values_perKp       = list() # 2d-list: one row for each Kp-range\n",
    "    MagLat_values_perKp   = list() # 2d-list: one row for each Kp-range\n",
    "    MLT_values_perKp      = list() # 2d-list: one row for each Kp-range\n",
    "    Altitude_values_perKp = list() # 2d-list: one row for each Kp-range\n",
    "    Time_values_perKp     = list()\n",
    "    for i in range(0, len(All_KpRanges)): \n",
    "        JH_values_perKp.append( list() )\n",
    "        MagLat_values_perKp.append( list() )\n",
    "        MLT_values_perKp.append( list() )\n",
    "        Altitude_values_perKp.append( list() )\n",
    "        Time_values_perKp.append( list() )\n",
    "        for B in BinsIncludedAtPlot:\n",
    "            if B.Kp_min==All_KpRanges[i][0] and B.Kp_max==All_KpRanges[i][1]: \n",
    "                JH_values_perKp[i]       += B.JH_values\n",
    "                MagLat_values_perKp[i]   += B.MagLat_values\n",
    "                MLT_values_perKp[i]      += B.MLT_values\n",
    "                Altitude_values_perKp[i] += B.Altitude_values\n",
    "                Time_values_perKp[i]     += B.Time_values\n",
    "    # make the data set smaller so that it can be plotted\n",
    "    max_num_of_points = 80000\n",
    "    print( \"\\n\" ) \n",
    "    for i in range(0, len(All_KpRanges)):\n",
    "        plot_step = int(  len(JH_values_perKp[i]) / max_num_of_points  )\n",
    "        n = max_num_of_points \n",
    "        if n > len(JH_values_perKp[i]):  n = len(JH_values_perKp[i])\n",
    "        print( \"I will plot\", n, \"out of\", len(JH_values_perKp[i]), \"points (1 per\", plot_step, \")\" + \" for \" + str(All_KpRanges[i][0]) + \"<Kp<\" + str(All_KpRanges[i][1]) )\n",
    "        if plot_step > 0:\n",
    "            #JH_values_perKp[i]       = JH_values_perKp[i][0::plot_step]\n",
    "            #MagLat_values_perKp[i]   = MagLat_values_perKp[i][0::plot_step]\n",
    "            #MLT_values_perKp[i]      = MLT_values_perKp[i][0::plot_step]\n",
    "            #Altitude_values_perKp[i] = Altitude_values_perKp[i][0::plot_step]\n",
    "            TMP_JH_values       = list()\n",
    "            TMP_MagLat_values   = list()\n",
    "            TMP_MLT_values      = list()\n",
    "            TMP_Altitude_values = list()\n",
    "            TMP_Time_values     = list()\n",
    "            for idx in range( 0, len(JH_values_perKp[i]) ):\n",
    "                if int(idx / 1) % int(plot_step) == 0: \n",
    "                    TMP_JH_values.append( JH_values_perKp[i][idx] )\n",
    "                    TMP_MagLat_values.append( MagLat_values_perKp[i][idx] )\n",
    "                    TMP_MLT_values.append( MLT_values_perKp[i][idx] )\n",
    "                    TMP_Altitude_values.append( Altitude_values_perKp[i][idx] )\n",
    "                    try:\n",
    "                        TMP_Time_values.append( Time_values_perKp[i][idx] )\n",
    "                    except:\n",
    "                        pass\n",
    "            JH_values_perKp[i]       = TMP_JH_values\n",
    "            MagLat_values_perKp[i]   = TMP_MagLat_values\n",
    "            MLT_values_perKp[i]      = TMP_MLT_values\n",
    "            Altitude_values_perKp[i] = TMP_Altitude_values\n",
    "            Time_values_perKp[i] = TMP_Time_values\n",
    "            \n",
    "    # PLOT\n",
    "    if len(all_MagLat_values) > 0  and  Plot_JHvsMagLat_Checkbox.value==True:\n",
    "        fig = make_subplots(rows=len(All_KpRanges), cols=1, shared_xaxes=False, vertical_spacing=0.05)\n",
    "        for i in range(0, len(All_KpRanges)):\n",
    "            fig.append_trace( go.Scatter(name=SELECTED_VARIABLE_longname, x=MagLat_values_perKp[i], y=JH_values_perKp[i], mode='markers', marker_size=2, marker_color=MyColors[i]), row=i+1, col=1 )\n",
    "        #\n",
    "        BinAnnotations = list()\n",
    "        FigureShapes = list()\n",
    "        MyColorsIndex = 0\n",
    "        BinIdx = 0\n",
    "        for B in BinsIncludedAtPlot:\n",
    "            if len(B.JH_values) > 0:\n",
    "                # choose which sub-plot will host this Bin's data\n",
    "                SubPlotIdx = 1\n",
    "                for i in range(0, len(All_KpRanges)):\n",
    "                    if B.Kp_min==All_KpRanges[i][0] and B.Kp_max==All_KpRanges[i][1]: SubPlotIdx = i+1\n",
    "                # choose color for mean line\n",
    "                MyColorsIndex = SubPlotIdx - 1\n",
    "                # add visuals for the mean line\n",
    "                FigureShapes.append( dict(type=\"line\", x0=B.MagLat_min, y0=B.JH_mean,     x1=B.MagLat_max, y1=B.JH_mean,   line=dict( color=MyColors[MyColorsIndex], width=2, ),  xref= 'x'+str(SubPlotIdx), yref= 'y'+str(SubPlotIdx))  )  #fig.append_shape( dict(type=\"line\", x0=B.MagLat_min, y0=B.JH_mean,     x1=B.MagLat_max, y1=B.JH_mean,   line=dict( color=MyColors[MyColorsIndex], width=2, )), row=SubPlotIdx, col=1 )    \n",
    "                # add info as legend for this bin\n",
    "                fig.append_trace( go.Scatter(name=B.ID + \":  \" + str(B.Altitude_min) + \"<Alt<\"+ str(B.Altitude_max) + \"  <b>\" + str(B.Kp_min) + \"<Kp<\" + str(B.Kp_max) + \"</b>\" + \"  Mean=\" + \"{:.3e}\".format(B.JH_mean) + \"  \" + \"Variance=\" + \"{:.3e}\".format(B.JH_variance) + \"  St.Deviation=\" + \"{:.3e}\".format(B.JH_variance**(1/2)), x=[-1], y=[-1], mode='markers', marker_size=1, marker_color=MyColors[MyColorsIndex]), row=SubPlotIdx, col=1 )\n",
    "                # add bin name above the mean line\n",
    "                BinAnnotations.append( dict( x=B.MagLat_min+((BinIdx+1)/len(BinsIncludedAtPlot))*(B.MagLat_max-B.MagLat_min)*3/4, y=B.JH_mean, text=B.ID, showarrow=False, yshift=8, font=dict(color=MyColors[MyColorsIndex]), xref='x1', yref='y'+str(SubPlotIdx) ) )\n",
    "                # add visuals for standard deviation\n",
    "                FigureShapes.append( dict(type=\"line\", x0=B.MagLat_min+((BinIdx+1)/len(BinsIncludedAtPlot))*(B.MagLat_max-B.MagLat_min)*7/8, y0=B.JH_mean+(B.JH_variance)**(1/2)/2,     x1=B.MagLat_min+((BinIdx+1)/len(BinsIncludedAtPlot))*(B.MagLat_max-B.MagLat_min)*7/8, y1=B.JH_mean-(B.JH_variance)**(1/2)/2,     line=dict( color=MyColors[MyColorsIndex], width=2, ), xref= 'x1', yref='y'+str(SubPlotIdx) )  )\n",
    "                #\n",
    "                BinIdx += 1\n",
    "        fig.update_layout( annotations=BinAnnotations )\n",
    "        fig.update_layout(shapes=FigureShapes)\n",
    "        fig.update_layout( title=SELECTED_VARIABLE_longname+\" vs Magnetic Latitude - \" + getBinDescription(CALCULATIONS_RegionName), \n",
    "                           width=1000, height=1500, legend_orientation=\"h\", legend= {'itemsizing': 'constant'}) \n",
    "        for i in range(0, len(All_KpRanges)):\n",
    "            fig.update_xaxes(range=[min(all_MagLat_values), max(all_MagLat_values)], title=\"Magnetic Latitude (degrees) for \" + str(All_KpRanges[i][0]) + \"<Kp<\"+  str(All_KpRanges[i][1]), row=i+1, col=1 )\n",
    "        fig.update_yaxes(range=[min(all_JH_values), JHmax], title=SELECTED_VARIABLE_shortname+\" (\"+SELECTED_VARIABLE_units+\")\", showexponent = 'all', exponentformat = 'e')\n",
    "        plotly.offline.init_notebook_mode(connected=True)\n",
    "        plotly.offline.iplot(fig)\n",
    "    else:\n",
    "        print( \"There are no points for MagLat per-Kp-range plot\" )                \n",
    "    \n",
    "    ##\n",
    "    if len(all_MLT_values) > 0  and  Plot_JHvsMLT_Checkbox.value == True:\n",
    "        fig = make_subplots(rows=len(All_KpRanges), cols=1, shared_xaxes=False, vertical_spacing=0.05)\n",
    "        for i in range(0, len(All_KpRanges)):\n",
    "            fig.append_trace( go.Scatter(name=SELECTED_VARIABLE_longname, x=MLT_values_perKp[i], y=JH_values_perKp[i], mode='markers', marker_size=2, marker_color=MyColors[i]), row=i+1, col=1 )\n",
    "        #\n",
    "        BinAnnotations = list()\n",
    "        FigureShapes = list()\n",
    "        MyColorsIndex = 0\n",
    "        BinIdx = 0\n",
    "        for B in BinsIncludedAtPlot:\n",
    "            if len(B.JH_values) > 0:\n",
    "                # choose which sub-plot will host this Bin's data\n",
    "                SubPlotIdx = 1\n",
    "                for i in range(0, len(All_KpRanges)):\n",
    "                    if B.Kp_min==All_KpRanges[i][0] and B.Kp_max==All_KpRanges[i][1]: SubPlotIdx = i+1\n",
    "                    #fig.update_xaxes(range=[min(MLT_values_perKp), max(MLT_values_perKp)], title=\"Magnetic Local Time (hours) for \" + str(All_KpRanges[i][0]) + \"<Kp<\"+  str(All_KpRanges[i][1]), row=SubPlotIdx, col=1 )                \n",
    "                # choose color for mean line\n",
    "                MyColorsIndex = SubPlotIdx - 1\n",
    "                # add visuals for the mean line             \n",
    "                FigureShapes.append( dict(type=\"line\", x0=MLT_min_toPlot, y0=B.JH_mean,     x1=MLT_max_toPlot, y1=B.JH_mean,   line=dict( color=MyColors[MyColorsIndex], width=2, ),  xref= 'x'+str(SubPlotIdx), yref= 'y'+str(SubPlotIdx))  ) \n",
    "                # add info as legend for this bin\n",
    "                fig.append_trace( go.Scatter(name=B.ID + \":  \" + str(B.Altitude_min) + \"<Alt<\"+ str(B.Altitude_max) + \"  <b>\" + str(B.Kp_min) + \"<Kp<\" + str(B.Kp_max) + \"</b>\" + \"  Mean=\" + \"{:.3e}\".format(B.JH_mean) + \"  \" + \"Variance=\" + \"{:.3e}\".format(B.JH_variance) + \"  St.Deviation=\" + \"{:.3e}\".format(B.JH_variance**(1/2)), x=[-1], y=[-1], mode='markers', marker_size=1, marker_color=MyColors[MyColorsIndex]), row=SubPlotIdx, col=1 )\n",
    "                # add bin name above the mean line\n",
    "                BinAnnotations.append(          dict( x=MLT_min_toPlot+((BinIdx+1)/len(BinsIncludedAtPlot))*(MLT_max_toPlot-MLT_min_toPlot)*3/4, y=B.JH_mean, text=B.ID, showarrow=False, yshift=8, font=dict(color=MyColors[MyColorsIndex]), xref='x1', yref='y'+str(SubPlotIdx)) )\n",
    "                FigureShapes.append( dict(type=\"line\", x0=MLT_min_toPlot+((BinIdx+1)/len(BinsIncludedAtPlot))*(MLT_max_toPlot-MLT_min_toPlot)*7/8, y0=B.JH_mean+(B.JH_variance)**(1/2)/2,     x1=MLT_min_toPlot+((BinIdx+1)/len(BinsIncludedAtPlot))*(MLT_max_toPlot-MLT_min_toPlot)*7/8, y1=B.JH_mean-(B.JH_variance)**(1/2)/2,     line=dict( color=MyColors[MyColorsIndex], width=2, ), xref= 'x1', yref= 'y'+str(SubPlotIdx) )  )\n",
    "                #\n",
    "                BinIdx += 1\n",
    "        fig.update_layout( annotations=BinAnnotations )\n",
    "        fig.update_layout( shapes=FigureShapes )\n",
    "        fig.update_layout( title=SELECTED_VARIABLE_longname+\" vs Magnetic Local Time - \" + getBinDescription(CALCULATIONS_RegionName), \n",
    "                           width=1000, height=1500, legend_orientation=\"h\", legend= {'itemsizing': 'constant'}) \n",
    "        #fig.update_xaxes(range=[MLT_min_toPlot, MLT_max_toPlot], title=\"Magnetic Local Time (hours)\")\n",
    "        for i in range(0, len(All_KpRanges)):\n",
    "            fig.update_xaxes(range=[MLT_min_toPlot, MLT_max_toPlot], title=\"Magnetic Local Time (hours) for \" + str(All_KpRanges[i][0]) + \"<Kp<\"+  str(All_KpRanges[i][1]), row=i+1, col=1 )\n",
    "        fig.update_yaxes(range=[min(all_JH_values), JHmax], title=SELECTED_VARIABLE_shortname+\" (\"+SELECTED_VARIABLE_units+\")\", showexponent = 'all', exponentformat = 'e')\n",
    "        plotly.offline.init_notebook_mode(connected=True)\n",
    "        plotly.offline.iplot(fig)\n",
    "    else:\n",
    "        print( \"There are no points for MLT per-Kp-range plot\" )        \n",
    "    \n",
    "    if len(all_Altitude_values) > 0  and  Plot_JHvsAltitude_Checkbox.value == True:\n",
    "        # the main scatter plot\n",
    "        fig = make_subplots(rows=len(All_KpRanges), cols=1, shared_xaxes=False, vertical_spacing=0.05)\n",
    "        for i in range(0, len(All_KpRanges)):\n",
    "            fig.append_trace( go.Scatter(name=SELECTED_VARIABLE_longname, x=Altitude_values_perKp[i], y=JH_values_perKp[i], mode='markers', marker_size=2, marker_color=MyColors[i]), row=i+1, col=1 )\n",
    "        # lines along neighbor points (according to time, only for orbit results)\n",
    "        if len(CALCULATIONS_OrbitFilesPath) > 0: \n",
    "            neighbors_JH   = list()\n",
    "            neighbors_Alt = list()\n",
    "            for i in range(0, len(All_KpRanges)):\n",
    "                for t in range(0, len(Time_values_perKp[i])):\n",
    "                    if t>0 and Time_values_perKp[i][t]-Time_values_perKp[i][t-1]<=10: # orbit file has 1 entry per 10 sec\n",
    "                        if len(neighbors_JH)==0:\n",
    "                            neighbors_JH.append( JH_values_perKp[i][t-1] )\n",
    "                            neighbors_Alt.append( Altitude_values_perKp[i][t-1] )\n",
    "                        neighbors_JH.append( JH_values_perKp[i][t] )\n",
    "                        neighbors_Alt.append( Altitude_values_perKp[i][t] )\n",
    "                    else:\n",
    "                        fig.append_trace( go.Scatter(x=neighbors_Alt, y=neighbors_JH, mode='lines', line_width=1, line_color=\"rgba(\"+Hex_to_RGB(MyColors[i])+\", 0.18)\", showlegend=False ), row=i+1, col=1)\n",
    "                        neighbors_JH   = list()\n",
    "                        neighbors_Alt = list()\n",
    "        # annotations, shapes etc\n",
    "        BinAnnotations = list()\n",
    "        FigureShapes = list()\n",
    "        MyColorsIndex = 0\n",
    "        BinIdx = 0\n",
    "        for B in BinsIncludedAtPlot:\n",
    "            if len(B.JH_values) > 0:\n",
    "                # choose which sub-plot will host this Bin's data\n",
    "                SubPlotIdx = 0\n",
    "                for i in range(0, len(All_KpRanges)):\n",
    "                    if B.Kp_min==All_KpRanges[i][0] and B.Kp_max==All_KpRanges[i][1]: SubPlotIdx = i+1\n",
    "                    fig.update_xaxes(range=[115, Altitude_max_toPlot], title=\"Altitude (km) for \" + str(All_KpRanges[i][0]) + \"<Kp<\"+  str(All_KpRanges[i][1]), row=i+1, col=1 )\n",
    "                # choose color for mean line\n",
    "                MyColorsIndex = SubPlotIdx - 1                \n",
    "                # add visuals for the mean line\n",
    "                FigureShapes.append( dict(type=\"line\", x0=B.Altitude_min, y0=B.JH_mean,     x1=B.Altitude_max, y1=B.JH_mean,   line=dict( color=MyColors[MyColorsIndex], width=2, ),  xref= 'x'+str(SubPlotIdx), yref= 'y'+str(SubPlotIdx))  )                \n",
    "                # add info as legend for this bin\n",
    "                fig.append_trace( go.Scatter(name=B.ID + \":  \" + str(B.Altitude_min) + \"<Alt<\"+ str(B.Altitude_max) + \"  <b>\" + str(B.Kp_min) + \"<Kp<\" + str(B.Kp_max) + \"</b>\" + \"  Mean=\" + \"{:.3e}\".format(B.JH_mean) + \"  \" + \"Variance=\" + \"{:.3e}\".format(B.JH_variance) + \"  St.Deviation=\" + \"{:.3e}\".format(B.JH_variance**(1/2)), x=[-1], y=[-1], mode='markers', marker_size=1, marker_color=MyColors[MyColorsIndex]), row=SubPlotIdx, col=1 )\n",
    "                # add bin name above the mean line\n",
    "                BinAnnotations.append( dict( x=B.Altitude_min+((BinIdx+1)/len(BinsIncludedAtPlot))*(B.Altitude_max-B.Altitude_min)*3/4, y=B.JH_mean, text=B.ID, showarrow=False, yshift=8, font=dict(color=MyColors[MyColorsIndex]), xref='x1', yref='y'+str(SubPlotIdx) ) )\n",
    "                # add visuals for standard deviation\n",
    "                FigureShapes.append( dict(type=\"line\", x0=B.Altitude_min+((BinIdx+1)/len(BinsIncludedAtPlot))*(B.Altitude_max-B.Altitude_min)*7/8, y0=B.JH_mean+(B.JH_variance)**(1/2)/2,     x1=B.Altitude_min+((BinIdx+1)/len(BinsIncludedAtPlot))*(B.Altitude_max-B.Altitude_min)*7/8, y1=B.JH_mean-(B.JH_variance)**(1/2)/2,     line=dict( color=MyColors[MyColorsIndex], width=2, ), xref= 'x1', yref= 'y'+str(SubPlotIdx) )  )\n",
    "                #\n",
    "                BinIdx += 1\n",
    "        fig.update_layout( annotations=BinAnnotations )\n",
    "        fig.update_layout( shapes=FigureShapes )\n",
    "        fig.update_layout( title=SELECTED_VARIABLE_longname+\" vs Altitude - \" + getBinDescription(CALCULATIONS_RegionName), \n",
    "                           width=1000, height=1500, legend_orientation=\"h\", legend= {'itemsizing': 'constant'}) \n",
    "        #fig.update_xaxes(range=[115, Altitude_max_toPlot], title=\"Altitude (km)\")\n",
    "        fig.update_yaxes(range=[min(all_JH_values), JHmax], title=SELECTED_VARIABLE_shortname+\" (\"+SELECTED_VARIABLE_units+\")\", showexponent = 'all', exponentformat = 'e')\n",
    "        plotly.offline.init_notebook_mode(connected=True)\n",
    "        plotly.offline.iplot(fig)\n",
    "    else:\n",
    "        print( \"There are no points for Altitude per-Kp-range plot\" )\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Y = a*X^k + c\n",
    "def func_powerlaw(x,  a, k, c):\n",
    "    return a * (x**k)  +  c\n",
    "\n",
    "# Y = a * log(X) + c\n",
    "def func_logarithmic(x,  a, c):\n",
    "    return [ (a * math.log(x_i) + c)  for x_i in x ]\n",
    "\n",
    "# Y = a / e ^ (bx) + c\n",
    "def func_euler(x,  a, b, c):\n",
    "    return [ (a / (math.e**(b*x_i)) + c) for x_i in x ]\n",
    "\n",
    "def func_maxwellian(x,  a, b, c):\n",
    "    return [ (a * x_i*x_i * (math.e**(-b*x_i)) + c) for x_i in x ]\n",
    "\n",
    "def Plot_JH_Distribution_perBin():\n",
    "    num_of_slots = 20\n",
    "    # choose which bins we are going to work with\n",
    "    if \"(\" in CALCULATIONS_RegionName:\n",
    "        RegionID = CALCULATIONS_RegionName[ CALCULATIONS_RegionName.find('(')+1 : CALCULATIONS_RegionName.rfind(')') ]\n",
    "    else:\n",
    "        RegionID = CALCULATIONS_RegionName\n",
    "    BinsIncludedAtPlot = list()\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID): BinsIncludedAtPlot.append( B )\n",
    "    \n",
    "    # init \n",
    "    #generalMean = sum(all_JH_values) / len(all_JH_values)\n",
    "    upper_value = (2)*BinsIncludedAtPlot[0].JH_mean\n",
    "    lower_value = 0\n",
    "    #upper_value = max(all_JH_values)\n",
    "    #lower_value = min(all_JH_values)\n",
    "    if lower_value > upper_value: # negative mean\n",
    "        tmp = lower_value\n",
    "        lower_value = upper_value\n",
    "        upper_value = tmp\n",
    "    slot_length = (upper_value - lower_value) / num_of_slots\n",
    "    if slot_length == 0: \n",
    "        print( \"No values for Distribution Plot\" )\n",
    "        return\n",
    "    \n",
    "    # calculate distribution for each bin\n",
    "    for B in BinsIncludedAtPlot:\n",
    "        B.JH_distribution = [0] * num_of_slots\n",
    "        #print(B.ID, \"distribution:\")\n",
    "        for aJHval in B.JH_values:\n",
    "            if aJHval >= lower_value  and    aJHval <= upper_value:\n",
    "                slot_idx = int(   (aJHval - lower_value) / slot_length  )\n",
    "            else:\n",
    "                continue\n",
    "            #print( \">>>>>> \", slot_idx, len(B.JH_distribution) )\n",
    "            if  slot_idx >= len(B.JH_distribution): slot_idx = num_of_slots-1\n",
    "            B.JH_distribution[ slot_idx ] += 1\n",
    "        #print(B.JH_distribution, \"\\n\")    \n",
    "    \n",
    "    # Normalize the distribution to [0,1] at y-axis\n",
    "    #for B in BinsIncludedAtPlot:\n",
    "    #    num_of_all_points_in_bin_distribution = sum(B.JH_distribution)\n",
    "    #    for slot_idx in range(0, len(B.JH_distribution)):\n",
    "    #        B.JH_distribution[ slot_idx ]  /=  num_of_all_points_in_bin_distribution\n",
    "    \n",
    "    # plot the distribution of all bins on the same figure\n",
    "    if len(all_JH_values) > 0  and  Plot_JHdistribution_Checkbox.value == True:\n",
    "        MyColorsIndex = 0\n",
    "        prevKpMin = -1\n",
    "        BinAnnotations = list()\n",
    "        BinIdx = 0\n",
    "        fig = go.Figure()        \n",
    "        print( \"Plotting \" + SELECTED_VARIABLE_longname + \" Distribution\" )\n",
    "        for B in BinsIncludedAtPlot:\n",
    "            if len(B.JH_values) > 0:\n",
    "                # choose color for this bin's points\n",
    "                if prevKpMin >= 0 and prevKpMin != B.Kp_min:\n",
    "                    MyColorsIndex += 1\n",
    "                    if MyColorsIndex>len(MyColors)-1: MyColorsIndex = 0\n",
    "                prevKpMin = B.Kp_min                        \n",
    "\n",
    "                if RegressionOptions_Dropdown.value.startswith( \"Polynomial\" ):\n",
    "                    # calculate the Polynomial Regression\n",
    "                    degree = int( RegressionOptions_Dropdown.value[-1] )\n",
    "                    myPolynomial = np.polyfit( list(range(0,num_of_slots)), B.JH_distribution, degree )\n",
    "                    # construct the equation to display\n",
    "                    poly_str = \"y = \"\n",
    "                    for i in range(0, len(myPolynomial)): \n",
    "                        if i>0 and myPolynomial[i] > 0: poly_str += \"+ \"\n",
    "                        poly_str += \"{:.2e}\".format(myPolynomial[i])\n",
    "                        if i < len(myPolynomial)-1: poly_str += \"x^\" + str(len(myPolynomial)-1-i) + \" \"\n",
    "                    # draw the Polynomial Regression\n",
    "                    mymodel = np.poly1d(myPolynomial)\n",
    "                    myline = np.linspace(1, num_of_slots, num_of_slots)\n",
    "                    fig.add_trace( go.Scatter(name=B.ID+\":  \"+poly_str, mode='lines', x=myline, y=mymodel(myline), line=dict(color=MyColors[MyColorsIndex], width=1) ) )\n",
    "                elif RegressionOptions_Dropdown.value == \"Power law\":\n",
    "                    try:\n",
    "                        OptimalParams, OptParamsCovariance = curve_fit(func_powerlaw, list(range(0,num_of_slots)), B.JH_distribution)\n",
    "                        poly_str = \"y = \" + \"{:.2e}\".format(OptimalParams[0]) + \" * x^\" + \"{:.2e}\".format(OptimalParams[1]) + \" + \" + \"{:.2e}\".format(OptimalParams[2])\n",
    "                        fig.add_trace( go.Scatter(name=B.ID+\":  \"+poly_str, mode='lines', x=list(range(0,num_of_slots)), y=func_powerlaw(list(range(0,num_of_slots)), *OptimalParams), line=dict(color=MyColors[MyColorsIndex], width=1) ) )\n",
    "                    except:\n",
    "                        print( \"Warning: Curve fit failed for\", B.ID )                                               \n",
    "                elif RegressionOptions_Dropdown.value == \"Logarithmic\":\n",
    "                    try:\n",
    "                        OptimalParams, OptParamsCovariance = curve_fit(func_logarithmic, list(range(1,num_of_slots)), B.JH_distribution[1:])\n",
    "                        poly_str = \"y = \" + \"{:.2e}\".format(OptimalParams[0]) + \" * log(x) +\" + \"{:.2e}\".format(OptimalParams[1])\n",
    "                        fig.add_trace( go.Scatter(name=B.ID+\":  \"+poly_str, mode='lines', x=list(range(1,num_of_slots)), y=func_logarithmic(list(range(1,num_of_slots)), *OptimalParams), line=dict(color=MyColors[MyColorsIndex], width=1) ) )\n",
    "                    except:\n",
    "                        print( \"Warning: Curve fit failed for\", B.ID )                        \n",
    "                elif RegressionOptions_Dropdown.value == \"Euler\":\n",
    "                    try:\n",
    "                        OptimalParams, OptParamsCovariance = curve_fit(func_euler, list(range(1,num_of_slots)), B.JH_distribution[1:])\n",
    "                        poly_str = \"y = \" + \"{:.2e}\".format(OptimalParams[0]) + \" / e^(\" + \"{:.2e}\".format(OptimalParams[1]) + \"*x) + \" + \"{:.2e}\".format(OptimalParams[2])\n",
    "                        fig.add_trace( go.Scatter(name=B.ID+\":  \"+poly_str, mode='lines', x=list(range(1,num_of_slots)), y=func_euler(list(range(1,num_of_slots)), *OptimalParams), line=dict(color=MyColors[MyColorsIndex], width=1) ) )\n",
    "                    except:\n",
    "                        print( \"Warning: Curve fit failed for\", B.ID )                        \n",
    "                elif RegressionOptions_Dropdown.value == \"Maxwell\":\n",
    "                    try:\n",
    "                        OptimalParams, OptParamsCovariance = curve_fit(func_maxwellian, list(range(1,num_of_slots)), B.JH_distribution[1:])\n",
    "                        poly_str = \"y = \" + \"{:.2e}\".format(OptimalParams[0]) + \" * x^2 * e^(-\" + \"{:.2e}\".format(OptimalParams[1]) + \"*x) + \" + \"{:.2e}\".format(OptimalParams[2])\n",
    "                        fig.add_trace( go.Scatter(name=B.ID+\":  \"+poly_str, mode='lines', x=list(range(1,num_of_slots)), y=func_maxwellian(list(range(1,num_of_slots)), *OptimalParams), line=dict(color=MyColors[MyColorsIndex], width=1) ) )                    \n",
    "                    except:\n",
    "                        print( \"Warning: Curve fit failed for\", B.ID )                        \n",
    "\n",
    "                # draw the distribution\n",
    "                bin_desciption = B.ID + \":  \" + str(B.Altitude_min) + \"<Alt<\"+ str(B.Altitude_max) + \"  <b>\" + str(B.Kp_min) + \"<Kp<\" + str(B.Kp_max) + \"</b>\" + \"  Mean=\" + \"{:.3e}\".format(B.JH_mean) + \"  \" + \"Variance=\" + \"{:.3e}\".format(B.JH_variance) + \"  St.Deviation=\" + \"{:.3e}\".format(B.JH_variance**(1/2))\n",
    "                fig.add_trace( go.Scatter(name=bin_desciption, x=list(range(0,num_of_slots)), y=B.JH_distribution, mode='markers', marker_size=3, marker_color=MyColors[MyColorsIndex]  ) )\n",
    "                \n",
    "                # add visuals for the mean line                \n",
    "                mean_slot_idx = int(   (B.JH_mean - lower_value) / slot_length  )\n",
    "                fig.add_shape( type=\"line\", x0=mean_slot_idx, y0=0,     x1=mean_slot_idx, y1=(95/100)*max(B.JH_distribution),     line=dict( color=MyColors[MyColorsIndex], width=1, ), )    \n",
    "                # add bin name above the mean line\n",
    "                BinAnnotations.append( dict( x=mean_slot_idx, y=(95/100)*max(B.JH_distribution), xref=\"x\", yref=\"y\", text=B.ID, showarrow=False, yshift=8, font=dict(color=MyColors[MyColorsIndex])) )\n",
    "                \n",
    "                # add visuals for standard deviation\n",
    "                #StDev_slots_width = int(   ((B.JH_variance)**(1/2)/2) / slot_length  )\n",
    "                #fig.add_shape( type=\"line\", x0=mean_slot_idx-StDev_slots_width, y0=(95/100)*max(B.JH_distribution),     x1=mean_slot_idx+StDev_slots_width, y1=(95/100)*max(B.JH_distribution),     line=dict( color=MyColors[MyColorsIndex], width=1, ), )\n",
    "                \n",
    "                BinIdx += 1\n",
    "                \n",
    "        # draw correct ticks at the x-axis, containing the JH values\n",
    "        XaxisTickPositions = list()\n",
    "        XaxisTickLabels = list()\n",
    "        for i in range( 0, num_of_slots, int(num_of_slots/5) ):\n",
    "            XaxisTickPositions.append( i )\n",
    "            XaxisTickLabels.append(  \"{:.3e}\".format(lower_value + i*slot_length)  )            \n",
    "        XaxisTickPositions.append( num_of_slots-1 )\n",
    "        XaxisTickLabels.append(  \"{:.3e}\".format(upper_value)  )\n",
    "        fig.update_xaxes( tickmode = 'array', tickvals=XaxisTickPositions,  ticktext=XaxisTickLabels )\n",
    "                \n",
    "        fig.update_layout( annotations=BinAnnotations )\n",
    "        fig.update_layout( title=SELECTED_VARIABLE_longname+\" Distribution per Bin - \" + getBinDescription(CALCULATIONS_RegionName), \n",
    "                           width=1000, height=900, legend_orientation=\"h\", legend= {'itemsizing': 'constant'}) \n",
    "        fig.update_xaxes(range=[0,num_of_slots-1], title=SELECTED_VARIABLE_shortname+\" (\"+SELECTED_VARIABLE_units+\")\", showexponent = 'all', exponentformat = 'e')\n",
    "        fig.update_yaxes(title=\"Number of hits inside the bin\") #rangemode='nonnegative'\n",
    "        plotly.offline.init_notebook_mode(connected=True)\n",
    "        plotly.offline.iplot(fig)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "# slack msg: May 26\n",
    "def Plot_Alex_Distribution():\n",
    "    num_of_slots = 25\n",
    "    # choose which bins we are going to work with\n",
    "    if \"(\" in CALCULATIONS_RegionName:\n",
    "        RegionID = CALCULATIONS_RegionName[ CALCULATIONS_RegionName.find('(')+1 : CALCULATIONS_RegionName.rfind(')') ]\n",
    "    else:\n",
    "        RegionID = CALCULATIONS_RegionName\n",
    "    BinsIncludedAtPlot = list()\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID): BinsIncludedAtPlot.append( B )\n",
    "\n",
    "\n",
    "    print( \"%%%%%%%%\")\n",
    "    print( len(BinsIncludedAtPlot) )\n",
    "    print( BinsIncludedAtPlot[0].JH_mean )\n",
    "    print( len(BinsIncludedAtPlot[0].JH_values) )\n",
    "            \n",
    "            \n",
    "    # merge all into one bin # TODO: remove after orbit calculation with correct sub-bins\n",
    "    if ( len(BinsIncludedAtPlot) == 3 ):\n",
    "        print( \"MERGING\" )\n",
    "        #BinsIncludedAtPlot[0].JH_values += BinsIncludedAtPlot[1].JH_values\n",
    "        #BinsIncludedAtPlot[0].JH_values += BinsIncludedAtPlot[2].JH_values\n",
    "        concatLists( BinsIncludedAtPlot[0].JH_values, BinsIncludedAtPlot[1].JH_values )\n",
    "        concatLists( BinsIncludedAtPlot[0].JH_values, BinsIncludedAtPlot[2].JH_values )\n",
    "        BinsIncludedAtPlot[0].JH_mean = sum(BinsIncludedAtPlot[0].JH_values) / len(BinsIncludedAtPlot[0].JH_values)\n",
    "        del BinsIncludedAtPlot[-1]\n",
    "        del BinsIncludedAtPlot[-1]\n",
    "            \n",
    "    \n",
    "    print( \"%%%%%%%%\")\n",
    "    print( len(BinsIncludedAtPlot) )\n",
    "    print( BinsIncludedAtPlot[0].JH_mean )\n",
    "    print( len(BinsIncludedAtPlot[0].JH_values) )\n",
    "    print( \"%%%%%%%%\")\n",
    "    \n",
    "    # init \n",
    "    #generalMean = sum(all_JH_values) / len(all_JH_values)\n",
    "    upper_value = (2)*BinsIncludedAtPlot[0].JH_mean\n",
    "    lower_value = 0\n",
    "    #upper_value = max(all_JH_values)\n",
    "    #lower_value = min(all_JH_values)\n",
    "    if lower_value > upper_value: # negative mean\n",
    "        tmp = lower_value\n",
    "        lower_value = upper_value\n",
    "        upper_value = tmp\n",
    "        \n",
    "    upper_value = 1.3e-8\n",
    "    \n",
    "    slot_length = (upper_value - lower_value) / num_of_slots\n",
    "    if slot_length == 0: \n",
    "        print( \"No values for Distribution Plot\" )\n",
    "        return\n",
    "    \n",
    "    # calculate distribution for each bin\n",
    "    for B in BinsIncludedAtPlot:\n",
    "        B.JH_distribution = [0] * num_of_slots\n",
    "        #print(B.ID, \"distribution:\")\n",
    "        for aJHval in B.JH_values:\n",
    "            if aJHval >= lower_value  and    aJHval <= upper_value:\n",
    "                slot_idx = int(   (aJHval - lower_value) / slot_length  )\n",
    "            else:\n",
    "                continue\n",
    "            #print( \">>>>>> \", slot_idx, len(B.JH_distribution) )\n",
    "            if  slot_idx >= len(B.JH_distribution): slot_idx = num_of_slots-1\n",
    "            B.JH_distribution[ slot_idx ] += 1\n",
    "        #print(B.JH_distribution, \"\\n\")    \n",
    "    \n",
    "    # Normalize the distribution to [0,1] at y-axis\n",
    "    #for B in BinsIncludedAtPlot:\n",
    "    #    num_of_all_points_in_bin_distribution = sum(B.JH_distribution)\n",
    "    #    for slot_idx in range(0, len(B.JH_distribution)):\n",
    "    #        B.JH_distribution[ slot_idx ]  /=  num_of_all_points_in_bin_distribution\n",
    "    \n",
    "    # plot the distribution of all bins on the same figure\n",
    "    if len(all_JH_values) > 0  and  Plot_JHdistribution_Checkbox.value == True:\n",
    "        MyColorsIndex = 0\n",
    "        prevKpMin = -1\n",
    "        BinAnnotations = list()\n",
    "        BinIdx = 0\n",
    "        fig = go.Figure()        \n",
    "        print( \"Plotting \" + SELECTED_VARIABLE_longname + \" Distribution\" )\n",
    "        for B in BinsIncludedAtPlot:\n",
    "            if len(B.JH_values) > 0:\n",
    "                # choose color for this bin's points\n",
    "                if prevKpMin >= 0 and prevKpMin != B.Kp_min:\n",
    "                    MyColorsIndex += 1\n",
    "                    if MyColorsIndex>len(MyColors)-1: MyColorsIndex = 0\n",
    "                prevKpMin = B.Kp_min                        \n",
    "\n",
    "                if RegressionOptions_Dropdown.value.startswith( \"Polynomial\" ):\n",
    "                    # calculate the Polynomial Regression\n",
    "                    degree = int( RegressionOptions_Dropdown.value[-1] )\n",
    "                    myPolynomial = np.polyfit( list(range(0,num_of_slots)), B.JH_distribution, degree )\n",
    "                    # construct the equation to display\n",
    "                    poly_str = \"y = \"\n",
    "                    for i in range(0, len(myPolynomial)): \n",
    "                        if i>0 and myPolynomial[i] > 0: poly_str += \"+ \"\n",
    "                        poly_str += \"{:.2e}\".format(myPolynomial[i])\n",
    "                        if i < len(myPolynomial)-1: poly_str += \"x^\" + str(len(myPolynomial)-1-i) + \" \"\n",
    "                    # draw the Polynomial Regression\n",
    "                    mymodel = np.poly1d(myPolynomial)\n",
    "                    myline = np.linspace(1, num_of_slots, num_of_slots)\n",
    "                    fig.add_trace( go.Scatter(name=B.ID+\":  \"+poly_str, mode='lines', x=myline, y=mymodel(myline), line=dict(color=MyColors[MyColorsIndex], width=1) ) )\n",
    "                elif RegressionOptions_Dropdown.value == \"Power law\":\n",
    "                    try:\n",
    "                        OptimalParams, OptParamsCovariance = curve_fit(func_powerlaw, list(range(0,num_of_slots)), B.JH_distribution)\n",
    "                        poly_str = \"y = \" + \"{:.2e}\".format(OptimalParams[0]) + \" * x^\" + \"{:.2e}\".format(OptimalParams[1]) + \" + \" + \"{:.2e}\".format(OptimalParams[2])\n",
    "                        fig.add_trace( go.Scatter(name=B.ID+\":  \"+poly_str, mode='lines', x=list(range(0,num_of_slots)), y=func_powerlaw(list(range(0,num_of_slots)), *OptimalParams), line=dict(color=MyColors[MyColorsIndex], width=1) ) )\n",
    "                    except:\n",
    "                        print( \"Warning: Curve fit failed for\", B.ID )                                               \n",
    "                elif RegressionOptions_Dropdown.value == \"Logarithmic\":\n",
    "                    try:\n",
    "                        OptimalParams, OptParamsCovariance = curve_fit(func_logarithmic, list(range(1,num_of_slots)), B.JH_distribution[1:])\n",
    "                        poly_str = \"y = \" + \"{:.2e}\".format(OptimalParams[0]) + \" * log(x) +\" + \"{:.2e}\".format(OptimalParams[1])\n",
    "                        fig.add_trace( go.Scatter(name=B.ID+\":  \"+poly_str, mode='lines', x=list(range(1,num_of_slots)), y=func_logarithmic(list(range(1,num_of_slots)), *OptimalParams), line=dict(color=MyColors[MyColorsIndex], width=1) ) )\n",
    "                    except:\n",
    "                        print( \"Warning: Curve fit failed for\", B.ID )                        \n",
    "                elif RegressionOptions_Dropdown.value == \"Euler\":\n",
    "                    try:\n",
    "                        OptimalParams, OptParamsCovariance = curve_fit(func_euler, list(range(1,num_of_slots)), B.JH_distribution[1:])\n",
    "                        poly_str = \"y = \" + \"{:.2e}\".format(OptimalParams[0]) + \" / e^(\" + \"{:.2e}\".format(OptimalParams[1]) + \"*x) + \" + \"{:.2e}\".format(OptimalParams[2])\n",
    "                        fig.add_trace( go.Scatter(name=B.ID+\":  \"+poly_str, mode='lines', x=list(range(1,num_of_slots)), y=func_euler(list(range(1,num_of_slots)), *OptimalParams), line=dict(color=MyColors[MyColorsIndex], width=3) ) )\n",
    "                    except:\n",
    "                        print( \"Warning: Curve fit failed for\", B.ID )                        \n",
    "                elif RegressionOptions_Dropdown.value == \"Maxwell\":\n",
    "                    try:\n",
    "                        OptimalParams, OptParamsCovariance = curve_fit(func_maxwellian, list(range(1,num_of_slots)), B.JH_distribution[1:])\n",
    "                        poly_str = \"y = \" + \"{:.2e}\".format(OptimalParams[0]) + \" * x^2 * e^(-\" + \"{:.2e}\".format(OptimalParams[1]) + \"*x) + \" + \"{:.2e}\".format(OptimalParams[2])\n",
    "                        fig.add_trace( go.Scatter(name=B.ID+\":  \"+poly_str, mode='lines', x=list(range(1,num_of_slots)), y=func_maxwellian(list(range(1,num_of_slots)), *OptimalParams), line=dict(color=MyColors[MyColorsIndex], width=1) ) )                    \n",
    "                    except:\n",
    "                        print( \"Warning: Curve fit failed for\", B.ID )                        \n",
    "\n",
    "                # draw the distribution\n",
    "                bin_desciption = B.ID + \":  \" + str(B.Altitude_min) + \"<Alt<\"+ str(B.Altitude_max) + \"  <b>\" + str(B.Kp_min) + \"<Kp<\" + str(B.Kp_max) + \"</b>\" + \"  Mean=\" + \"{:.3e}\".format(B.JH_mean) + \"  \" + \"Variance=\" + \"{:.3e}\".format(B.JH_variance) + \"  St.Deviation=\" + \"{:.3e}\".format(B.JH_variance**(1/2))\n",
    "                #fig.add_trace( go.Scatter(name=bin_desciption, x=list(range(0,num_of_slots)), y=B.JH_distribution, mode='markers', marker_size=3, marker_color=MyColors[MyColorsIndex]  ) )\n",
    "                #fig.add_trace( go.Bar(name=bin_desciption, x=list(range(0,num_of_slots)), y=B.JH_distribution, marker_color=\"LightSkyBlue\" ) )\n",
    "                \n",
    "                # add visuals for the mean line                \n",
    "                mean_slot_idx = int(   (B.JH_mean - lower_value) / slot_length  )\n",
    "                fig.add_shape( type=\"line\", x0=mean_slot_idx, y0=0,     x1=mean_slot_idx, y1=(95/100)*max(B.JH_distribution),     line=dict( color=MyColors[MyColorsIndex], width=1, ), )    \n",
    "                # add bin name above the mean line\n",
    "                BinAnnotations.append( dict( x=mean_slot_idx, y=(95/100)*max(B.JH_distribution), xref=\"x\", yref=\"y\", text=B.ID, showarrow=False, yshift=8, font=dict(color=MyColors[MyColorsIndex])) )\n",
    "                \n",
    "                # add visuals for standard deviation\n",
    "                #StDev_slots_width = int(   ((B.JH_variance)**(1/2)/2) / slot_length  )\n",
    "                #fig.add_shape( type=\"line\", x0=mean_slot_idx-StDev_slots_width, y0=(95/100)*max(B.JH_distribution),     x1=mean_slot_idx+StDev_slots_width, y1=(95/100)*max(B.JH_distribution),     line=dict( color=MyColors[MyColorsIndex], width=1, ), )\n",
    "                \n",
    "                BinIdx += 1\n",
    "                \n",
    "        # draw correct ticks at the x-axis, containing the JH values\n",
    "        XaxisTickPositions = list()\n",
    "        XaxisTickLabels = list()\n",
    "        for i in range( 0, num_of_slots, int(num_of_slots/5) ):\n",
    "            XaxisTickPositions.append( i )\n",
    "            XaxisTickLabels.append(  \"{:.3e}\".format(lower_value + i*slot_length)  )            \n",
    "        XaxisTickPositions.append( num_of_slots-1 )\n",
    "        XaxisTickLabels.append(  \"{:.3e}\".format(upper_value)  )\n",
    "        fig.update_xaxes( tickmode = 'array', tickvals=XaxisTickPositions,  ticktext=XaxisTickLabels )\n",
    "                \n",
    "        fig.update_layout( annotations=BinAnnotations )\n",
    "        fig.update_layout( title=SELECTED_VARIABLE_longname+\" Distribution per Bin - \" + getBinDescription(CALCULATIONS_RegionName), \n",
    "                           width=1000, height=900, legend_orientation=\"h\", legend= {'itemsizing': 'constant'}) \n",
    "        fig.update_xaxes(range=[0,num_of_slots-1], title=SELECTED_VARIABLE_shortname+\" (\"+SELECTED_VARIABLE_units+\")\", showexponent = 'all', exponentformat = 'e')\n",
    "        fig.update_yaxes(title=\"Number of hits inside the bin\") #rangemode='nonnegative'\n",
    "        plotly.offline.init_notebook_mode(connected=True)\n",
    "        plotly.offline.iplot(fig)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "def plotComparisonOfResults():\n",
    "    ColorTriplet = [\"#EEEEEE\", \"#FF4447\", \"#257985\"] # white red petrol\n",
    "    # init\n",
    "    BinIDs = list()\n",
    "    Means1 = list()\n",
    "    Means2 = list()\n",
    "    StDev1 = list()\n",
    "    StDev2 = list()\n",
    "    RegionDescription = \"\"\n",
    "    # load results no1\n",
    "    if SavedFilenames_Dropdown.value.endswith( \".nc\" ):\n",
    "        LoadResults_CDF( SavedFilenames_Dropdown.value )\n",
    "    else:\n",
    "        LoadResults( SavedFilenames_Dropdown.value )\n",
    "    for B in Bins:\n",
    "        if B.JH_mean != 0:\n",
    "            RegionDescription = B.Description\n",
    "            BinIDs.append( B.ID )\n",
    "            Means1.append( B.JH_mean )\n",
    "            StDev1.append( math.sqrt(B.JH_variance) )\n",
    "            print( B.ID, B.JH_mean, math.sqrt(B.JH_variance), B.JH_variance**(1/2) )\n",
    "    # load results no2\n",
    "    if SavedFilenames2_Dropdown.value.endswith( \".nc\" ):\n",
    "        LoadResults_CDF( SavedFilenames2_Dropdown.value )\n",
    "    else:\n",
    "        LoadResults( SavedFilenames2_Dropdown.value )\n",
    "\n",
    "    for B in Bins:\n",
    "        if B.JH_mean != 0:\n",
    "            Means2.append( B.JH_mean )\n",
    "            StDev2.append( math.sqrt(B.JH_variance) )\n",
    "    # plot bars chart\n",
    "    Bars = list()\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(name='TIEGCM - JH Mean', x=BinIDs, y=Means1, marker_color=ColorTriplet[1], offsetgroup=0),\n",
    "        go.Bar(name='Orbit  - JH Mean', x=BinIDs, y=Means2, marker_color=ColorTriplet[2], offsetgroup=1),\n",
    "        #go.Bar(name='JH StDv 1', x=BinIDs, y=StDev1, marker_color=\"red\",  offsetgroup=0, base=Means1),\n",
    "        #go.Bar(name='JH StDv 2', x=BinIDs, y=StDev2, marker_color=\"cyan\", offsetgroup=1, base=Means2)\n",
    "    ])\n",
    "    fig.update_layout(barmode='group', title='Statistics Comparison - '+RegionDescription , plot_bgcolor=ColorTriplet[0], yaxis = dict(showexponent = 'all',exponentformat = 'e'))\n",
    "    plotly.offline.init_notebook_mode(connected=True)\n",
    "    plotly.offline.iplot(fig) \n",
    "    print(\"Comparison plots finished.\")\n",
    "\n",
    "    \n",
    "\n",
    "# Returns \"Winter\", \"Spring\", \"Summer\" or \"Autumn\", depending on a UTC timestamp. Works for years 2015-2017\n",
    "#                                                                                                          1417392000=12/01/2014@12:00am(UTC)  \n",
    "# 1425168000=03/01/2015@12:00am(UTC) 1433116800=06/01/2015@12:00am(UTC) 1441065600=09/01/2015@12:00am(UTC) 1448928000=12/01/2015@12:00am(UTC)\n",
    "# 1456790400=03/01/2016@12:00am(UTC) 1464739200=06/01/2016@12:00am(UTC) 1472688000=09/01/2016@12:00am(UTC) 1480550400=12/01/2016@12:00am(UTC)\n",
    "# 1488326400=03/01/2017@12:00am(UTC) 1496275200=06/01/2017@12:00am(UTC) 1504224000=09/01/2017@12:00am(UTC) 1512086400=12/01/2017@12:00am(UTC)\n",
    "# 1519862400=03/01/2018@12:00am(UTC)\n",
    "def getSeason( UTCtimestamp ):\n",
    "    result = \"UTC timestamp exceed range of 20015-2017\"\n",
    "    if   UTCtimestamp>=1417392000 and UTCtimestamp<1425168000: \n",
    "        result = \"Winter\"\n",
    "    elif UTCtimestamp>=1425168000 and UTCtimestamp<1433116800: \n",
    "        result = \"Spring\"\n",
    "    elif UTCtimestamp>=1433116800 and UTCtimestamp<1441065600: \n",
    "        result = \"Summer\"        \n",
    "    elif UTCtimestamp>=1441065600 and UTCtimestamp<1448928000: \n",
    "        result = \"Autumn\"\n",
    "    elif UTCtimestamp>=1448928000 and UTCtimestamp<1456790400: \n",
    "        result = \"Winter\"\n",
    "    elif UTCtimestamp>=1456790400 and UTCtimestamp<1464739200: \n",
    "        result = \"Spring\"\n",
    "    elif UTCtimestamp>=1464739200 and UTCtimestamp<1472688000: \n",
    "        result = \"Summer\"\n",
    "    elif UTCtimestamp>=1472688000 and UTCtimestamp<1480550400: \n",
    "        result = \"Autumn\"        \n",
    "    elif UTCtimestamp>=1480550400 and UTCtimestamp<1488326400: \n",
    "        result = \"Winter\"                \n",
    "    elif UTCtimestamp>=1488326400 and UTCtimestamp<1496275200: \n",
    "        result = \"Spring\"        \n",
    "    elif UTCtimestamp>=1496275200 and UTCtimestamp<1504224000: \n",
    "        result = \"Summer\"                \n",
    "    elif UTCtimestamp>=1504224000 and UTCtimestamp<1512086400: \n",
    "        result = \"Autumn\"                \n",
    "    elif UTCtimestamp>=1512086400 and UTCtimestamp<1519862400: \n",
    "        result = \"Winter\"\n",
    "    #    \n",
    "    return result\n",
    "    \n",
    "    \n",
    "'''    \n",
    "def plotAltitudeProfiles_perSeason( plot_all_seasons_together ):\n",
    "    if Plot_AltProfilesCanonical_Checkbox.value == False: return # <<<\n",
    "    # init parameters\n",
    "    if SELECTED_VARIABLE == \"Ohmic\":\n",
    "        x_axes_range=[0, 6] # JH\n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"\n",
    "    elif SELECTED_VARIABLE == \"SIGMA_PED\":\n",
    "        x_axes_range=[0, 0.3]\n",
    "        MultiplicationFactor = 10**3 \n",
    "        new_units = \"mS/m\"\n",
    "    elif SELECTED_VARIABLE == \"SIGMA_HAL\":\n",
    "        x_axes_range=[0, 1.5]\n",
    "        MultiplicationFactor = 10**3 \n",
    "        new_units = \"mS/m\"        \n",
    "    else:\n",
    "        x_axes_range=[0, 100] \n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"?\"\n",
    "        \n",
    "    # init data structures\n",
    "    Profiles = dict()\n",
    "    MLT_duration_of_a_profile = 3\n",
    "    ALT_distance_of_a_bucket  = 4\n",
    "    MLTsequence     = list( range( 0,  24, MLT_duration_of_a_profile) )\n",
    "    ALTsequence     = list( range(80, 150, ALT_distance_of_a_bucket ) )\n",
    "    if plot_all_seasons_together:\n",
    "        SEASONSsequence = [ \"All Seasons\" ]\n",
    "    else:\n",
    "        SEASONSsequence = [ \"Spring\", \"Summer\", \"Autumn\", \"Winter\" ] \n",
    "    if len(SEASONSsequence) > 1: x_axes_range[1] *= 1.4\n",
    "    for aMLT in MLTsequence:\n",
    "        for anALT in ALTsequence:\n",
    "            for aSEASON in SEASONSsequence:\n",
    "                Profiles[(aSEASON, aMLT, anALT)] = list()\n",
    "        \n",
    "    # parse all values and decide into which sum they must fall\n",
    "    for i in range( 0, len(all_Time_values) ):\n",
    "        mlt_to_fall = alt_to_fall = -1        \n",
    "        # find correct season\n",
    "        if SEASONSsequence[0] == \"All Seasons\":\n",
    "            season_to_fall = \"All Seasons\"\n",
    "        else:\n",
    "            season_to_fall = getSeason( all_Time_values[i] )     \n",
    "        if len(season_to_fall) > 15: print(\"Error: wrong season for idx =\", i, \"  UTC =\",  all_Time_values[i], season_to_fall )        \n",
    "        # find correct MLT\n",
    "        for seq_idx in range(1, len(MLTsequence)):\n",
    "            if all_MLT_values[i] < MLTsequence[seq_idx]: \n",
    "                mlt_to_fall=MLTsequence[seq_idx-1]\n",
    "                break\n",
    "        if mlt_to_fall == -1: mlt_to_fall = MLTsequence[len(MLTsequence)-1] # for hour=24                \n",
    "        # find correct Alt\n",
    "        for seq_idx in range(1, len(ALTsequence)):\n",
    "            if all_Altitude_values[i] < ALTsequence[seq_idx]: \n",
    "                alt_to_fall=ALTsequence[seq_idx-1]\n",
    "                break\n",
    "        if alt_to_fall == -1: continue # ignore highest altitudes\n",
    "        # store the value at the right place\n",
    "        Profiles[ (season_to_fall, mlt_to_fall, alt_to_fall) ].append( all_JH_values[ i ] )\n",
    "    \n",
    "    # plot\n",
    "    fig = make_subplots(rows=len(SEASONSsequence), cols=8, shared_xaxes=True, shared_yaxes=True, vertical_spacing=0.02, subplot_titles=(\"0-3\", \"3-6\", \"6-9\", \"9-12\", \"12-15\", \"15-18\", \"18-21\", \"21-24\"))\n",
    "    for aSEASON in SEASONSsequence:\n",
    "        for aMLT in MLTsequence:\n",
    "            Means = list()\n",
    "            Percentiles10 = list()\n",
    "            Percentiles25 = list()\n",
    "            Percentiles50 = list()\n",
    "            Percentiles75 = list()\n",
    "            Percentiles90 = list()\n",
    "            hits  = 0\n",
    "            for anALT in ALTsequence:\n",
    "                hits += len(Profiles[(aSEASON, aMLT, anALT)])\n",
    "                if len(Profiles[(aSEASON, aMLT, anALT)]) > 0:\n",
    "                    Means.append(  sum(Profiles[(aSEASON, aMLT, anALT)]) / len(Profiles[(aSEASON, aMLT, anALT)]) )\n",
    "                    Percentiles10.append( np.percentile(Profiles[(aSEASON, aMLT, anALT)], 10) )\n",
    "                    Percentiles25.append( np.percentile(Profiles[(aSEASON, aMLT, anALT)], 25) )\n",
    "                    Percentiles50.append( np.percentile(Profiles[(aSEASON, aMLT, anALT)], 50) )\n",
    "                    Percentiles75.append( np.percentile(Profiles[(aSEASON, aMLT, anALT)], 75) )\n",
    "                    Percentiles90.append( np.percentile(Profiles[(aSEASON, aMLT, anALT)], 90) )\n",
    "                else:\n",
    "                    Means.append( 0 )\n",
    "                    Percentiles10.append( 0 )\n",
    "                    Percentiles25.append( 0 )\n",
    "                    Percentiles50.append( 0 )\n",
    "                    Percentiles75.append( 0 )\n",
    "                    Percentiles90.append( 0 )\n",
    "            print( aSEASON, \"MLT =\", aMLT, \"  Hits =\", hits )\n",
    "            \n",
    "            # change units\n",
    "            for i in range(0,len(Means)): \n",
    "                Means[i] *= MultiplicationFactor\n",
    "                Percentiles75[i] *= MultiplicationFactor\n",
    "                Percentiles90[i] *= MultiplicationFactor\n",
    "            \n",
    "            # plot percentiles 10th, 25th, 50th\n",
    "            fig.add_trace( go.Scatter(x=Percentiles10, y=ALTsequence, mode='lines', fill='tonexty', fillcolor='red', line=dict(color='gray',width=1,), showlegend=False), row=SEASONSsequence.index(aSEASON)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            fig.add_trace( go.Scatter(x=Percentiles25, y=ALTsequence, mode='lines', fill='tonexty', fillcolor='yellow', line=dict(color='gray',width=1,), showlegend=False), row=SEASONSsequence.index(aSEASON)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            fig.add_trace( go.Scatter(x=Percentiles50, y=ALTsequence, mode='lines', fill='tonexty', fillcolor='green', line=dict(color='gray',width=1,), showlegend=False), row=SEASONSsequence.index(aSEASON)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            # plot mean\n",
    "            fig.add_trace( go.Scatter(x=Means, y=ALTsequence, mode='lines', fill='tonexty', fillcolor='#1995ad', line=dict(color='black',width=1,), showlegend=False), row=SEASONSsequence.index(aSEASON)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            # plot percentiles 75th, 90th\n",
    "            fig.add_trace( go.Scatter(x=Percentiles75, y=ALTsequence, mode='lines', fill='tonexty', fillcolor='#a1d6e2', line=dict(color='gray',width=1,), showlegend=False), row=SEASONSsequence.index(aSEASON)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            fig.add_trace( go.Scatter(x=Percentiles90, y=ALTsequence, mode='lines', fill='tonexty', fillcolor='#c4dfe6', line=dict(color='gray',width=1,), showlegend=False), row=SEASONSsequence.index(aSEASON)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "\n",
    "    fig.add_trace( go.Scatter(name='Mean value', x=Means, y=ALTsequence, mode='lines', fill='tonexty', fillcolor='#5cc5ef', line=dict(color='black',width=1,), showlegend=True), row=SEASONSsequence.index(aSEASON)+1, col=MLTsequence.index(aMLT)+1 )            \n",
    "    fig.add_trace( go.Scatter(name='75th Percentile', x=Percentiles75, y=ALTsequence, mode='lines', fill='tonexty', fillcolor='#a1d6e2', line=dict(color='gray',width=1,), showlegend=True), row=SEASONSsequence.index(aSEASON)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "    fig.add_trace( go.Scatter(name='90th Percentile', x=Percentiles90, y=ALTsequence, mode='lines', fill='tonexty', fillcolor='#c4dfe6', line=dict(color='gray',width=1,), showlegend=True), row=SEASONSsequence.index(aSEASON)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            \n",
    "    #fig.update_yaxes( title=\"Altitude(km)\" )\n",
    "    for aSEASON in SEASONSsequence:\n",
    "        fig.update_yaxes( title_text=\"Altitude (km)\", row=SEASONSsequence.index(aSEASON)+1, col=1)\n",
    "        fig.update_yaxes( title_text=aSEASON, row=SEASONSsequence.index(aSEASON)+1, col=8, side='right' )\n",
    "    fig.update_xaxes( range=x_axes_range )        \n",
    "    fig.update_yaxes( range=[80, 150] )  \n",
    "    fig.update_layout( title = getBinDescription(CALCULATIONS_RegionName) + \" - \" + \"Altitude Profile of \" + SELECTED_VARIABLE_longname + \" (\" + new_units + \")\",\n",
    "                       width=1000, height=200+200*len(SEASONSsequence), showlegend=True) \n",
    "    plotly.offline.init_notebook_mode(connected=True)\n",
    "    plotly.offline.iplot(fig) \n",
    "'''\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "Profiles = dict()    \n",
    "MLTsequence = list()\n",
    "ALTsequence = list()\n",
    "MLT_duration_of_a_profile = 0\n",
    "ALT_distance_of_a_bucket = 0\n",
    "regionMLTmax = 0\n",
    "regionMLTmin = 0\n",
    "ProfilesUpdateLock = threading.Lock()   \n",
    "class Thread_AltProfBinner (threading.Thread):\n",
    "    def __init__(self, from_idx, to_idx):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.from_idx = from_idx\n",
    "        self.to_idx = to_idx\n",
    "    def run(self):\n",
    "        global Profiles\n",
    "        for i in range( self.from_idx, self.to_idx ):\n",
    "            mlt_to_fall = alt_to_fall = -1  \n",
    "            # find correct Alt\n",
    "            for seq_idx in range(0, len(ALTsequence)):\n",
    "                if all_Altitude_values[i]>=ALTsequence[seq_idx] and all_Altitude_values[i]<ALTsequence[seq_idx]+ALT_distance_of_a_bucket:\n",
    "                    alt_to_fall=ALTsequence[seq_idx]\n",
    "                    break\n",
    "            if alt_to_fall == -1: continue # ignore highest altitudes        \n",
    "            # find correct kp\n",
    "            if all_Kp_values[i] < 2: \n",
    "                kp_to_fall = 0\n",
    "            elif all_Kp_values[i] < 4:  \n",
    "                kp_to_fall = 2\n",
    "            else:\n",
    "                kp_to_fall = 4\n",
    "            # find correct MLT\n",
    "            MLT_tocheck = all_MLT_values[i]\n",
    "            if regionMLTmax>24  and  MLT_tocheck<=regionMLTmax-24:\n",
    "                MLT_tocheck += 24\n",
    "            for seq_idx in range(0, len(MLTsequence)):\n",
    "                if MLT_tocheck>=MLTsequence[seq_idx] and MLT_tocheck<MLTsequence[seq_idx]+MLT_duration_of_a_profile: \n",
    "                    mlt_to_fall=MLTsequence[seq_idx]\n",
    "                    break\n",
    "            if MLT_tocheck == MLTsequence[len(MLTsequence)-1]+MLT_duration_of_a_profile: mlt_to_fall = MLTsequence[len(MLTsequence)-1] # for last MLT position\n",
    "            # store the value at the right place\n",
    "            #ProfilesUpdateLock.acquire()\n",
    "            Profiles[ (kp_to_fall, mlt_to_fall, alt_to_fall) ].append( all_JH_values[ i ] )\n",
    "            #ProfilesUpdateLock.release()   \n",
    "\n",
    "    \n",
    "def plotAltProfilesCanonical_perKpRange( ):\n",
    "    global Profiles, MLTsequence, ALTsequence, MLT_duration_of_a_profile, ALT_distance_of_a_bucket, regionMLTmax, regionMLTmin\n",
    "    if Plot_AltProfilesCanonical_Checkbox.value == False: return # <<<\n",
    "    # init parameters\n",
    "    if SELECTED_VARIABLE == \"Ohmic\":\n",
    "        x_axes_range=[0, 6]\n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"\n",
    "    elif SELECTED_VARIABLE == \"SIGMA_PED\":\n",
    "        x_axes_range=[0, 0.15]\n",
    "        MultiplicationFactor = 10**3 \n",
    "        new_units = \"mS/m\"\n",
    "    elif SELECTED_VARIABLE == \"SIGMA_HAL\":\n",
    "        x_axes_range=[0, 0.4] \n",
    "        MultiplicationFactor = 10**3 \n",
    "        new_units = \"mS/m\"        \n",
    "    elif SELECTED_VARIABLE == \"Convection_heating\":\n",
    "        x_axes_range=[0, 6] \n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"           \n",
    "    elif SELECTED_VARIABLE == \"Wind_heating\":\n",
    "        x_axes_range=[0, 6] \n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"                   \n",
    "    elif SELECTED_VARIABLE == \"EEX_si\" or SELECTED_VARIABLE == \"EEY_si\":\n",
    "        x_axes_range=[-24, 0] \n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"mV/m\"        \n",
    "    else:\n",
    "        x_axes_range=[0, 100] \n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"?\" \n",
    "        \n",
    "    print(SELECTED_VARIABLE)\n",
    "\n",
    "    # Region specific binning:\n",
    "    if \"(\" in CALCULATIONS_RegionName:\n",
    "        RegionID = CALCULATIONS_RegionName[ CALCULATIONS_RegionName.find('(')+1 : CALCULATIONS_RegionName.rfind(')') ]\n",
    "    else:\n",
    "        RegionID = CALCULATIONS_RegionName\n",
    "    regionMLTmin = 999\n",
    "    regionMLTmax = -999\n",
    "    regionALTmin = 999\n",
    "    regionALTmax = -999\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith( RegionID ):\n",
    "            if regionMLTmin>B.MLT_min: regionMLTmin = B.MLT_min\n",
    "            if regionMLTmax<B.MLT_max: regionMLTmax = B.MLT_max\n",
    "            if regionALTmin>B.Altitude_min: regionALTmin = B.Altitude_min\n",
    "            if regionALTmax<B.Altitude_max: regionALTmax = B.Altitude_max\n",
    "    if regionMLTmax < regionMLTmin: regionMLTmax += 24\n",
    "        \n",
    "    # find lowest altitude\n",
    "    LowestAltitude = 999999\n",
    "    for i in range(0, len(all_Altitude_values)):\n",
    "        if LowestAltitude > all_Altitude_values[i]: LowestAltitude = all_Altitude_values[i]\n",
    "    \n",
    "    # init data structures\n",
    "    Profiles = dict()\n",
    "    if \"TRO\" in RegionID:\n",
    "        MLT_duration_of_a_profile = 3        \n",
    "    else:\n",
    "        MLT_duration_of_a_profile = 6\n",
    "    ALT_distance_of_a_bucket  = 5\n",
    "    MLTsequence     = list( range( regionMLTmin, regionMLTmax, MLT_duration_of_a_profile) )\n",
    "    ALTsequence     = list( range( regionALTmin, regionALTmax, ALT_distance_of_a_bucket ) )\n",
    "    KPsequence      = [ 0, 2, 4 ] \n",
    "    for aMLT in MLTsequence:\n",
    "        for anALT in ALTsequence:\n",
    "            for aKP in KPsequence:\n",
    "                Profiles[(aKP, aMLT, anALT)] = list()\n",
    "    \n",
    "    print( \"Parsing\", len(all_JH_values), \"values.\", datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\") )\n",
    "    # parse all values and decide into which sum they must fall\n",
    "    AllThreads = list()\n",
    "    positions_per_thread = int ( len(all_JH_values) / 10 )\n",
    "    from_pos = 0\n",
    "    while from_pos < len(all_JH_values):\n",
    "        # calculate boundaries for thread\n",
    "        to_pos = from_pos + positions_per_thread\n",
    "        if to_pos >= len(all_JH_values): to_pos = len(all_JH_values)-1\n",
    "        if len(all_JH_values)-to_pos<positions_per_thread : to_pos = len(all_JH_values)-1\n",
    "        # spawn new thread\n",
    "        print(\"Thread:\", from_pos, \"-\", to_pos, \" of \" ,len(all_JH_values), \"positions\")\n",
    "        T = Thread_AltProfBinner(from_pos, to_pos)\n",
    "        AllThreads.append(T)\n",
    "        T.start()\n",
    "        # go on\n",
    "        from_pos += positions_per_thread\n",
    "        \n",
    "    # wait for all threads to terminate\n",
    "    for T in AllThreads: T.join()\n",
    "\n",
    "    # plot\n",
    "    Color10 = '#c4dfe6'\n",
    "    Color25 = '#a1d6e2'\n",
    "    Color50 = '#1995ad'\n",
    "    Color75 = '#a1d6e2'\n",
    "    Color90 = '#c4dfe6'\n",
    "    \n",
    "    # construct the column MLT titles #(\"0-3\", \"3-6\", \"6-9\", \"9-12\", \"12-15\", \"15-18\", \"18-21\", \"21-24\")\n",
    "    ColumnTitles = list()\n",
    "    \n",
    "    for i in range(0, len(MLTsequence)):\n",
    "        ColumnTitles.append( \"MLT \" + str(MLTsequence[i]) + \"-\"  + str(MLTsequence[i]+MLT_duration_of_a_profile) )\n",
    "    # define secondary y-axis at the right of the plot\n",
    "    mySpecs = list()\n",
    "    for row in range(0, len(KPsequence)):\n",
    "        mySpecs.append( list() )\n",
    "        for col in range(0, len(MLTsequence)):\n",
    "            mySpecs[row].append( {\"secondary_y\": True} )\n",
    "        \n",
    "    #make plot\n",
    "    fig = make_subplots(rows=len(KPsequence), cols=len(MLTsequence), shared_xaxes=True, shared_yaxes=True, vertical_spacing=0.035, horizontal_spacing=0.01, subplot_titles=ColumnTitles, specs=mySpecs)\n",
    "    for aKP in KPsequence:\n",
    "        for aMLT in MLTsequence:\n",
    "            #Means = list()\n",
    "            Percentiles10 = list()\n",
    "            Percentiles25 = list()\n",
    "            Percentiles50 = list()            \n",
    "            Percentiles75 = list()\n",
    "            Percentiles90 = list()\n",
    "            visibleALTsequence = list()\n",
    "            hits  = 0\n",
    "            for anALT in ALTsequence:\n",
    "                print(\"  \", anALT, \"km     hits =\",  len(Profiles[(aKP, aMLT, anALT)]))\n",
    "                hits += len(Profiles[(aKP, aMLT, anALT)])\n",
    "                if len(Profiles[(aKP, aMLT, anALT)]) > 0:\n",
    "                    #Means.append(  sum(Profiles[(aKP, aMLT, anALT)]) / len(Profiles[(aKP, aMLT, anALT)]) )\n",
    "                    Percentiles10.append( np.percentile(Profiles[(aKP, aMLT, anALT)], 10) )\n",
    "                    Percentiles25.append( np.percentile(Profiles[(aKP, aMLT, anALT)], 25) )\n",
    "                    Percentiles50.append( np.percentile(Profiles[(aKP, aMLT, anALT)], 50) )                    \n",
    "                    Percentiles75.append( np.percentile(Profiles[(aKP, aMLT, anALT)], 75) )\n",
    "                    Percentiles90.append( np.percentile(Profiles[(aKP, aMLT, anALT)], 90) )\n",
    "                    visibleALTsequence.append( anALT )\n",
    "                #else:\n",
    "                    #Means.append( 0 )\n",
    "                    #Percentiles10.append( 0 )\n",
    "                    #Percentiles25.append( 0 )\n",
    "                    #Percentiles50.append( 0 )                    \n",
    "                    #Percentiles75.append( 0 )\n",
    "                    #Percentiles90.append( 0 )\n",
    "            print( \"Kp = \", aKP, \"MLT =\", aMLT, \"   Hits =\", hits, \"  \", datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\") )\n",
    "            \n",
    "            # change units\n",
    "            for i in range(0,len(Percentiles50)): \n",
    "                #Means[i] *= MultiplicationFactor\n",
    "                Percentiles10[i] *= MultiplicationFactor\n",
    "                Percentiles25[i] *= MultiplicationFactor\n",
    "                Percentiles50[i] *= MultiplicationFactor\n",
    "                Percentiles75[i] *= MultiplicationFactor\n",
    "                Percentiles90[i] *= MultiplicationFactor\n",
    "            \n",
    "            # alter visibleALTsequence so that data are displayed correctly\n",
    "            #print(ALTsequence)\n",
    "            #print( Profiles[(aKP, aMLT, anALT)] )\n",
    "            #print( visibleALTsequence )\n",
    "            #print( Percentiles50 )            \n",
    "            for i in range(0, len(visibleALTsequence)):\n",
    "                visibleALTsequence[i] += ALT_distance_of_a_bucket/2\n",
    "            #for anALT in ALTsequence:\n",
    "            #    if len(Profiles[(aKP, aMLT, anALT)]) > 0:\n",
    "            #        visibleALTsequence[0]  = anALT #regionALTmin\n",
    "            #        break\n",
    "            visibleALTsequence[0] = LowestAltitude\n",
    "            visibleALTsequence[-1] = regionALTmax\n",
    "            #print( visibleALTsequence )\n",
    "            \n",
    "            fig.add_trace( go.Scatter(x=[0]*len(visibleALTsequence), y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color10, line=dict(color='gray',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            fig.add_trace( go.Scatter(x=Percentiles10, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color10, line=dict(color='gray',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            fig.add_trace( go.Scatter(x=Percentiles25, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color25, line=dict(color='gray',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            fig.add_trace( go.Scatter(x=Percentiles50, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color50, line=dict(color='black',width=2,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            # plot mean\n",
    "            #fig.add_trace( go.Scatter(x=Means, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor='black', line=dict(color='black',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            # plot percentiles\n",
    "            fig.add_trace( go.Scatter(x=Percentiles75, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color75, line=dict(color='gray',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            fig.add_trace( go.Scatter(x=Percentiles90, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color90, line=dict(color='gray',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1,  )\n",
    "            # add a trace in order to display secondary y-axis at the right\n",
    "            fig.add_trace( go.Scatter(x=[-1000], y=[-1000], showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1, secondary_y=True )\n",
    "            \n",
    "    # display legends\n",
    "    fig.add_trace( go.Scatter(name='10th Perc.', x=Percentiles10, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color10, line=dict(color='gray',width=1,), showlegend=True), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "    fig.add_trace( go.Scatter(name='25th Perc.', x=Percentiles25, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color25, line=dict(color='gray',width=1,), showlegend=True), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "    fig.add_trace( go.Scatter(name='50th Perc.', x=Percentiles50, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color50, line=dict(color='black',width=2,), showlegend=True), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "    #fig.add_trace( go.Scatter(name='Mean value', x=Means, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor='#5cc5ef', line=dict(color='black',width=1,), showlegend=True), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )            \n",
    "    fig.add_trace( go.Scatter(name='75th Perc.', x=Percentiles75, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color75, line=dict(color='gray',width=1,), showlegend=True), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "    fig.add_trace( go.Scatter(name='90th Perc.', x=Percentiles90, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color90, line=dict(color='gray',width=1,), showlegend=True), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "    \n",
    "    \n",
    "    #fig.update_yaxes( title=\"Altitude(km)\" )\n",
    "    for aKP in KPsequence:\n",
    "        fig.update_yaxes( title_text=\"Altitude (km)\", row=KPsequence.index(aKP)+1, col=1, side='left', secondary_y=False)\n",
    "        row_title = \"Kp \" + str(aKP) + \" - \"\n",
    "        if aKP == 0:\n",
    "            row_title +=  \"2\"\n",
    "        elif aKP == 2:\n",
    "            row_title +=  \"4\"\n",
    "        else:\n",
    "            row_title +=  \"9\"\n",
    "        fig.update_yaxes( title_text=row_title, row=KPsequence.index(aKP)+1, col=len(MLTsequence),  side='right', secondary_y=True, showticklabels=False )\n",
    "        for aMLT in MLTsequence:\n",
    "            fig.update_yaxes( row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1, secondary_y=True, showticklabels=False )\n",
    "    fig.update_xaxes( range=x_axes_range )\n",
    "    fig.update_yaxes( range=[80, 150], dtick=10 )  \n",
    "    fig.update_layout( title = getBinDescription(CALCULATIONS_RegionName) + \"<br>\" + \"Alt.Prof. of \" + SELECTED_VARIABLE_longname + \" (\" + new_units + \")\",\n",
    "                       width=280+len(MLTsequence)*100, height=200+200*len(KPsequence), showlegend=True, legend_orientation=\"h\", legend_y=-0.04) \n",
    "    plotly.offline.init_notebook_mode(connected=True)\n",
    "    plotly.offline.iplot(fig) \n",
    "    \n",
    "    # plot more zoom versions\n",
    "    new_x_axes_range = [x * (2/3) for x in x_axes_range]\n",
    "    fig.update_xaxes( range=new_x_axes_range )\n",
    "    plotly.offline.iplot(fig) \n",
    "    new_x_axes_range = [x * (1/2) for x in x_axes_range]\n",
    "    fig.update_xaxes( range=new_x_axes_range )\n",
    "    plotly.offline.iplot(fig) \n",
    "    new_x_axes_range = [x * (3/2) for x in x_axes_range]\n",
    "    fig.update_xaxes( range=new_x_axes_range )\n",
    "    plotly.offline.iplot(fig) \n",
    "    new_x_axes_range = [x * (2.5) for x in x_axes_range]\n",
    "    fig.update_xaxes( range=new_x_axes_range )\n",
    "    plotly.offline.iplot(fig) \n",
    "    \n",
    "    \n",
    "DiskAccessLock = threading.Lock()   \n",
    "class Thread_ValueAssigner (threading.Thread):\n",
    "    def __init__(self, DataFilename, ResultsFilename):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.DataFilename = DataFilename\n",
    "        self.ResultsFilename = ResultsFilename\n",
    "    def run(self):\n",
    "        DataFilename = self.DataFilename\n",
    "        ResultsFilename = self.ResultsFilename\n",
    "        print( \"Thread start\",  datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\"), ResultsFilename, \"\\n\" )\n",
    "        MagLat_min =  1000\n",
    "        MagLat_max = -1000\n",
    "        MLT_min    =  1000\n",
    "        MLT_max    = -1000\n",
    "        Altitude_min    =  1000\n",
    "        Altitude_max    = -1000\n",
    "        Lat_min     =  1000\n",
    "        Lat_max     = -1000    \n",
    "        Kp_min     =  1000\n",
    "        Kp_max     = -1000\n",
    "        localBins = copy.deepcopy(Bins)\n",
    "        for B in localBins:\n",
    "            B.reset()\n",
    "            if B.MagLat_min < MagLat_min: MagLat_min = B.MagLat_min \n",
    "            if B.MagLat_max > MagLat_max: MagLat_max = B.MagLat_max\n",
    "            if B.MLT_min < MLT_min: MLT_min = B.MLT_min \n",
    "            if B.MLT_max > MLT_max: MLT_max = B.MLT_max\n",
    "            if B.Altitude_min < Altitude_min: Altitude_min = B.Altitude_min \n",
    "            if B.Altitude_max > Altitude_max: Altitude_max = B.Altitude_max\n",
    "            if B.Lat_min < Lat_min: Lat_min = B.Lat_min \n",
    "            if B.Lat_max > Lat_max: Lat_max = B.Lat_max                        \n",
    "            if B.Kp_min < Kp_min: Kp_min = B.Kp_min \n",
    "            if B.Kp_max > Kp_max: Kp_max = B.Kp_max            \n",
    "        all_JH_values       = list()\n",
    "        all_MagLat_values   = list() \n",
    "        all_MLT_values      = list() \n",
    "        all_Altitude_values = list() \n",
    "        all_Lat_values      = list()\n",
    "        all_Kp_values       = list() \n",
    "        all_Time_values     = list()\n",
    "        all_HittedBin_IDs   = list()\n",
    "        all_EEX_values      = list()\n",
    "        all_EEY_values      = list()\n",
    "        all_Pedersen_values = list()\n",
    "        all_Density_values  = list()\n",
    "        all_Lev_values      = list()\n",
    "        all_Hall_values     = list()\n",
    "        all_ConvectionHeating_values = list()\n",
    "        all_WindHeating_values = list()\n",
    "        Matches = 0\n",
    "        \n",
    "        # parse TIEGCM file\n",
    "        try:\n",
    "            CDFroot = Dataset( DataFilename, 'r' )\n",
    "        except:\n",
    "            print ( \"WRONG FORMAT:\", DataFilename )\n",
    "            return\n",
    "        try:\n",
    "            FileStartTimeStamp = calendar.timegm( datetime.strptime( CDFroot.variables['time'].units[14:],  \"%Y-%m-%d %H:%M:%S\" ).utctimetuple() ) # ex: \"minutes since 2015-1-1 0:0:0\"\n",
    "        except:\n",
    "            print ( \"WRONG CONTENTS:\", DataFilename )\n",
    "            return\n",
    "        length_time = CDFroot.variables['Ohmic'].shape[0]\n",
    "        length_lev  = CDFroot.variables['Ohmic'].shape[1]\n",
    "        length_lat  = CDFroot.variables['Ohmic'].shape[2]\n",
    "        length_lon  = CDFroot.variables['Ohmic'].shape[3]\n",
    "        # wait until disk is released\n",
    "        DiskAccessLock.acquire()\n",
    "        # Load or calculate all basic values from the netcdf file\n",
    "        try:\n",
    "            TIMEs   = CDFroot.variables['time'][:] # minutes since the start time\n",
    "            LATs    = CDFroot.variables['lat'][:] \n",
    "            ALTs    = CDFroot.variables['ZGMID'][:, :, :, :] / 100000 # it is stored in cm inside the file\n",
    "            JHs     = CDFroot.variables['Ohmic'][:, :, :, :]\n",
    "            KPs     = CDFroot.variables['Kp'][:]\n",
    "            MAGLATs = CDFroot.variables['mlat_qdf'][:, :, :, :] \n",
    "            MLTs    = CDFroot.variables['mlt_qdf'][:, :, :, :] \n",
    "            EEXs    = CDFroot.variables['EEX_si'][:, :, :, :] \n",
    "            EEYs    = CDFroot.variables['EEY_si'][:, :, :, :] \n",
    "            PEDs    = CDFroot.variables['SIGMA_PED'][:, :, :, :] \n",
    "            HALs    = CDFroot.variables['SIGMA_HAL'][:, :, :, :]\n",
    "            DENs    = CDFroot.variables['DEN'][:, :, :, :] \n",
    "            LEVs    = CDFroot.variables['lev'][:] \n",
    "            try:\n",
    "                CONV_H  = CDFroot.variables['Convection_heating'][:, :, :, :]\n",
    "            except:\n",
    "                CONV_H  = CDFroot.variables['Convenction_heating'][:, :, :, :]\n",
    "            WIND_H  = CDFroot.variables['Wind_heating'][:, :, :, :]\n",
    "        except:\n",
    "            print( \"Thread aborted while reading\",  datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\"), ResultsFilename[-22:], \"\\n\" )\n",
    "            DiskAccessLock.release()\n",
    "            return \n",
    "        DiskAccessLock.release()\n",
    "        print( \"Thread file read done\",  datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\"), ResultsFilename[-22:], \"\\n\" )\n",
    "    \n",
    "        step = 1\n",
    "        for idx_lat in range(0, length_lat, step):\n",
    "            if idx_lat%30==0: print(\"Thread Calculating Lat\",  idx_lat, ResultsFilename[-22:])\n",
    "            current_Lat = LATs[idx_lat] \n",
    "            if current_Lat < Lat_min  or  current_Lat > Lat_max: continue\n",
    "            for idx_lon in range(0, length_lon, step):\n",
    "                for idx_lev in range(0, length_lev, step):\n",
    "                    for idx_time in range(0, length_time, step):                    \n",
    "                        in_Altitude_range = in_MagLat_range = in_MLT_range = in_Kp_range = False\n",
    "                            \n",
    "                        current_Altitude = ALTs[idx_time, idx_lev, idx_lat, idx_lon]\n",
    "                        if current_Altitude >= Altitude_min and current_Altitude <= Altitude_max:\n",
    "                            in_Altitude_range = True\n",
    "                        \n",
    "                        if in_Altitude_range:\n",
    "                            current_MagLat = MAGLATs[ idx_time, idx_lev, idx_lat, idx_lon ]\n",
    "                            if current_MagLat >= MagLat_min and current_MagLat <= MagLat_max:\n",
    "                                in_MagLat_range = True\n",
    "                                \n",
    "                        if in_MagLat_range:\n",
    "                            current_MLT = MLTs[ idx_time, idx_lev, idx_lat, idx_lon ]\n",
    "                            if in_MagLat_range:\n",
    "                                in_MLT_range = is_MLT_inside_range( current_MLT, MLT_min, MLT_max )\n",
    "                        \n",
    "                        if in_MLT_range:\n",
    "                            current_Kp = KPs[idx_time]\n",
    "                            if current_Kp >= Kp_min and current_Kp <= Kp_max:\n",
    "                                in_Kp_range = True   \n",
    "                                \n",
    "                        if in_Kp_range:                    \n",
    "                            matchedBin = GetMatchedBin( current_MLT, current_MagLat, current_Altitude, current_Kp, current_Lat )\n",
    "                            if matchedBin is not None:\n",
    "                                for B in localBins:\n",
    "                                    if B.ID == matchedBin.ID:\n",
    "                                        matchedBin = B\n",
    "                                current_time = int( FileStartTimeStamp + TIMEs[idx_time]*120*60 )\n",
    "                                current_JH = JHs[idx_time, idx_lev, idx_lat ,idx_lon] #CDFroot.variables['Joule Heating'][idx_time, idx_lev, idx_lat, idx_lon]\n",
    "                                matchedBin.JH_values.append( current_JH )\n",
    "                                matchedBin.MagLat_values.append( current_MagLat )\n",
    "                                matchedBin.MLT_values.append( current_MLT )\n",
    "                                matchedBin.Altitude_values.append( current_Altitude )\n",
    "                                matchedBin.Kp_values.append( current_Kp )\n",
    "                                matchedBin.Time_values.append( current_time )\n",
    "                                matchedBin.EEX_values.append( EEXs[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                matchedBin.EEY_values.append( EEYs[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                matchedBin.Pedersen_values.append( PEDs[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                matchedBin.Hall_values.append( HALs[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                matchedBin.Density_values.append( DENs[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                matchedBin.Lev_values.append( LEVs[ idx_lev ] ) \n",
    "                                matchedBin.ConvectionHeating_values.append( CONV_H[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                matchedBin.WindHeating_values.append( WIND_H[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                all_JH_values.append( current_JH )\n",
    "                                all_MagLat_values.append( current_MagLat )\n",
    "                                all_MLT_values.append( current_MLT )\n",
    "                                all_Altitude_values.append( current_Altitude )\n",
    "                                all_Kp_values.append( current_Kp )\n",
    "                                all_Time_values.append( current_time )\n",
    "                                all_HittedBin_IDs.append( matchedBin.ID )\n",
    "                                all_EEX_values.append( EEXs[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                all_EEY_values.append( EEYs[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                all_Pedersen_values.append( PEDs[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                all_Hall_values.append( HALs[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                all_Density_values.append( DENs[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                all_Lev_values.append( LEVs[ idx_lev ] )\n",
    "                                all_ConvectionHeating_values.append( CONV_H[ idx_time, idx_lev, idx_lat, idx_lon ] ) \n",
    "                                all_WindHeating_values.append( WIND_H[ idx_time, idx_lev, idx_lat, idx_lon ] )\n",
    "                                Matches += 1\n",
    "                    #break\n",
    "                #break\n",
    "        CDFroot.close()\n",
    "        # wait until disk is released\n",
    "        #DiskAccessLock.acquire()\n",
    "        #### SAVE Results ####\n",
    "        try:\n",
    "            # save general info\n",
    "            resultsCDF = Dataset( ResultsFilename, 'a' )\n",
    "            resultsCDF.DateOfUpdate = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "            resultsCDF.Region = CALCULATIONS_RegionName\n",
    "            resultsCDF.DataPath = CALCULATIONS_TIEGCMfolder\n",
    "            # save data for each bin seperately \n",
    "            for B in localBins:\n",
    "                # save data about the hits inside the bin\n",
    "                if len(B.Time_values) > 0:\n",
    "                    resultsCDF.variables[B.ID+\"_TimeValues\"][:]      = B.Time_values\n",
    "                    resultsCDF.variables[B.ID+\"_JHValues\"][:]        = B.JH_values        \n",
    "                    resultsCDF.variables[B.ID+\"_MagLatValues\"][:]    = B.MagLat_values\n",
    "                    resultsCDF.variables[B.ID+\"_MLTValues\"][:]       = B.MLT_values\n",
    "                    resultsCDF.variables[B.ID+\"_AltitudeValues\"][:]  = B.Altitude_values\n",
    "                    resultsCDF.variables[B.ID+\"_LatValues\"][:]       = B.Lat_values\n",
    "                    resultsCDF.variables[B.ID+\"_KpValues\"][:]        = B.Kp_values\n",
    "                    resultsCDF.variables[B.ID+\"_EEXValues\"][:]       = B.EEX_values        \n",
    "                    resultsCDF.variables[B.ID+\"_EEYValues\"][:]       = B.EEY_values\n",
    "                    resultsCDF.variables[B.ID+\"_PedersenValues\"][:]  = B.Pedersen_values\n",
    "                    resultsCDF.variables[B.ID+\"_HallValues\"][:]      = B.Hall_values\n",
    "                    resultsCDF.variables[B.ID+\"_DensityValues\"][:]   = B.Density_values\n",
    "                    resultsCDF.variables[B.ID+\"_LevValues\"][:]       = B.Lev_values\n",
    "                    resultsCDF.variables[B.ID+\"_ConvectionHeatingValues\"][:] = B.ConvectionHeating_values\n",
    "                    resultsCDF.variables[B.ID+\"_WindHeatingValues\"][:] = B.WindHeating_values\n",
    "            ## save data for all hits\n",
    "            resultsCDF.variables[\"allTimeValues\"][:]     = all_Time_values\n",
    "            resultsCDF.variables[\"allJHValues\"][:]       = all_JH_values    \n",
    "            resultsCDF.variables[\"allMagLatValues\"][:]   = all_MagLat_values\n",
    "            resultsCDF.variables[\"allMLTValues\"][:]      = all_MLT_values\n",
    "            resultsCDF.variables[\"allAltitudeValues\"][:] = all_Altitude_values\n",
    "            resultsCDF.variables[\"allLatValues\"][:]      = all_Lat_values\n",
    "            resultsCDF.variables[\"allKpValues\"][:]       = all_Kp_values\n",
    "            #resultsCDF.variables[\"allHittedBinIDs\"][:]   = netCDF4.stringtochar(np.array(all_HittedBin_IDs[:], 'S8'))\n",
    "            resultsCDF.variables[\"allEEXValues\"][:]      = all_EEX_values\n",
    "            resultsCDF.variables[\"allEEYValues\"][:]      = all_EEY_values\n",
    "            resultsCDF.variables[\"allPedersenValues\"][:] = all_Pedersen_values\n",
    "            resultsCDF.variables[\"allHallValues\"][:]     = all_Hall_values\n",
    "            resultsCDF.variables[\"allDensityValues\"][:]  = all_Density_values\n",
    "            resultsCDF.variables[\"allLevValues\"][:]      = all_Lev_values\n",
    "            resultsCDF.variables[\"allConvectionHeatingValues\"][:] = all_ConvectionHeating_values\n",
    "            resultsCDF.variables[\"allWindHeatingValues\"][:] = all_WindHeating_values\n",
    "            #\n",
    "            resultsCDF.close()    \n",
    "        except Exception as e:\n",
    "            print( \"!!!! Thread error while writing\",  datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\"), ResultsFilename[-22:], \"\\n\" )\n",
    "            print( e )\n",
    "            #DiskAccessLock.release()\n",
    "        #DiskAccessLock.release()\n",
    "    \n",
    "        print( \"Thread finish\",  datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\"), ResultsFilename[-22:], \"\\n\", Matches, \"matches\", len(localBins[0].JH_values), len(Bins[0].JH_values) )\n",
    "        print( \"\" )\n",
    "    \n",
    "    \n",
    "def AssignValuesPerBin_MultipleResultFiles( DataFilesPath ):\n",
    "    startSecs = time.time()\n",
    "\n",
    "    ResultsFolder = DaedalusGlobals.CoverageResults_Files_Path + BinGroups_Dropdown.value + \".\" + CALCULATIONS_TIEGCMfolder[CALCULATIONS_TIEGCMfolder[:-1].rfind('/')+1:-1] + \".MultiFileResults/\"\n",
    "    CALCULATIONS_ResultsFolder = ResultsFolder\n",
    "    if path.exists( ResultsFolder ) == False:\n",
    "        os.mkdir( ResultsFolder )\n",
    "    \n",
    "    AllThreads = list()\n",
    "    AllDataFiles = sorted( glob.glob( DataFilesPath + \"TIEGCM*/*.nc\", recursive=True ) )\n",
    "    for currentDataFile in AllDataFiles:\n",
    "        ResultsFilename = ResultsFolder + currentDataFile[ currentDataFile.rfind('/')+1 : -3 ] + \".nc\"\n",
    "        if path.exists( ResultsFilename ): \n",
    "            print(\"Skipping because exists:\", ResultsFilename)\n",
    "            continue\n",
    "        else:\n",
    "            # wait if there are plenty alive threads\n",
    "            alive_counter = 0\n",
    "            for aThread in AllThreads:\n",
    "                if aThread.is_alive():\n",
    "                    alive_counter += 1\n",
    "            while alive_counter >= 36:\n",
    "                time.sleep(random.randint(10, 15))\n",
    "                alive_counter = 0\n",
    "                for aThread in AllThreads:\n",
    "                    if aThread.is_alive():\n",
    "                        alive_counter += 1\n",
    "            # spawn new thread\n",
    "            CreateResults_CDF( ResultsFilename )\n",
    "            T = Thread_ValueAssigner(currentDataFile, ResultsFilename)\n",
    "            AllThreads.append(T)\n",
    "            T.start()\n",
    "            time.sleep(2)\n",
    "\n",
    "    # wait for all threads to terminate\n",
    "    for T in AllThreads: T.join()\n",
    "    # finish it\n",
    "    finishSecs = time.time()\n",
    "    print( finishSecs-startSecs, \" sec\")    \n",
    "    return ResultsFolder\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def plotHeightIntegrated_perKpRange():\n",
    "    print( \"Height-integration plot started\", datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\") )\n",
    "    # init parameters\n",
    "    if SELECTED_VARIABLE == \"Ohmic\":\n",
    "        SELECTED_VARIABLE_longname = \"Joule Heating\"\n",
    "        MultiplicationFactor = 1000\n",
    "        new_units = \"mW/m3\"\n",
    "    elif SELECTED_VARIABLE == \"SIGMA_PED\":\n",
    "        SELECTED_VARIABLE_longname = \"Pedersen Conductivity\"\n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"S/m\"\n",
    "    elif SELECTED_VARIABLE == \"SIGMA_HAL\":\n",
    "        SELECTED_VARIABLE_longname = \"Hall Conductivity\"\n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"S/m\"        \n",
    "    elif SELECTED_VARIABLE == \"Convection_heating\":\n",
    "        SELECTED_VARIABLE_longname = \"Convection Heating\"\n",
    "        MultiplicationFactor = 1000\n",
    "        new_units = \"mW/m3\"           \n",
    "    elif SELECTED_VARIABLE == \"Wind_heating\":\n",
    "        SELECTED_VARIABLE_longname = \"Wind Correction\"\n",
    "        MultiplicationFactor = 1000\n",
    "        new_units = \"mW/m3\"                   \n",
    "    elif SELECTED_VARIABLE == \"EEX_si\" or SELECTED_VARIABLE == \"EEY_si\":\n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"mV/m\"        \n",
    "    else:\n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"?\" \n",
    "        \n",
    "    print( \"Variable\" , SELECTED_VARIABLE)\n",
    "\n",
    "    # Region specific binning:\n",
    "    s = SavedFilenames_Dropdown.value[:-1]\n",
    "    s = s[ s.rfind('/')+1 : ]\n",
    "    RegionID = s[ 0 : s.find('.')]\n",
    "    print( \"Region\", RegionID )\n",
    "    regionMagLatmin = 999\n",
    "    regionMagLatmax = -999\n",
    "    regionMLTmin = 999\n",
    "    regionMLTmax = -999\n",
    "    regionLATmin = 999\n",
    "    regionLATmax = -999\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith( RegionID ):\n",
    "            if regionMagLatmin>B.MagLat_min: regionMagLatmin = B.MagLat_min\n",
    "            if regionMagLatmax<B.MagLat_max: regionMagLatmax = B.MagLat_max            \n",
    "            if regionMLTmin>B.MLT_min: regionMLTmin = B.MLT_min\n",
    "            if regionMLTmax<B.MLT_max: regionMLTmax = B.MLT_max\n",
    "            if regionLATmin>B.Lat_min: regionLATmin = B.Lat_min\n",
    "            if regionLATmax<B.Lat_max: regionLATmax = B.Lat_max\n",
    "    if regionMLTmax < regionMLTmin: regionMLTmax += 24\n",
    "        \n",
    "    # init data structures\n",
    "    MLTsequence     = list( range( regionMLTmin,  regionMLTmax, 1) )\n",
    "    KPsequence      = [ 0, 2, 4 ] \n",
    "    Distribution    = dict()\n",
    "    for aKP in KPsequence:\n",
    "        for aMLT in MLTsequence:\n",
    "            Distribution[ (aKP, aMLT) ] = list()\n",
    "        \n",
    "    # read data and put them into the data structures\n",
    "    AllDataFilenames = sorted( glob.glob(\"/home/NAS/TIEGCM_DATA_2/Height_Integrated_Products/*.nc\") )\n",
    "    for file_idx in range(0, len(AllDataFilenames)):\n",
    "        if file_idx%10==0: print( \"Reading\", AllDataFilenames[file_idx] )\n",
    "        CDFroot = Dataset( AllDataFilenames[file_idx], 'r' )\n",
    "        length_time = CDFroot.variables['mlt_qdf'].shape[0]\n",
    "        length_lat  = CDFroot.variables['mlt_qdf'].shape[1]\n",
    "        length_lon  = CDFroot.variables['mlt_qdf'].shape[2]\n",
    "        MAGLAT_values = CDFroot.variables['mlat_qdf'][:, :, :] \n",
    "        MLT_values    = CDFroot.variables['mlt_qdf'][:, :, :] \n",
    "        LAT_values    = CDFroot.variables['lat'][:] \n",
    "        KP_values     = CDFroot.variables['Kp'][:] \n",
    "        if SELECTED_VARIABLE == \"Ohmic\":\n",
    "            try:\n",
    "                VAR_values = CDFroot.variables['Convection_heating'][:, :, :] + CDFroot.variables['Wind_heating'][:, :, :]\n",
    "            except:\n",
    "                VAR_values = CDFroot.variables['Convenction_heating'][:, :, :] + CDFroot.variables['Wind_heating'][:, :, :]\n",
    "        elif SELECTED_VARIABLE == \"SIGMA_PED\":\n",
    "            VAR_values = CDFroot.variables['SigmaP_HI'][:, :, :] \n",
    "        elif SELECTED_VARIABLE == \"SIGMA_HAL\":\n",
    "            VAR_values = CDFroot.variables['SigmaH_HI'][:, :, :] \n",
    "        elif SELECTED_VARIABLE == \"Convection_heating\":\n",
    "            try:\n",
    "                VAR_values = CDFroot.variables['Convection_heating'][:, :, :] \n",
    "            except:\n",
    "                VAR_values = CDFroot.variables['Convenction_heating'][:, :, :] \n",
    "        elif SELECTED_VARIABLE == \"Wind_heating\":\n",
    "            VAR_values = CDFroot.variables['Wind_heating'][:, :, :] \n",
    "        VAR_values *= MultiplicationFactor\n",
    "        CDFroot.close()\n",
    "        # parse data into the structrures\n",
    "        for idx_time in range(0, length_time, 1):\n",
    "            for idx_lat in range(0, length_lat, 1):\n",
    "                for idx_lon in range(0, length_lon, 1):\n",
    "                    in_MagLat_range = in_MLT_range = in_Lat_range = False\n",
    "                    \n",
    "                    currentMagLat = MAGLAT_values[ idx_time, idx_lat, idx_lon ]\n",
    "                    if currentMagLat>=regionMagLatmin and currentMagLat<=regionMagLatmax: in_MagLat_range = True\n",
    "                        \n",
    "                    if in_MagLat_range:\n",
    "                        currentLAT = LAT_values[ idx_lat ]    \n",
    "                        if currentLAT>=regionLATmin and currentLAT<=regionLATmax: in_Lat_range = True\n",
    "                        \n",
    "                    if in_Lat_range:\n",
    "                        currentMLT = MLT_values[ idx_time, idx_lat, idx_lon ]\n",
    "                        MLT_toCheck = currentMLT\n",
    "                        if regionMLTmax > 24  and  currentMLT<=regionMLTmax-24: MLT_toCheck += 24\n",
    "                        if MLT_toCheck>=regionMLTmin and MLT_toCheck<=regionMLTmax: in_MLT_range = True\n",
    "                            \n",
    "                    if in_MLT_range:\n",
    "                        currentKP = KP_values[ idx_time ]\n",
    "                        # find correct kp\n",
    "                        if currentKP < 2: \n",
    "                            kp_to_fall = 0\n",
    "                        elif currentKP < 4:  \n",
    "                            kp_to_fall = 2\n",
    "                        else:\n",
    "                            kp_to_fall = 4\n",
    "                        # find correct MLT\n",
    "                        for seq_idx in range(0, len(MLTsequence)):\n",
    "                            if MLT_toCheck>=MLTsequence[seq_idx] and MLT_toCheck<MLTsequence[seq_idx]+1: \n",
    "                                mlt_to_fall=MLTsequence[seq_idx]\n",
    "                                break\n",
    "                        if MLT_toCheck == MLTsequence[len(MLTsequence)-1]+1: mlt_to_fall = MLTsequence[len(MLTsequence)-1] # for last MLT position\n",
    "                        # store the value at the right place\n",
    "                        Distribution[ (kp_to_fall, mlt_to_fall) ].append( VAR_values[ idx_time, idx_lat, idx_lon ] )\n",
    "        #break # <<< zoro\n",
    "        \n",
    "    Color10 = '#c4dfe6'\n",
    "    Color25 = '#a1d6e2'\n",
    "    Color50 = '#1995ad'\n",
    "    Color75 = '#a1d6e2'\n",
    "    Color90 = '#c4dfe6'\n",
    "    # define secondary y-axis at the right of the plot\n",
    "    mySpecs = list()\n",
    "    for row in range(0, len(KPsequence)):\n",
    "        mySpecs.append( {\"secondary_y\": True} )\n",
    "    # init figure            \n",
    "    fig = make_subplots(rows=len(KPsequence), cols=1, shared_xaxes=True, vertical_spacing=0.03, specs=[[{\"secondary_y\": True}]]*len(KPsequence))\n",
    "\n",
    "    # calculate Percentiles\n",
    "    hits = 0\n",
    "    Ymax = -10000\n",
    "    for aKP in KPsequence:\n",
    "        Percentiles10 = list()\n",
    "        Percentiles25 = list()\n",
    "        Percentiles50 = list()\n",
    "        Percentiles75 = list()\n",
    "        Percentiles90 = list()\n",
    "        Xaxis_values= list()\n",
    "        for aMLT in MLTsequence:\n",
    "            hits += len(Distribution[(aKP, aMLT)])\n",
    "            print( \"Kp = \", aKP, \"MLT =\", aMLT, \"   Hits =\", len(Distribution[(aKP, aMLT)]) )\n",
    "            Xaxis_values.append( aMLT )\n",
    "            Xaxis_values.append( aMLT + 1 )\n",
    "            if len(Distribution[(aKP, aMLT)]):\n",
    "                n = np.percentile(Distribution[(aKP, aMLT)], 10)\n",
    "                Percentiles10.append( n )\n",
    "                Percentiles10.append( n )\n",
    "                n = np.percentile(Distribution[(aKP, aMLT)], 25)\n",
    "                Percentiles25.append( n )\n",
    "                Percentiles25.append( n )\n",
    "                n = np.percentile(Distribution[(aKP, aMLT)], 50)\n",
    "                Percentiles50.append( n )\n",
    "                Percentiles50.append( n )\n",
    "                n = np.percentile(Distribution[(aKP, aMLT)], 75)\n",
    "                Percentiles75.append( n )\n",
    "                Percentiles75.append( n )\n",
    "                n = np.percentile(Distribution[(aKP, aMLT)], 90)\n",
    "                Percentiles90.append( n )\n",
    "                Percentiles90.append( n )\n",
    "        # add traces for percentiles\n",
    "        DisplayThisLegend = False\n",
    "        if KPsequence.index(aKP) == 0: DisplayThisLegend = True\n",
    "        fig.add_trace( go.Scatter(x=Xaxis_values, y=[0]*len(Percentiles10), mode='lines', fill='tonexty', fillcolor=Color10, line=dict(color='gray',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=1 )\n",
    "        fig.add_trace( go.Scatter(name='10th Perc.', x=Xaxis_values, y=Percentiles10, mode='lines', fill='tonexty', fillcolor=Color10, line=dict(color='gray', width=1,), showlegend=DisplayThisLegend), row=KPsequence.index(aKP)+1, col=1 )\n",
    "        fig.add_trace( go.Scatter(name='25th Perc.', x=Xaxis_values, y=Percentiles25, mode='lines', fill='tonexty', fillcolor=Color25, line=dict(color='gray', width=1,), showlegend=DisplayThisLegend), row=KPsequence.index(aKP)+1, col=1 )\n",
    "        fig.add_trace( go.Scatter(name='50th Perc.', x=Xaxis_values, y=Percentiles50, mode='lines', fill='tonexty', fillcolor=Color50, line=dict(color='black',width=2,), showlegend=DisplayThisLegend), row=KPsequence.index(aKP)+1, col=1 )\n",
    "        fig.add_trace( go.Scatter(name='75th Perc.', x=Xaxis_values, y=Percentiles75, mode='lines', fill='tonexty', fillcolor=Color75, line=dict(color='gray', width=1,), showlegend=DisplayThisLegend), row=KPsequence.index(aKP)+1, col=1 )\n",
    "        fig.add_trace( go.Scatter(name='90th Perc.', x=Xaxis_values, y=Percentiles90, mode='lines', fill='tonexty', fillcolor=Color90, line=dict(color='gray', width=1,), showlegend=DisplayThisLegend), row=KPsequence.index(aKP)+1, col=1 )\n",
    "        # add a trace in order to display secondary y-axis at the right\n",
    "        fig.add_trace( go.Scatter(x=[-10], y=[-10], showlegend=False, marker_size=0), row=KPsequence.index(aKP)+1, col=1, secondary_y=True )\n",
    "        #\n",
    "        if Ymax < max(Percentiles90): Ymax = max(Percentiles90)\n",
    "    Ymax = Ymax * 1.05\n",
    "    print( \"Total Hits =\", hits, \"   Ymax =\", Ymax )\n",
    "        \n",
    "    # set layout\n",
    "    for aKP in KPsequence:\n",
    "        fig.update_yaxes( title_text=new_units, row=KPsequence.index(aKP)+1, col=1, side='left', secondary_y=False)\n",
    "        row_title = \"Kp \" + str(aKP) + \" - \"\n",
    "        if aKP == 0:\n",
    "            row_title +=  \"2\"\n",
    "        elif aKP == 2:\n",
    "            row_title +=  \"4\"\n",
    "        else:\n",
    "            row_title +=  \"9\"\n",
    "        fig.update_yaxes( title_text=row_title, row=KPsequence.index(aKP)+1, col=1,  side='right', secondary_y=True, showticklabels=False )\n",
    "        ####\n",
    "    fig.update_xaxes( range=[MLTsequence[0],MLTsequence[-1]+1], dtick=1 )\n",
    "    fig.update_xaxes( title_text=\"Magnetic Local Time (hours)\", row=len(KPsequence), col=1 )\n",
    "    fig.update_yaxes( range=[0, Ymax ] )\n",
    "    fig.update_layout( title = getBinDescription(RegionID) + \"<br>\" + \"Height-integrated Dsitribution of \" + SELECTED_VARIABLE_longname + \" (\" + new_units + \")\",\n",
    "                       width=800, height=200+200*len(KPsequence), showlegend=True, legend_orientation=\"h\", legend_y=-0.06) \n",
    "    plotly.offline.init_notebook_mode(connected=True)\n",
    "    plotly.offline.iplot(fig)\n",
    "    print( \"Height-integration plot finished\", datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\") )\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# takes a list of real numbers and returns their standard deviation\n",
    "def CalculateStandardDeviation( Data ):\n",
    "    mean = sum(Data) / len(Data)\n",
    "    variance = 0 \n",
    "    for n in Data:\n",
    "        variance += abs(n - mean)**2\n",
    "    stdev = variance / len(Data)\n",
    "    return stdev\n",
    "\n",
    "\n",
    "def plotColorSpread_perKpRange( ):\n",
    "    if Plot_ColorSpreads_Checkbox.value == False: return # <<<\n",
    "    # init parameters\n",
    "    if SELECTED_VARIABLE == \"Ohmic\":\n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"\n",
    "    elif SELECTED_VARIABLE == \"SIGMA_PED\":\n",
    "        MultiplicationFactor = 10**3 \n",
    "        new_units = \"mS/m\"\n",
    "    elif SELECTED_VARIABLE == \"SIGMA_HAL\":\n",
    "        MultiplicationFactor = 10**3 \n",
    "        new_units = \"mS/m\"        \n",
    "    elif SELECTED_VARIABLE == \"Convection_heating\":\n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"           \n",
    "    elif SELECTED_VARIABLE == \"Wind_heating\":\n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"                   \n",
    "    elif SELECTED_VARIABLE == \"EEX_si\" or SELECTED_VARIABLE == \"EEY_si\":\n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"mV/m\"      \n",
    "    elif SELECTED_VARIABLE == \"JH/mass\":\n",
    "        MultiplicationFactor = 1 \n",
    "        new_units = \"W/kg\"\n",
    "    elif SELECTED_VARIABLE == \"JH/pressure\":\n",
    "        MultiplicationFactor = 1 \n",
    "        new_units = \"sec^-1\"        \n",
    "    else:\n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"?\" \n",
    "        \n",
    "    print(\"SELECTED_VARIABLE=\", SELECTED_VARIABLE)\n",
    "\n",
    "    # Region specific binning:\n",
    "    if \"(\" in CALCULATIONS_RegionName:\n",
    "        RegionID = CALCULATIONS_RegionName[ CALCULATIONS_RegionName.find('(')+1 : CALCULATIONS_RegionName.rfind(')') ]\n",
    "    else:\n",
    "        RegionID = CALCULATIONS_RegionName\n",
    "    regionMLTmin = 999\n",
    "    regionMLTmax = -999\n",
    "    regionMagLatMin = 999\n",
    "    regionMagLatMax = -999\n",
    "    regionAltMin = 999\n",
    "    regionAltMax = -999\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith( RegionID ):\n",
    "            if regionMLTmin>B.MLT_min: regionMLTmin = B.MLT_min\n",
    "            if regionMLTmax<B.MLT_max: regionMLTmax = B.MLT_max\n",
    "            if regionMagLatMin>B.MagLat_min: regionMagLatMin = B.MagLat_min\n",
    "            if regionMagLatMax<B.MagLat_max: regionMagLatMax = B.MagLat_max\n",
    "            if regionAltMin>B.Altitude_min: regionAltMin = B.Altitude_min\n",
    "            if regionAltMax<B.Altitude_max: regionAltMax = B.Altitude_max\n",
    "    if regionMLTmax <= regionMLTmin: regionMLTmax += 24\n",
    "    x_axes_range = [regionMLTmin, regionMLTmax]\n",
    "    print(\"REGION=\",RegionID)\n",
    "    # init data structures\n",
    "    Buckets = dict()\n",
    "    MLT_duration_of_a_bucket   = 1\n",
    "    MagLat_degrees_of_a_bucket = 1\n",
    "    ALT_distance_of_a_bucket   = 10\n",
    "    ALTsequence     = list( range( regionAltMin, regionAltMax, ALT_distance_of_a_bucket ) )\n",
    "    MLTsequence     = list( range( regionMLTmin,  regionMLTmax, MLT_duration_of_a_bucket) )\n",
    "    MagLatSequence  = list( range( regionMagLatMin,  regionMagLatMax, MagLat_degrees_of_a_bucket) )\n",
    "    KPsequence      = [ 0, 2, 4 ] \n",
    "    for aMLT in MLTsequence:\n",
    "        for aMagLat in MagLatSequence:\n",
    "            for anALT in ALTsequence:\n",
    "                for aKP in KPsequence:\n",
    "                    Buckets[(aKP, anALT, aMagLat, aMLT)] = list()\n",
    "    \n",
    "    print(\"Processing\", len(all_JH_values), \"values\")\n",
    "    for i in range( 0, len(all_JH_values) ):\n",
    "        if i % 10000000 == 0: print( \"Processing value No\", i, datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\") )\n",
    "        mlt_to_fall = alt_to_fall = maglat_to_fall = -1  \n",
    "        # find correct Alt\n",
    "        for seq_idx in range(0, len(ALTsequence)):\n",
    "            if all_Altitude_values[i]>=ALTsequence[seq_idx] and all_Altitude_values[i]<ALTsequence[seq_idx]+ALT_distance_of_a_bucket:\n",
    "                alt_to_fall=ALTsequence[seq_idx]\n",
    "                break\n",
    "        if alt_to_fall == -1: continue # ignore highest altitudes        \n",
    "        # find correct kp\n",
    "        if all_Kp_values[i] < 2: \n",
    "            kp_to_fall = 0\n",
    "        elif all_Kp_values[i] < 4:  \n",
    "            kp_to_fall = 2\n",
    "        else:\n",
    "            kp_to_fall = 4\n",
    "        # find correct MLT\n",
    "        MLT_tocheck = all_MLT_values[i]\n",
    "        if regionMLTmax>24  and  MLT_tocheck<=regionMLTmax-24:\n",
    "            MLT_tocheck += 24\n",
    "        for seq_idx in range(0, len(MLTsequence)):\n",
    "            if MLT_tocheck>=MLTsequence[seq_idx] and MLT_tocheck<MLTsequence[seq_idx]+MLT_duration_of_a_bucket: \n",
    "                mlt_to_fall=MLTsequence[seq_idx]\n",
    "                break\n",
    "        if MLT_tocheck == MLTsequence[len(MLTsequence)-1]+MLT_duration_of_a_bucket: mlt_to_fall = MLTsequence[len(MLTsequence)-1] # for last MLT position\n",
    "        # find correct MagLat\n",
    "        for seq_idx in range(0, len(MagLatSequence)):\n",
    "            if all_MagLat_values[i]>=MagLatSequence[seq_idx] and all_MagLat_values[i]<MagLatSequence[seq_idx]+MagLat_degrees_of_a_bucket:\n",
    "                maglat_to_fall=MagLatSequence[seq_idx]\n",
    "                break\n",
    "        if maglat_to_fall == -1: continue # ignore \n",
    "        # store the value at the right place\n",
    "        Buckets[ (kp_to_fall, alt_to_fall, maglat_to_fall, mlt_to_fall) ].append( all_JH_values[ i ] )\n",
    "\n",
    "    # plot\n",
    "    \n",
    "    # construct the column titles \n",
    "    ColumnTitles = list()    \n",
    "    for i in range(0, len(ALTsequence)):\n",
    "        ColumnTitles.append( \"<b>\" + str(ALTsequence[i]) + \"-\"  + str(ALTsequence[i]+ALT_distance_of_a_bucket) + \"km\" + \"</b>\")\n",
    "        \n",
    "    #make plot\n",
    "    HitsStr = \"\"\n",
    "    fig1 = make_subplots(rows=len(KPsequence), cols=len(ALTsequence), shared_xaxes=True, shared_yaxes=True, vertical_spacing=0.035, horizontal_spacing=0.01, subplot_titles=ColumnTitles)\n",
    "    fig2 = make_subplots(rows=len(KPsequence), cols=len(ALTsequence), shared_xaxes=True, shared_yaxes=True, vertical_spacing=0.035, horizontal_spacing=0.01, subplot_titles=ColumnTitles)\n",
    "    fig3 = make_subplots(rows=len(KPsequence), cols=len(ALTsequence), shared_xaxes=True, shared_yaxes=True, vertical_spacing=0.035, horizontal_spacing=0.01, subplot_titles=ColumnTitles)\n",
    "    fig4 = make_subplots(rows=len(KPsequence), cols=len(ALTsequence), shared_xaxes=True, shared_yaxes=True, vertical_spacing=0.035, horizontal_spacing=0.01, subplot_titles=ColumnTitles)\n",
    "    figs = [fig1, fig2, fig3, fig4]\n",
    "    \n",
    "    # bundle data, min and max values\n",
    "    allPercentiles10_min = allPercentiles10_logscale_min = 999999\n",
    "    allPercentiles10_max = allPercentiles10_logscale_max = -99999\n",
    "    allPercentiles90_min = allPercentiles90_logscale_min = 999999\n",
    "    allPercentiles90_max = allPercentiles90_logscale_max = -99999\n",
    "    allMeans_min = allMeans_logscale_min = 999999\n",
    "    allMeans_max = allMeans_logscale_max = -99999\n",
    "    allStDevs_min = allStDevs_logscale_min = 999999\n",
    "    allStDevs_max = allStDevs_logscale_max = -99999    \n",
    "    for aKP in KPsequence:\n",
    "        for anALT in ALTsequence:\n",
    "            Percentiles10 = np.zeros( ( len(MagLatSequence), len(MLTsequence)) )\n",
    "            Percentiles90 = np.zeros( ( len(MagLatSequence), len(MLTsequence)) )\n",
    "            Means         = np.zeros( ( len(MagLatSequence), len(MLTsequence)) )\n",
    "            StDevs        = np.zeros( ( len(MagLatSequence), len(MLTsequence)) )\n",
    "            hits  = 0\n",
    "\n",
    "            for aMLT in MLTsequence:\n",
    "                for aMagLat in MagLatSequence:\n",
    "                    hits += len(Buckets[(aKP, anALT, aMagLat, aMLT)])\n",
    "                    i = MagLatSequence.index(aMagLat)\n",
    "                    j = MLTsequence.index(aMLT)\n",
    "                    if len(Buckets[(aKP, anALT, aMagLat, aMLT)]) > 0: \n",
    "                        Percentiles10[ i, j ] = np.percentile(Buckets[(aKP, anALT, aMagLat, aMLT)], 10) \n",
    "                        Percentiles90[ i, j ] = np.percentile(Buckets[(aKP, anALT, aMagLat, aMLT)], 90)\n",
    "                        Means        [ i, j ] = sum(Buckets[(aKP, anALT, aMagLat, aMLT)]) / len(Buckets[(aKP, anALT, aMagLat, aMLT)]) \n",
    "                        StDevs       [ i, j ] = CalculateStandardDeviation( Buckets[(aKP, anALT, aMagLat, aMLT)] )\n",
    "                        \n",
    "            print( \"Kp = \", aKP, \"ALT =\", anALT, \"   Hits =\", hits)\n",
    "            HitsStr += \"Kp=\" + str(aKP) + \" ALT=\" + str(anALT) + \"   Hits=\" + str(hits) + \"\\n\"\n",
    "            \n",
    "            # change units\n",
    "            Percentiles10 *= MultiplicationFactor\n",
    "            Percentiles90 *= MultiplicationFactor\n",
    "            Means         *= MultiplicationFactor\n",
    "            StDevs        *= MultiplicationFactor\n",
    "            \n",
    "            # logScale\n",
    "            Percentiles10_logscale = np.log10(Percentiles10)\n",
    "            #for i in range(0, len(Percentiles10_logscale)):\n",
    "            #    for j in range(0, len(Percentiles10_logscale[i])):\n",
    "            #        if np.isnan( Percentiles10_logscale[i, j] ):\n",
    "            #            print( i, j, Percentiles10[i, j] )\n",
    "            Percentiles10_logscale_min = np.nanmin(Percentiles10_logscale)\n",
    "            Percentiles10_logscale_max = np.nanmax(Percentiles10_logscale)\n",
    "            Percentiles10_min = np.nanmin(Percentiles10)\n",
    "            Percentiles10_max = np.nanmax(Percentiles10)\n",
    "            if Percentiles10_logscale_min==float(\"-inf\"): Percentiles10_logscale_min = 0\n",
    "            if Percentiles10_logscale_max==float(\"-inf\"): Percentiles10_logscale_max = 0\n",
    "            if allPercentiles10_min > Percentiles10_min: allPercentiles10_min = Percentiles10_min\n",
    "            if allPercentiles10_max < Percentiles10_max: allPercentiles10_max = Percentiles10_max\n",
    "            if allPercentiles10_logscale_min > Percentiles10_logscale_min: allPercentiles10_logscale_min = Percentiles10_logscale_min\n",
    "            if allPercentiles10_logscale_max < Percentiles10_logscale_max: allPercentiles10_logscale_max = Percentiles10_logscale_max                            \n",
    "            #Percentiles10_logscale = np.nan_to_num( Percentiles10_logscale, nan=np.nan, posinf=Percentiles10_logscale_max, neginf=Percentiles10_logscale_min )\n",
    "            #\n",
    "            Percentiles90_logscale = np.log10(Percentiles90)\n",
    "            Percentiles90_logscale_min = np.nanmin(Percentiles90_logscale)\n",
    "            Percentiles90_logscale_max = np.nanmax(Percentiles90_logscale)\n",
    "            Percentiles90_min = np.nanmin(Percentiles90)\n",
    "            Percentiles90_max = np.nanmax(Percentiles90)\n",
    "            if Percentiles90_logscale_min==float(\"-inf\"): Percentiles90_logscale_min = 0\n",
    "            if Percentiles90_logscale_max==float(\"-inf\"): Percentiles90_logscale_max = 0\n",
    "            if allPercentiles90_min > Percentiles90_min: allPercentiles90_min = Percentiles90_min\n",
    "            if allPercentiles90_max < Percentiles90_max: allPercentiles90_max = Percentiles90_max\n",
    "            if allPercentiles90_logscale_min > Percentiles90_logscale_min: allPercentiles90_logscale_min = Percentiles90_logscale_min\n",
    "            if allPercentiles90_logscale_max < Percentiles90_logscale_max: allPercentiles90_logscale_max = Percentiles90_logscale_max                \n",
    "            #Percentiles90_logscale = np.nan_to_num( Percentiles90_logscale, nan=np.nan, posinf=Percentiles90_logscale_max, neginf=Percentiles90_logscale_min )\n",
    "            #\n",
    "            Means_logscale = np.log10(Means)\n",
    "            Means_logscale_min = np.nanmin(Means_logscale)\n",
    "            Means_logscale_max = np.nanmax(Means_logscale)\n",
    "            Means_min = np.nanmin(Means)\n",
    "            Means_max = np.nanmax(Means)\n",
    "            if Means_logscale_min==float(\"-inf\"): Means_logscale_min = 0\n",
    "            if Means_logscale_max==float(\"-inf\"): Means_logscale_max = 0\n",
    "            if allMeans_min > Means_min: allMeans_min = Means_min\n",
    "            if allMeans_max < Means_max: allMeans_max = Means_max\n",
    "            if allMeans_logscale_min > Means_logscale_min: allMeans_logscale_min = Means_logscale_min\n",
    "            if allMeans_logscale_max < Means_logscale_max: allMeans_logscale_max = Means_logscale_max                \n",
    "            #Means_logscale = np.nan_to_num( Means_logscale, nan=np.nan, posinf=Means_logscale_max, neginf=Means_logscale_min )\n",
    "            #\n",
    "            StDevs_logscale = np.log10(StDevs)\n",
    "            StDevs_logscale_min = np.nanmin(StDevs_logscale)\n",
    "            StDevs_logscale_max = np.nanmax(StDevs_logscale)\n",
    "            StDevs_min = np.nanmin(StDevs)\n",
    "            StDevs_max = np.nanmax(StDevs)\n",
    "            if StDevs_logscale_min==float(\"-inf\"): StDevs_logscale_min = 0\n",
    "            if StDevs_logscale_max==float(\"-inf\"): StDevs_logscale_max = 0\n",
    "            if allStDevs_min > StDevs_min: allStDevs_min = StDevs_min\n",
    "            if allStDevs_max < StDevs_max: allStDevs_max = StDevs_max\n",
    "            if allStDevs_logscale_min > StDevs_logscale_min: allStDevs_logscale_min = StDevs_logscale_min\n",
    "            if allStDevs_logscale_max < StDevs_logscale_max: allStDevs_logscale_max = StDevs_logscale_max                \n",
    "            #StDevs_logscale = np.nan_to_num( StDevs_logscale, nan=np.nan, posinf=StDevs_logscale_max, neginf=StDevs_logscale_min )\n",
    "\n",
    "            \n",
    "            #print(\"ttttt \", Means_logscale_min, Means_logscale_max, Means_min, Means_max )\n",
    "            #print(\"yyyyy\", StDevs_logscale_min, StDevs_logscale_max, StDevs_min, StDevs_max )\n",
    "            \n",
    "            # force all min/max equal to tiegcm's\n",
    "            allPercentiles10_logscale_min = -3.4149059296149056\n",
    "            allPercentiles10_logscale_max = 0.564702317445891\n",
    "            allPercentiles10_min = 0.0\n",
    "            allPercentiles10_max = 3.6703063699405902\n",
    "            allPercentiles90_logscale_min = -1.4281194745464154 \n",
    "            allPercentiles90_logscale_max = 1.5500688891821217 \n",
    "            allPercentiles90_min = 0.0\n",
    "            allPercentiles90_max = 35.486967533415736\n",
    "            allMeans_logscale_min = -1.801815958043412 \n",
    "            allMeans_logscale_max = 1.1062579615522905 \n",
    "            allMeans_min = 0.0\n",
    "            allMeans_max = 12.771972111394563\n",
    "            allStDevs_logscale_min = -10.866333742303075\n",
    "            allStDevs_logscale_max = 0.0\n",
    "            allStDevs_min = 0.0\n",
    "            allStDevs_max = 2.616035496454226e-06\n",
    "    \n",
    "            # plot heatmap\n",
    "            figs[0].add_trace( go.Heatmap(z=Percentiles10_logscale.tolist(), x=MLTsequence, y=MagLatSequence, zsmooth='best', showlegend=False, coloraxis=\"coloraxis1\"), row=KPsequence.index(aKP)+1, col=ALTsequence.index(anALT)+1,  )\n",
    "            figs[1].add_trace( go.Heatmap(z=Percentiles90_logscale.tolist(), x=MLTsequence, y=MagLatSequence, zsmooth='best', showlegend=False, coloraxis=\"coloraxis1\"), row=KPsequence.index(aKP)+1, col=ALTsequence.index(anALT)+1,  )\n",
    "            figs[2].add_trace( go.Heatmap(z=Means_logscale.tolist(),         x=MLTsequence, y=MagLatSequence, zsmooth='best', showlegend=False, coloraxis=\"coloraxis1\"), row=KPsequence.index(aKP)+1, col=ALTsequence.index(anALT)+1,  )\n",
    "            figs[3].add_trace( go.Heatmap(z=StDevs_logscale.tolist(),        x=MLTsequence, y=MagLatSequence, zsmooth='best', showlegend=False, coloraxis=\"coloraxis1\"), row=KPsequence.index(aKP)+1, col=ALTsequence.index(anALT)+1,  )\n",
    "\n",
    "    print(\"iiiii Percentiles10 \", allPercentiles10_logscale_min, allPercentiles10_logscale_max, allPercentiles10_min, allPercentiles10_max )\n",
    "    print(\"iiiii Percentiles90 \", allPercentiles90_logscale_min, allPercentiles90_logscale_max, allPercentiles90_min, allPercentiles90_max )            \n",
    "    print(\"iiiii Means \", allMeans_logscale_min, allMeans_logscale_max, allMeans_min, allMeans_max )\n",
    "    print(\"iiiii StDevs \", allStDevs_logscale_min, allStDevs_logscale_max, allStDevs_min, allStDevs_max )\n",
    "    \n",
    "    for i in range(0,  len(figs)):\n",
    "        figs[i].update_layout(coloraxis=dict(colorscale='Jet'), showlegend=False) #fig.update_traces(zmin=0.07687949e-02, zmax=3.07687949e-01, selector=dict(type=\"heatmap\"))\n",
    "        # display titles\n",
    "        figs[i].update_yaxes( title_text=\"<b>\" + \"Kp 0-2\" + \"</b>\" + \"<br><br>\" + \"Magnetic Latitude (deg)\", row=1, col=1, side='left', secondary_y=False)\n",
    "        figs[i].update_yaxes( title_text=\"<b>\" + \"Kp 2-4\" + \"</b>\" + \"<br><br>\" + \"Magnetic Latitude (deg)\", row=2, col=1, side='left', secondary_y=False)\n",
    "        figs[i].update_yaxes( title_text=\"<b>\" + \"Kp 4-9\" + \"</b>\" + \"<br><br>\" + \"Magnetic Latitude (deg)\", row=3, col=1, side='left', secondary_y=False)\n",
    "        for aMLT in MLTsequence: figs[i].update_xaxes( title_text=\"MLT (hours)\", row=len(KPsequence), col=MLTsequence.index(aMLT)+1)\n",
    "        #\n",
    "        mainTitle = getBinDescription(CALCULATIONS_RegionName) + \"<br>\" \n",
    "        if   i == 0: \n",
    "            figs[i].update_traces(zmin=allPercentiles10_min, zmax=allPercentiles10_max)\n",
    "            mainTitle += \"10th Percentile of \"\n",
    "            #figs[i].update_layout(coloraxis_colorbar=dict( title=\"Log scale<br>colors\",  tickvals=[Percentiles10_logscale_min, Percentiles10_logscale_max],  ticktext=[\"{:.3e}\".format(Percentiles10_min) , \"{:.3e}\".format(Percentiles10_max) ], ))\n",
    "            my_Tickvals    = np.linspace(allPercentiles10_min, allPercentiles10_max, 5, endpoint=True)\n",
    "        elif i == 1:\n",
    "            figs[i].update_traces(zmin=allPercentiles90_min, zmax=allPercentiles90_max)\n",
    "            mainTitle += \"90th Percentile of \"\n",
    "            #figs[i].update_layout(coloraxis_colorbar=dict( title=\"Log scale<br>colors\",  tickvals=[Percentiles90_logscale_min, Percentiles90_logscale_max],  ticktext=[\"{:.3e}\".format(Percentiles90_min) , \"{:.3e}\".format(Percentiles90_max) ], ))\n",
    "            my_Tickvals    = np.linspace(allPercentiles90_min, allPercentiles90_max, 5, endpoint=True)\n",
    "        elif i == 2:\n",
    "            figs[i].update_traces(zmin=allMeans_min, zmax=allMeans_max)\n",
    "            mainTitle += \"Mean of \"\n",
    "            #figs[i].update_layout(coloraxis_colorbar=dict( title=\"Log scale<br>colors\",  tickvals=[Means_logscale_min, Means_logscale_max],  ticktext=[\"{:.3e}\".format(Means_min) , \"{:.3e}\".format(Means_max) ], ))\n",
    "            my_Tickvals    = np.linspace(allMeans_min, allMeans_max, 5, endpoint=True)\n",
    "        elif i == 3:\n",
    "            figs[i].update_traces(zmin=allStDevs_min, zmax=allStDevs_max)\n",
    "            mainTitle += \"Standard Deviation of \"\n",
    "            #figs[i].update_layout(coloraxis_colorbar=dict( title=\"Log scale<br>colors\",  tickvals=[StDevs_logscale_min, StDevs_logscale_max],  ticktext=[\"{:.3e}\".format(StDevs_min) , \"{:.3e}\".format(StDevs_max) ], ))\n",
    "            my_Tickvals    = np.linspace(allStDevs_min, allStDevs_max, 5, endpoint=True)\n",
    "        # tick values at the color bar\n",
    "        my_logTickvals = list()\n",
    "        my_Ticktexts   = list()\n",
    "        for t in range( 0, len(my_Tickvals) ):\n",
    "            try:\n",
    "                my_logTickvals.append( math.log10(my_Tickvals[t]) )\n",
    "                my_Ticktexts.append( \"{:.3e}\".format(my_Tickvals[t]) )                \n",
    "            except:\n",
    "                pass\n",
    "        figs[i].update_layout(coloraxis_colorbar=dict( title=\"Log scale<br>colors\",  tickvals=my_logTickvals,  ticktext=my_Ticktexts, ))\n",
    "        #\n",
    "        figs[i].update_yaxes( range=[regionMagLatMin,  regionMagLatMax] )\n",
    "        mainTitle += SELECTED_VARIABLE_longname + \" (\" + new_units + \")\"\n",
    "        figs[i].update_layout( title = mainTitle, width=400+len(ALTsequence)*150, height=220+200*len(KPsequence), showlegend=True, legend_orientation=\"h\", legend_y=-0.04) \n",
    "        plotly.offline.init_notebook_mode(connected=True)\n",
    "        plotly.offline.iplot(figs[i])\n",
    "        \n",
    "    print( HitsStr )    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def plotPDFperSubBin():\n",
    "    # init parameters\n",
    "    if SELECTED_VARIABLE == \"Ohmic\":\n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"\n",
    "        JH_min = 0\n",
    "        JH_max = 7 #197 #1.538087e-06 * 10**8 / 10 #1.4e-7\n",
    "    elif SELECTED_VARIABLE == \"SIGMA_PED\":\n",
    "        MultiplicationFactor = 10**3 \n",
    "        new_units = \"mS/m\"\n",
    "    elif SELECTED_VARIABLE == \"SIGMA_HAL\":\n",
    "        MultiplicationFactor = 10**3 \n",
    "        new_units = \"mS/m\"        \n",
    "    elif SELECTED_VARIABLE == \"Convection_heating\":\n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"           \n",
    "    elif SELECTED_VARIABLE == \"Wind_heating\":\n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"                   \n",
    "    elif SELECTED_VARIABLE == \"EEX_si\" or SELECTED_VARIABLE == \"EEY_si\":\n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"mV/m\"      \n",
    "    elif SELECTED_VARIABLE == \"JH/mass\":\n",
    "        MultiplicationFactor = 1 \n",
    "        new_units = \"W/kg\"\n",
    "    elif SELECTED_VARIABLE == \"JH/pressure\":\n",
    "        MultiplicationFactor = 1 \n",
    "        new_units = \"sec^-1\"        \n",
    "    else:\n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"?\"         \n",
    "    print(\"SELECTED_VARIABLE=\", SELECTED_VARIABLE)\n",
    "\n",
    "    \n",
    "    # Region info:\n",
    "    RegionID = SavedFilenames_Dropdown.value[ : -1 ]\n",
    "    RegionID = RegionID[ RegionID.rfind('/')+1 : ]\n",
    "    RegionID = RegionID[ : RegionID.find('.') ]\n",
    "    regionAltMin = regionMLTmin = regionMagLatMin =  99999\n",
    "    regionAltMax = regionMLTmax = regionMagLatMax = -99999\n",
    "    All_KpRanges = list()        \n",
    "    for B in Bins:\n",
    "        if B.ID.startswith( RegionID ):\n",
    "            if [B.Kp_min, B.Kp_max] not in All_KpRanges: \n",
    "                All_KpRanges.append( [B.Kp_min, B.Kp_max] )  \n",
    "            if regionAltMin>B.Altitude_min: regionAltMin = B.Altitude_min\n",
    "            if regionAltMax<B.Altitude_max: regionAltMax = B.Altitude_max\n",
    "            if regionMLTmin>B.MLT_min: regionMLTmin = B.MLT_min\n",
    "            if regionMLTmax<B.MLT_max: regionMLTmax = B.MLT_max\n",
    "            if regionMagLatMin>B.MagLat_min: regionMagLatMin = B.MagLat_min\n",
    "            if regionMagLatMax<B.MagLat_max: regionMagLatMax = B.MagLat_max\n",
    "    if regionMLTmax <= regionMLTmin: regionMLTmax += 24    \n",
    "    print(\"REGION=\", RegionID, \"    (\", regionAltMin, regionAltMax, \") (\", regionMLTmin,  regionMLTmax, \") (\", regionMagLatMin,  regionMagLatMax, \")\" )\n",
    "\n",
    "    \n",
    "    DataFolders = [ SavedFilenames_Dropdown.value, SavedFilenamesDuplicate_Dropdown.value ]\n",
    "    fig_log = make_subplots(rows=1, cols=len(All_KpRanges), shared_yaxes=True, horizontal_spacing=0.015)\n",
    "    fig_lin = make_subplots(rows=1, cols=len(All_KpRanges), shared_yaxes=True, horizontal_spacing=0.015)\n",
    "\n",
    "    for aDataFolder in DataFolders:\n",
    "        LoadResults_CDF( aDataFolder, loadGlobalValues=False, loadTimeValues=False, loadMagLatValues=True, loadMLTvalues=True, loadAltValues=True, loadLatValues=False )\n",
    "        \n",
    "        # decide line type and opacity\n",
    "        if \"Hz\" in aDataFolder or \"Tricubic\" in aDataFolder: # it is orbit data\n",
    "            LineType = \"dot\"\n",
    "            LineFade = 0.5\n",
    "        else: # it is tiegcm-grid data\n",
    "            LineType = \"solid\"\n",
    "            LineFade = 0\n",
    "            \n",
    "        #### apply the MultiplicationFactor to fix the variable's units and the log-scale if necessary\n",
    "        num_of_subBins = 0\n",
    "        for B in Bins:\n",
    "            if B.ID.startswith(RegionID) and len(B.JH_values)>0:\n",
    "                num_of_subBins += 1\n",
    "                for i in range(0, len(B.JH_values)):\n",
    "                    B.JH_values[i] *= MultiplicationFactor\n",
    "        CalculateStatsOnData()            \n",
    "    \n",
    "        #### Plot \n",
    "        BinAnnotations = list()\n",
    "        FigureShapes = list()\n",
    "        MyColorsIndex = 0\n",
    "        SubPlotIdx = 0\n",
    "        BinIdx = 0\n",
    "        Npercentage = 0\n",
    "        for B in Bins:\n",
    "            if B.ID.startswith(RegionID) and len(B.JH_values)>0:\n",
    "                \n",
    "                Tmin = \"{:.3f}\".format( min(B.JH_values) )\n",
    "                Tmax = \"{:.3f}\".format( max(B.JH_values) )\n",
    "                Tmean = \"{:.3f}\".format( np.mean(B.JH_values) )\n",
    "                Tmedian = \"{:.3f}\".format( np.percentile(B.JH_values, 50) )\n",
    "                Tper10 = \"{:.3f}\".format( np.percentile(B.JH_values, 10) )\n",
    "                Tper90 = \"{:.3f}\".format( np.percentile(B.JH_values, 90) )\n",
    "                print(B.ID, B.Kp_min,\"<Kp<\",B.Kp_max, B.Altitude_min,\"<Alt<\",B.Altitude_max)\n",
    "                print( \"    min =\", Tmin, \" max=\", Tmax, \" mean =\", Tmean, \" median =\", Tmedian, \" percentile10 =\", Tper10, \" percentile90 =\", Tper90)\n",
    "                \n",
    "                # choose which sub-plot will host this Bin's data\n",
    "                #SubPlotIdx += 1\n",
    "                # find out the plot team\n",
    "                for i in range(0, len(All_KpRanges)):\n",
    "                    if B.Kp_min==All_KpRanges[i][0] and B.Kp_max==All_KpRanges[i][1]: PlotTeam = i+1 \n",
    "                SubPlotIdx = PlotTeam\n",
    "                # decide  color\n",
    "                MyColorsIndex = PlotTeam - 1\n",
    "                #if \"Hz\" in aDataFolder or \"Tricubic\" in aDataFolder: MyColorsIndex += 5\n",
    "                currentColor = MyColors[MyColorsIndex]\n",
    "                # decide how many data points will be plotted \n",
    "                #if Npercentage == 0: Npercentage = 2000 / len(B.JH_values)\n",
    "                #num_of_points_to_plot = int( len(B.JH_values) * Npercentage )\n",
    "                #step_per_subBin = int ( len(B.JH_values) / num_of_points_to_plot )\n",
    "                #print( \"Alt\", B.Altitude_min, B.Altitude_max, \" Kp\", B.Kp_min, B.Kp_max, \"  Ploting\", num_of_points_to_plot, \" out of \", len(B.JH_values), \"points\" )\n",
    "                # **** add info as legend for this bin\n",
    "                if \"Hz\" in aDataFolder or \"Tricubic\" in aDataFolder:\n",
    "                    prefix = \"Orbit \"\n",
    "                else:\n",
    "                    prefix = \"TIEGCM \"\n",
    "                fig_log.append_trace( go.Scatter(name=prefix + B.ID + \": \" + str(B.Altitude_min) + \"<Alt<\"+ str(B.Altitude_max) + \" <b>\" + str(B.Kp_min) + \"<Kp<\" + str(B.Kp_max) + \"</b>\" + \" Median=\" + \"{:.3f}\".format(B.JH_mean) + \" Variance=\" + \"{:.3f}\".format(B.JH_variance) + \" St.Dev.=\" + \"{:.3f}\".format(B.JH_variance**(1/2)), x=[-1], y=[-1], mode='markers', marker_size=1, marker_color=currentColor), row=1, col=SubPlotIdx )\n",
    "                fig_lin.append_trace( go.Scatter(name=prefix + B.ID + \": \" + str(B.Altitude_min) + \"<Alt<\"+ str(B.Altitude_max) + \" <b>\" + str(B.Kp_min) + \"<Kp<\" + str(B.Kp_max) + \"</b>\" + \" Median=\" + \"{:.3f}\".format(B.JH_mean) + \" Variance=\" + \"{:.3f}\".format(B.JH_variance) + \" St.Dev.=\" + \"{:.3f}\".format(B.JH_variance**(1/2)), x=[-1], y=[-1], mode='markers', marker_size=1, marker_color=currentColor), row=1, col=SubPlotIdx )\n",
    "                # **** plot data points\n",
    "                #fig_log.append_trace( go.Scatter(name=SELECTED_VARIABLE_longname, x=B.JH_values[::step_per_subBin], y=B.Altitude_values[::step_per_subBin], mode='markers', marker_size=2, marker_color=currentColor, opacity=0.5, showlegend=False), row=1, col=SubPlotIdx )\n",
    "                #fig_lin.append_trace( go.Scatter(name=SELECTED_VARIABLE_longname, x=B.JH_values[::step_per_subBin], y=B.Altitude_values[::step_per_subBin], mode='markers', marker_size=2, marker_color=currentColor, opacity=0.5, showlegend=False), row=1, col=SubPlotIdx )\n",
    "                #################\n",
    "                # find the values which fall in this bin\n",
    "                num_of_buckets = 150\n",
    "                bucket_widths  = list()\n",
    "                bucket_starts  = list()\n",
    "                Buckets        = [0] * num_of_buckets\n",
    "                factor1 = 1.2 # 1.085\n",
    "                factor2 = 2.2 # 1\n",
    "                for j in range( 0, num_of_buckets ):\n",
    "                    bucket_widths.append( 0.02 + factor1**((j+1)/factor2) - factor1**(j/factor2) )\n",
    "                bucket_widths = [0.020, 0.024, 0.029, 0.035, 0.041, 0.050, 0.060, 0.072, 0.086, 0.103, 0.124, 0.149, 0.178, 0.214, 0.257, 0.308, 0.370, 0.444, 0.532, 0.639, 0.767, 0.920, 1.104, 1.325, 1.590, 1.908, 2.290, 2.747, 3.297]\n",
    "                bucket_widths = [JH_max/num_of_buckets] * (num_of_buckets-1)\n",
    "                \n",
    "                for j in range( 0, num_of_buckets ):\n",
    "                    if j == 0:\n",
    "                        bucket_starts.append( JH_min )\n",
    "                    else:\n",
    "                        bucket_starts.append( bucket_starts[-1] + bucket_widths[j-1] )\n",
    "                        \n",
    "                #if '1' in B.ID:\n",
    "                #    print( \"bucket_widths\", bucket_widths )\n",
    "                #    print( \"bucket_starts\", bucket_starts )\n",
    "                    \n",
    "                # calculate Probability Density\n",
    "                for i in range(0, len(B.JH_values)):\n",
    "                    dropped = False\n",
    "                    for j in range( 1, num_of_buckets ):\n",
    "                        if B.JH_values[i] < bucket_starts[j]:\n",
    "                            Buckets[ j-1 ] += 1\n",
    "                            dropped = True\n",
    "                            break\n",
    "                    if dropped==False and B.JH_values[i]<bucket_starts[-1]+bucket_widths[-1]: # this goes into the last bucket\n",
    "                        Buckets[-1] += 1\n",
    "                #print( \"Buckets\", Buckets )\n",
    "                # normalize to [0,1] * Bin Altitude\n",
    "                localMax = max( Buckets )\n",
    "                for j in range( 0, num_of_buckets ):\n",
    "                    Buckets[j] = (Buckets[j] / localMax) * (B.Altitude_max-B.Altitude_min) + B.Altitude_min\n",
    "                # eliminate zero values in case of log scale - only for plotting reasons\n",
    "                bucket_starts_logscale = bucket_starts.copy()\n",
    "                Buckets_logscale = Buckets.copy()\n",
    "                if bucket_starts_logscale[0] <= 0: \n",
    "                    #del bucket_starts_logscale[0:2]\n",
    "                    #del Buckets_logscale[0:2]\n",
    "                    bucket_starts_logscale[0] = (JH_max / num_of_buckets) / 2\n",
    "                # expand end of line\n",
    "                #bucket_starts[num_of_buckets-1] = JH_max                    \n",
    "                # **** plot Probability Density Function for this bin\n",
    "                fig_log.add_trace( go.Scatter(x=bucket_starts_logscale, y=Buckets_logscale, mode='lines', line=dict(color=currentColor,width=6,dash=LineType), opacity=1-LineFade, showlegend=False), row=1, col=SubPlotIdx)\n",
    "                fig_lin.add_trace( go.Scatter(x=bucket_starts,          y=Buckets,          mode='lines', line=dict(color=currentColor,width=6,dash=LineType), opacity=1-LineFade, showlegend=False), row=1, col=SubPlotIdx)\n",
    "                #print( \">>>> bucket values: \", Buckets[0], Buckets[1] )\n",
    "            \n",
    "                # **** add visuals for the median line\n",
    "                Percentile50 = B.JH_median #np.percentile(B.JH_values, 50)\n",
    "                fig_log.add_trace( go.Scatter(x=[Percentile50,Percentile50], y=[B.Altitude_min,B.Altitude_max], mode='lines', line=dict(color=currentColor,width=6,dash=LineType), opacity=1-LineFade, showlegend=False), row=1, col=SubPlotIdx)\n",
    "                fig_lin.add_trace( go.Scatter(x=[Percentile50,Percentile50], y=[B.Altitude_min,B.Altitude_max], mode='lines', line=dict(color=currentColor,width=6,dash=LineType), opacity=1-LineFade, showlegend=False), row=1, col=SubPlotIdx)\n",
    "                # **** add visuals for standard deviation\n",
    "                fig_log.add_trace( go.Scatter(x=[Percentile50-(B.JH_medianVariance)**(1/2)/2,Percentile50+(B.JH_medianVariance)**(1/2)/2], y=[B.Altitude_min+(B.Altitude_max-B.Altitude_min)/2, B.Altitude_min+(B.Altitude_max-B.Altitude_min)/2], mode='lines', line=dict(color=currentColor,width=4,dash=LineType), opacity=1-LineFade, showlegend=False), row=1, col=SubPlotIdx)            \n",
    "                fig_lin.add_trace( go.Scatter(x=[Percentile50-(B.JH_medianVariance)**(1/2)/2,Percentile50+(B.JH_medianVariance)**(1/2)/2], y=[B.Altitude_min+(B.Altitude_max-B.Altitude_min)/2, B.Altitude_min+(B.Altitude_max-B.Altitude_min)/2], mode='lines', line=dict(color=currentColor,width=4,dash=LineType), opacity=1-LineFade, showlegend=False), row=1, col=SubPlotIdx)            \n",
    "\n",
    "    # update layout\n",
    "    fig_log.update_layout( annotations=BinAnnotations )\n",
    "    fig_log.update_layout( shapes=FigureShapes )\n",
    "    fig_log.update_layout( title=getBinDescription(CALCULATIONS_RegionName) + \"<br>\" + SELECTED_VARIABLE_longname + \" (\" + new_units + \"). Probability Density for TIEGCM grid (solid) and Daedalus orbit (dotted) \", width=4800, height=1800, legend_orientation=\"h\", legend= {'itemsizing': 'constant'}) \n",
    "    fig_log.update_yaxes(title=\"Altitude (km)\", row=1, col=1)\n",
    "    fig_lin.update_layout( annotations=BinAnnotations )\n",
    "    fig_lin.update_layout( shapes=FigureShapes )\n",
    "    fig_lin.update_layout( title=getBinDescription(CALCULATIONS_RegionName) + \"<br>\" + SELECTED_VARIABLE_longname + \" (\" + new_units + \"). Probability Density for TIEGCM grid (solid) and Daedalus orbit (dotted) \", width=4800, height=1800, legend_orientation=\"h\", legend= {'itemsizing': 'constant'}) \n",
    "    fig_lin.update_yaxes(title=\"Altitude (km)\", row=1, col=1)\n",
    "    # increase font size\n",
    "    fig_log.update_xaxes( tickfont=dict(size=34) )\n",
    "    fig_log.update_yaxes( tickfont=dict(size=34) )\n",
    "    fig_lin.update_xaxes( tickfont=dict(size=34) )\n",
    "    fig_lin.update_yaxes( tickfont=dict(size=34) )\n",
    "    # ======== plot log scale\n",
    "    i = 0\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID) and len(B.JH_values)>0:\n",
    "            fig_log.update_yaxes(range=[regionAltMin, regionAltMax], row=1, col=i+1)\n",
    "            fig_log.update_xaxes(type=\"log\", row=1, col=i+1 )\n",
    "            i = i + 1\n",
    "    plotly.offline.init_notebook_mode(connected=True)\n",
    "    plotly.offline.iplot(fig_log)    \n",
    "    # ======== plot linear scale\n",
    "    i = 0\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID) and len(B.JH_values)>0:\n",
    "            fig_lin.update_yaxes(range=[regionAltMin, regionAltMax], row=1, col=i+1)\n",
    "            fig_lin.update_xaxes(range=[JH_min, JH_max], row=1, col=i+1 )\n",
    "            i = i + 1\n",
    "    plotly.offline.init_notebook_mode(connected=True)\n",
    "    plotly.offline.iplot(fig_lin)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "def plotAltProfilesNatural_perKpRange( ):\n",
    "    #global Profiles, MLTsequence, MLT_duration_of_a_profile, ALT_distance_of_a_bucket, regionMLTmax, regionMLTmin\n",
    "    # init parameters\n",
    "    if SELECTED_VARIABLE == \"Ohmic\":\n",
    "        x_axes_range=[0, 6]\n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"\n",
    "    elif SELECTED_VARIABLE == \"SIGMA_PED\":\n",
    "        x_axes_range=[0, 0.15]\n",
    "        MultiplicationFactor = 10**3 \n",
    "        new_units = \"mS/m\"\n",
    "    elif SELECTED_VARIABLE == \"SIGMA_HAL\":\n",
    "        x_axes_range=[0, 0.4] \n",
    "        MultiplicationFactor = 10**3 \n",
    "        new_units = \"mS/m\"        \n",
    "    elif SELECTED_VARIABLE == \"Convection_heating\":\n",
    "        x_axes_range=[0, 6] \n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"           \n",
    "    elif SELECTED_VARIABLE == \"Wind_heating\":\n",
    "        x_axes_range=[0, 6] \n",
    "        MultiplicationFactor = 10**8 \n",
    "        new_units = \"10^-8 W/m3\"                   \n",
    "    elif SELECTED_VARIABLE == \"EEX_si\" or SELECTED_VARIABLE == \"EEY_si\":\n",
    "        x_axes_range=[-24, 0] \n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"mV/m\"        \n",
    "    else:\n",
    "        x_axes_range=[0, 100] \n",
    "        MultiplicationFactor = 1\n",
    "        new_units = \"?\" \n",
    "        \n",
    "    print(SELECTED_VARIABLE)\n",
    "\n",
    "    # Region specific binning:\n",
    "    if \"(\" in CALCULATIONS_RegionName:\n",
    "        RegionID = CALCULATIONS_RegionName[ CALCULATIONS_RegionName.find('(')+1 : CALCULATIONS_RegionName.rfind(')') ]\n",
    "    else:\n",
    "        RegionID = CALCULATIONS_RegionName\n",
    "    regionMLTmin = 999\n",
    "    regionMLTmax = -999\n",
    "    regionALTmin = 999\n",
    "    regionALTmax = -999\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith( RegionID ):\n",
    "            if regionMLTmin>B.MLT_min: regionMLTmin = B.MLT_min\n",
    "            if regionMLTmax<B.MLT_max: regionMLTmax = B.MLT_max\n",
    "            if regionALTmin>B.Altitude_min: regionALTmin = B.Altitude_min\n",
    "            if regionALTmax<B.Altitude_max: regionALTmax = B.Altitude_max\n",
    "    if regionMLTmax < regionMLTmin: regionMLTmax += 24\n",
    "        \n",
    "    # init data structures\n",
    "    Profiles = dict()\n",
    "    if \"TRO\" in RegionID:\n",
    "        MLT_duration_of_a_profile = 3        \n",
    "    else:\n",
    "        MLT_duration_of_a_profile = 6\n",
    "    ALT_distance_of_a_bucket  = 5\n",
    "    MLTsequence     = list( range( regionMLTmin, regionMLTmax, MLT_duration_of_a_profile) )\n",
    "    KPsequence      = [ 0, 2, 4 ] \n",
    "    for B in Bins:\n",
    "        if B.ID.startswith( RegionID ):\n",
    "            print( B.ID )\n",
    "            for aMLT in MLTsequence:\n",
    "                Profiles[(B.Kp_min, aMLT, B.Altitude_min)] = list()\n",
    "      \n",
    "    # Binning: put data in the profiles\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith( RegionID ):\n",
    "            for i in range( 0, len(B.JH_values) ):\n",
    "                # find the MLT to fall\n",
    "                MLT_tocheck = B.MLT_values[i]\n",
    "                if regionMLTmax>24  and  MLT_tocheck<=regionMLTmax-24:\n",
    "                    MLT_tocheck += 24\n",
    "                for seq_idx in range(0, len(MLTsequence)):\n",
    "                    if MLT_tocheck>=MLTsequence[seq_idx] and MLT_tocheck<MLTsequence[seq_idx]+MLT_duration_of_a_profile: \n",
    "                        mlt_to_fall=MLTsequence[seq_idx]\n",
    "                        break\n",
    "                if MLT_tocheck == MLTsequence[len(MLTsequence)-1]+MLT_duration_of_a_profile: mlt_to_fall = MLTsequence[len(MLTsequence)-1] # for last MLT position\n",
    "                # store it into the correct profile\n",
    "                Profiles[ B.Kp_min, mlt_to_fall, B.Altitude_min].append( B.JH_values[i] )      \n",
    "\n",
    "    # plot\n",
    "    Color10 = '#c4dfe6'\n",
    "    Color25 = '#a1d6e2'\n",
    "    Color50 = '#1995ad'\n",
    "    Color75 = '#a1d6e2'\n",
    "    Color90 = '#c4dfe6'\n",
    "    \n",
    "    # construct the column MLT titles #(\"0-3\", \"3-6\", \"6-9\", \"9-12\", \"12-15\", \"15-18\", \"18-21\", \"21-24\")\n",
    "    ColumnTitles = list()\n",
    "    \n",
    "    for i in range(0, len(MLTsequence)):\n",
    "        ColumnTitles.append( \"MLT \" + str(MLTsequence[i]) + \"-\"  + str(MLTsequence[i]+MLT_duration_of_a_profile) )\n",
    "    # define secondary y-axis at the right of the plot\n",
    "    mySpecs = list()\n",
    "    for row in range(0, len(KPsequence)):\n",
    "        mySpecs.append( list() )\n",
    "        for col in range(0, len(MLTsequence)):\n",
    "            mySpecs[row].append( {\"secondary_y\": True} )\n",
    "\n",
    "    #make plot\n",
    "    fig = make_subplots(rows=len(KPsequence), cols=len(MLTsequence), shared_xaxes=True, shared_yaxes=True, vertical_spacing=0.035, horizontal_spacing=0.01, subplot_titles=ColumnTitles, specs=mySpecs)\n",
    "    for aKP in KPsequence:\n",
    "        for aMLT in MLTsequence:\n",
    "            #Means = list()\n",
    "            Percentiles10 = list()\n",
    "            Percentiles25 = list()\n",
    "            Percentiles50 = list()            \n",
    "            Percentiles75 = list()\n",
    "            Percentiles90 = list()\n",
    "            visibleALTsequence = list()\n",
    "            hits  = 0\n",
    "            \n",
    "            # find the ALTsequence of this bin\n",
    "            ALTsequence = list()\n",
    "            for B in Bins:\n",
    "                if B.ID.startswith( RegionID ) and B.Kp_min==aKP:\n",
    "                    ALTsequence.append( B.Altitude_min )\n",
    "            print( \"    >>>\", ALTsequence )\n",
    "             \n",
    "            # compute percentiles\n",
    "            for anALT in ALTsequence:\n",
    "                print(\"  \", anALT, \"km     hits =\",  len(Profiles[(aKP, aMLT, anALT)]))\n",
    "                hits += len(Profiles[(aKP, aMLT, anALT)])\n",
    "                if len(Profiles[(aKP, aMLT, anALT)]) > 0:\n",
    "                    #Means.append(  sum(Profiles[(aKP, aMLT, anALT)]) / len(Profiles[(aKP, aMLT, anALT)]) )\n",
    "                    Percentiles10.append( np.percentile(Profiles[(aKP, aMLT, anALT)], 10) )\n",
    "                    Percentiles25.append( np.percentile(Profiles[(aKP, aMLT, anALT)], 25) )\n",
    "                    Percentiles50.append( np.percentile(Profiles[(aKP, aMLT, anALT)], 50) )                    \n",
    "                    Percentiles75.append( np.percentile(Profiles[(aKP, aMLT, anALT)], 75) )\n",
    "                    Percentiles90.append( np.percentile(Profiles[(aKP, aMLT, anALT)], 90) )\n",
    "                    visibleALTsequence.append( anALT )\n",
    "            print( \"Kp = \", aKP, \"MLT =\", aMLT, \"   Hits =\", hits, \"  \", datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\") )\n",
    "            \n",
    "            # change units\n",
    "            for i in range(0,len(Percentiles50)): \n",
    "                #Means[i] *= MultiplicationFactor\n",
    "                Percentiles10[i] *= MultiplicationFactor\n",
    "                Percentiles25[i] *= MultiplicationFactor\n",
    "                Percentiles50[i] *= MultiplicationFactor\n",
    "                Percentiles75[i] *= MultiplicationFactor\n",
    "                Percentiles90[i] *= MultiplicationFactor\n",
    "            \n",
    "            # alter visibleALTsequence so that data are displayed correctly\n",
    "            # set the point in the middle of the altitude sub-bin\n",
    "            #print(ALTsequence) print( \"Data length =\", len( Profiles[(aKP, aMLT, anALT)]) ) print( visibleALTsequence ) print( Percentiles50 )\n",
    "            for i in range(0, len(visibleALTsequence)):\n",
    "                visibleALTsequence[i] += ALT_distance_of_a_bucket/2\n",
    "            # find lowest altitude for this sub-region and set it as the first in the plot\n",
    "            LowestAltitude = 999999\n",
    "            for B in Bins:\n",
    "                if B.ID.startswith( RegionID ) and B.Kp_min==aKP:\n",
    "                    for i in range(0, len(B.Altitude_values)):\n",
    "                        if LowestAltitude > B.Altitude_values[i]: LowestAltitude = B.Altitude_values[i]\n",
    "            print(\"Kp = \", aKP, \"MLT =\", aMLT, \"  LowestAltitude=\", LowestAltitude)\n",
    "            if LowestAltitude < 10000:\n",
    "                for anALT in ALTsequence:\n",
    "                    if len(Profiles[(aKP, aMLT, anALT)]) > 0:\n",
    "                        visibleALTsequence[0] = LowestAltitude\n",
    "                        break\n",
    "            # stretch the plot to the maximum altitude\n",
    "            if len(visibleALTsequence) == 1:\n",
    "                visibleALTsequence.append( regionALTmax )\n",
    "                Percentiles10.append( Percentiles10[0] )\n",
    "                Percentiles25.append( Percentiles25[0] )\n",
    "                Percentiles50.append( Percentiles50[0] )\n",
    "                Percentiles75.append( Percentiles75[0] )\n",
    "                Percentiles90.append( Percentiles90[0] )\n",
    "            elif len(visibleALTsequence) > 1:\n",
    "                visibleALTsequence[-1] = regionALTmax\n",
    "            \n",
    "            fig.add_trace( go.Scatter(x=[0]*len(visibleALTsequence), y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color10, line=dict(color='gray',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            fig.add_trace( go.Scatter(x=Percentiles10, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color10, line=dict(color='gray',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            fig.add_trace( go.Scatter(x=Percentiles25, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color25, line=dict(color='gray',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            fig.add_trace( go.Scatter(x=Percentiles50, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color50, line=dict(color='black',width=2,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            # plot mean\n",
    "            #fig.add_trace( go.Scatter(x=Means, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor='black', line=dict(color='black',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            # plot percentiles\n",
    "            fig.add_trace( go.Scatter(x=Percentiles75, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color75, line=dict(color='gray',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "            fig.add_trace( go.Scatter(x=Percentiles90, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color90, line=dict(color='gray',width=1,), showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1,  )\n",
    "            # add a trace in order to display secondary y-axis at the right\n",
    "            fig.add_trace( go.Scatter(x=[-1000], y=[-1000], showlegend=False), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1, secondary_y=True )\n",
    "            \n",
    "    # display legends\n",
    "    fig.add_trace( go.Scatter(name='10th Perc.', x=Percentiles10, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color10, line=dict(color='gray',width=1,), showlegend=True), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "    fig.add_trace( go.Scatter(name='25th Perc.', x=Percentiles25, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color25, line=dict(color='gray',width=1,), showlegend=True), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "    fig.add_trace( go.Scatter(name='50th Perc.', x=Percentiles50, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color50, line=dict(color='black',width=2,), showlegend=True), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "    #fig.add_trace( go.Scatter(name='Mean value', x=Means, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor='#5cc5ef', line=dict(color='black',width=1,), showlegend=True), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )            \n",
    "    fig.add_trace( go.Scatter(name='75th Perc.', x=Percentiles75, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color75, line=dict(color='gray',width=1,), showlegend=True), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "    fig.add_trace( go.Scatter(name='90th Perc.', x=Percentiles90, y=visibleALTsequence, mode='lines', fill='tonexty', fillcolor=Color90, line=dict(color='gray',width=1,), showlegend=True), row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1 )\n",
    "    \n",
    "    \n",
    "    #fig.update_yaxes( title=\"Altitude(km)\" )\n",
    "    for aKP in KPsequence:\n",
    "        fig.update_yaxes( title_text=\"Altitude (km)\", row=KPsequence.index(aKP)+1, col=1, side='left', secondary_y=False)\n",
    "        row_title = \"Kp \" + str(aKP) + \" - \"\n",
    "        if aKP == 0:\n",
    "            row_title +=  \"2\"\n",
    "        elif aKP == 2:\n",
    "            row_title +=  \"4\"\n",
    "        else:\n",
    "            row_title +=  \"9\"\n",
    "        fig.update_yaxes( title_text=row_title, row=KPsequence.index(aKP)+1, col=len(MLTsequence),  side='right', secondary_y=True, showticklabels=False )\n",
    "        for aMLT in MLTsequence:\n",
    "            fig.update_yaxes( row=KPsequence.index(aKP)+1, col=MLTsequence.index(aMLT)+1, secondary_y=True, showticklabels=False )\n",
    "    fig.update_xaxes( range=x_axes_range )\n",
    "    fig.update_yaxes( range=[80, 150], dtick=10 )  \n",
    "    fig.update_layout( title = getBinDescription(CALCULATIONS_RegionName) + \"<br>\" + \"Alt.Prof. of \" + SELECTED_VARIABLE_longname + \" (\" + new_units + \")\",\n",
    "                       width=280+len(MLTsequence)*100, height=200+200*len(KPsequence), showlegend=True, legend_orientation=\"h\", legend_y=-0.04) \n",
    "    plotly.offline.init_notebook_mode(connected=True)\n",
    "    plotly.offline.iplot(fig) \n",
    "    \n",
    "    # plot more zoom versions\n",
    "    new_x_axes_range = [x * (2/3) for x in x_axes_range]\n",
    "    fig.update_xaxes( range=new_x_axes_range )\n",
    "    plotly.offline.iplot(fig) \n",
    "    new_x_axes_range = [x * (1/2) for x in x_axes_range]\n",
    "    fig.update_xaxes( range=new_x_axes_range )\n",
    "    plotly.offline.iplot(fig) \n",
    "    new_x_axes_range = [x * (3/2) for x in x_axes_range]\n",
    "    fig.update_xaxes( range=new_x_axes_range )\n",
    "    plotly.offline.iplot(fig) \n",
    "    new_x_axes_range = [x * (2.5) for x in x_axes_range]\n",
    "    fig.update_xaxes( range=new_x_axes_range )\n",
    "    plotly.offline.iplot(fig) \n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def WriteListToTextFile(TheList, TheFilename):\n",
    "    fd = open(TheFilename, \"w\") \n",
    "    for i in range(0, len(TheList)):\n",
    "        fd.write( str(TheList[i]) + \"\\n\" )\n",
    "    fd.close() \n",
    "\n",
    "\n",
    "'''\n",
    "executes several statistical tests in order to compare the distributions of two data sets\n",
    "'''\n",
    "def executeZtest( DataPath1, DataPath2 ):\n",
    "    # Region info:\n",
    "    RegionID = SavedFilenames_Dropdown.value[ : -1 ]\n",
    "    RegionID = RegionID[ RegionID.rfind('/')+1 : ]\n",
    "    RegionID = RegionID[ : RegionID.find('.') ]\n",
    "    print(\"REGION =\", RegionID )\n",
    "\n",
    "    # number of samples to be taken from each data set. Set to -1 in order to take account all data\n",
    "    k = 50\n",
    "    \n",
    "    # init data structures to hold the statistical calculations\n",
    "    Stats1 = dict()\n",
    "    Stats2 = dict()\n",
    "    Ztest_means = dict()\n",
    "    Ztest_medians = dict()\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID):\n",
    "            Stats1[( B.ID, \"AllData\" )] = list()            \n",
    "            Stats1[( B.ID, \"Sample\" )] = list()\n",
    "            Stats1[( B.ID, \"Median\" )] = 0\n",
    "            Stats1[( B.ID, \"MAD\" )] = 0\n",
    "            Stats1[( B.ID, \"Mean\" )] = 0\n",
    "            Stats1[( B.ID, \"StDev\" )] = 0\n",
    "            Stats1[( B.ID, \"num_of_datapoints\" )] = 0\n",
    "            Stats2[( B.ID, \"AllData\" )] = list()            \n",
    "            Stats2[( B.ID, \"Sample\" )] = list()\n",
    "            Stats2[( B.ID, \"Median\" )] = 0\n",
    "            Stats2[( B.ID, \"MAD\" )] = 0\n",
    "            Stats2[( B.ID, \"Mean\" )] = 0\n",
    "            Stats2[( B.ID, \"StDev\" )] = 0\n",
    "            Stats2[( B.ID, \"num_of_datapoints\" )] = 0\n",
    "            Ztest_means[( B.ID, \"Z\" )] = 0\n",
    "            Ztest_medians[( B.ID, \"Z\" )] = 0\n",
    "    \n",
    "    # ---------------- Load data set 1\n",
    "    print(\"Loading data set 1:\", DataPath1)\n",
    "    LoadResults_CDF( DataPath1, loadGlobalValues=False, loadTimeValues=False, loadMagLatValues=False, loadMLTvalues=False, loadAltValues=False, loadLatValues=False )\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID):\n",
    "            if len(B.JH_values) > 0: WriteListToTextFile(B.JH_values, \"Data/dataset1_\"+B.ID+\".txt\")\n",
    "            Stats1[( B.ID, \"AllData\" )] = B.JH_values.copy()\n",
    "    # reduce data to samples\n",
    "    if k > 0:\n",
    "        for B in Bins:\n",
    "            if B.ID.startswith(RegionID):\n",
    "                if len(B.JH_values) > k:\n",
    "                    B.JH_values = random.sample(B.JH_values, k) \n",
    "                    Stats1[( B.ID, \"Sample\" )] = B.JH_values.copy()\n",
    "                    print(\"-------- TIEGCM\", B.ID, \"--------\")\n",
    "                    print( Stats1[( B.ID, \"Sample\" )] )\n",
    "                else:\n",
    "                    print( B.ID, \"has a only\", len(B.JH_values), \"items\" )\n",
    "        CalculateStatsOnData()\n",
    "        print(\"Data reduced to a sample of\", k)\n",
    "    print(\"TIEGCM\")\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID):\n",
    "            Stats1[( B.ID, \"Median\" )] = B.JH_median\n",
    "            Stats1[( B.ID, \"Mean\" )] = B.JH_mean\n",
    "            Stats1[( B.ID, \"StDev\" )] = math.sqrt( B.JH_variance )\n",
    "            Stats1[( B.ID, \"MAD\" )] = B.JH_medianAbsDev\n",
    "            Stats1[( B.ID, \"num_of_datapoints\" )] = len( B.JH_values )\n",
    "            print( \" \", B.ID, \" Mean =\", \"{:.3e}\".format(Stats1[( B.ID, \"Mean\" )]), \" StDev =\", \"{:.3e}\".format(Stats1[( B.ID, \"StDev\" )]), \" Median =\", \"{:.3e}\".format(Stats1[( B.ID, \"Median\" )]), \" MAD =\",\"{:.3e}\".format(Stats1[( B.ID, \"MAD\" )]), \" points =\",Stats1[(B.ID, \"num_of_datapoints\" )] )\n",
    "            \n",
    "            \n",
    "    # ---------------- Load data set 2\n",
    "    print(\"Loading data set 2:\", DataPath2)\n",
    "    LoadResults_CDF( DataPath2, loadGlobalValues=False, loadTimeValues=False, loadMagLatValues=False, loadMLTvalues=False, loadAltValues=False, loadLatValues=False )\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID):\n",
    "            if len(B.JH_values) > 0: WriteListToTextFile(B.JH_values, \"Data/dataset2_\"+B.ID+\".txt\")\n",
    "            Stats2[( B.ID, \"AllData\" )] = B.JH_values.copy()\n",
    "    # reduce data to samples\n",
    "    if k > 0:\n",
    "        for B in Bins:\n",
    "            if B.ID.startswith(RegionID):\n",
    "                if len(B.JH_values) > k:\n",
    "                    B.JH_values = random.sample(B.JH_values, k) \n",
    "                    Stats2[( B.ID, \"Sample\" )] = B.JH_values.copy()\n",
    "                    print(\"-------- Orbit\", B.ID, \"--------\")\n",
    "                    print( Stats2[( B.ID, \"Sample\" )] )\n",
    "                else:\n",
    "                    print( B.ID, \"has a only\", len(B.JH_values), \"items\" )\n",
    "        CalculateStatsOnData()\n",
    "        print(\"Data reduces to a sample of\", k)\n",
    "    print(\"ORBIT\")\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID):\n",
    "            Stats2[( B.ID, \"Median\" )] = B.JH_median\n",
    "            Stats2[( B.ID, \"Mean\" )] = B.JH_mean\n",
    "            Stats2[( B.ID, \"StDev\" )] = math.sqrt( B.JH_variance )\n",
    "            Stats2[( B.ID, \"MAD\" )] = B.JH_medianAbsDev\n",
    "            Stats2[( B.ID, \"num_of_datapoints\" )] = len( B.JH_values )\n",
    "            print( \" \", B.ID, \" Mean =\", \"{:.3e}\".format(Stats2[( B.ID, \"Mean\" )]), \" StDev =\", \"{:.3e}\".format(Stats2[( B.ID, \"StDev\" )]), \" Median =\", \"{:.3e}\".format(Stats2[( B.ID, \"Median\" )]), \" MAD =\",\"{:.3e}\".format(Stats2[( B.ID, \"MAD\" )]), \" points =\", Stats2[(B.ID, \"num_of_datapoints\" )] )\n",
    "            \n",
    "    ''' testing with numbers from the example\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID):            \n",
    "            Stats1[( B.ID, \"Mean\" )] = 51.5 \n",
    "            Stats2[( B.ID, \"Mean\" )] = 39.5 \n",
    "    \n",
    "            Stats1[( B.ID, \"StDev\" )] = 8\n",
    "            Stats2[( B.ID, \"StDev\" )] = 7\n",
    "\n",
    "            Stats1[( B.ID, \"num_of_datapoints\" )] = 25\n",
    "            Stats2[( B.ID, \"num_of_datapoints\" )] = 25\n",
    "    '''\n",
    "    \n",
    "    # ######## Execute the Z-test http://homework.uoregon.edu/pub/class/es202/ztest.html\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID):\n",
    "            # ------------ for mean values\n",
    "            a = Stats1[( B.ID, \"Mean\" )] - Stats2[( B.ID, \"Mean\" )]\n",
    "            try:\n",
    "                s1 = Stats1[( B.ID, \"StDev\" )] / math.sqrt( Stats1[( B.ID, \"num_of_datapoints\" )] )\n",
    "            except:\n",
    "                s1 = 0\n",
    "            try:\n",
    "                s2 = Stats2[( B.ID, \"StDev\" )] / math.sqrt( Stats2[( B.ID, \"num_of_datapoints\" )] )\n",
    "            except:\n",
    "                s2 = 0\n",
    "            b = math.sqrt( s1**2 + s2**2 )\n",
    "            if b!=0: Ztest_means[( B.ID, \"Z\" )] = a / b\n",
    "            #if b!=0: print(\"s1=\",s1, \"  s2=\",s2, \"  a=\",a, \"  b=\",b, \" z=\", a/b)\n",
    "            # ------------ for median values\n",
    "            a = Stats1[( B.ID, \"Median\" )] - Stats2[( B.ID, \"Median\" )]\n",
    "            try:\n",
    "                s1 = Stats1[( B.ID, \"MAD\" )] / math.sqrt( Stats1[( B.ID, \"num_of_datapoints\" )] )\n",
    "            except:\n",
    "                s1 = 0\n",
    "            try:\n",
    "                s2 = Stats2[( B.ID, \"MAD\" )] / math.sqrt( Stats2[( B.ID, \"num_of_datapoints\" )] )\n",
    "            except:\n",
    "                s2 = 0\n",
    "            b = math.sqrt( s1**2 + s2**2 )\n",
    "            if b!=0 : Ztest_medians[( B.ID, \"Z\" )] = a / b\n",
    "            # ----------------- from wikipedia\n",
    "            try:\n",
    "                SE = Stats1[( B.ID, \"StDev\" )] / math.sqrt( Stats2[( B.ID, \"num_of_datapoints\" )] )\n",
    "                z = (Stats2[( B.ID, \"Mean\" )] - Stats1[( B.ID, \"Mean\" )]) / SE\n",
    "                print( B.ID, \"WikipediaZ =\", z )\n",
    "            except:\n",
    "                print( B.ID, \"WikipediaZ = NaN\",  )\n",
    "            \n",
    "    # display results of the z-test\n",
    "    print(\"\\nZ-test results for region\", RegionID, \":\")\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID) and len(B.JH_values)>0:\n",
    "            print(\"   \", B.ID, \"  \", B.Kp_min,\"<Kp<\",B.Kp_max, \"  \", B.Altitude_min,\"<Alt<\",B.Altitude_max, \"   Z of means =\", \"{:.3f}\".format(Ztest_means[( B.ID, \"Z\" )]), \"   Z of medians =\", \"{:.3f}\".format(Ztest_medians[( B.ID, \"Z\" )]) )\n",
    "        \n",
    "    # ############ execute Wilcoxon test\n",
    "    #Stats1[( \"AEM_L2\", \"Sample\" )] = [2.5951188e-08, 5.3817932e-09, 4.5183768e-08, 1.551039e-10, 1.0724093e-09, 4.962505e-09, 5.4119514e-10, 3.945805e-09, 5.9539945e-10, 1.8923414e-08, 1.960878e-09, 4.055865e-09, 1.7519519e-10, 1.3301345e-08, 1.2372746e-07, 1.2138809e-08, 8.16415e-09, 3.289174e-10, 8.7328536e-09, 3.827526e-08, 5.4933094e-09, 3.4882688e-09, 1.7631713e-08, 4.8599507e-09, 1.0905276e-09, 6.7475585e-09, 5.2583008e-08, 1.3054376e-08, 2.8305527e-09, 3.3543217e-09, 6.1289263e-09, 2.352899e-08, 2.0256745e-09, 6.2435213e-09, 1.1858019e-08, 8.533459e-09, 2.687838e-09, 1.875761e-08, 9.90745e-12, 4.014579e-10, 5.657707e-10, 4.473683e-09, 4.9620965e-09, 1.695748e-09, 1.5530714e-08, 5.283186e-10, 2.5974272e-09, 1.3884176e-08, 5.4488223e-09, 1.8228039e-09]\n",
    "    #Stats1[( \"AEM_L3\", \"Sample\" )] = [2.925222e-08, 2.8446618e-09, 1.2962599e-08, 4.0733735e-08, 1.13316e-08, 3.9474628e-08, 1.04909297e-10, 1.15847726e-07, 1.0136927e-09, 1.9383768e-10, 6.831934e-09, 1.0782474e-08, 1.2424795e-10, 4.196759e-09, 5.1174908e-08, 1.7030825e-08, 1.0095899e-08, 1.1140663e-08, 4.077417e-09, 9.559168e-09, 4.920846e-08, 2.398426e-08, 1.690071e-08, 2.2489953e-08, 9.672096e-12, 1.4901229e-10, 1.8795976e-09, 3.1964256e-10, 1.7421792e-09, 4.656256e-09, 7.853907e-09, 1.7165107e-08, 9.6540695e-09, 3.952511e-09, 1.9861e-09, 5.2326378e-08, 6.117663e-09, 1.224011e-08, 7.4337563e-09, 5.351637e-08, 1.4914312e-08, 5.9796363e-09, 2.1843855e-08, 2.0803566e-10, 9.217002e-09, 1.5518825e-08, 3.8406185e-09, 3.002403e-08, 2.3402782e-08, 1.03541e-08]\n",
    "    #Stats2[( \"AEM_L2\", \"Sample\" )] = [2.0343393e-08, 2.32117e-09, 2.813346e-08, 1.3160446e-08, 3.800517e-11, 7.743971e-09, 6.345863e-10, 2.7468875e-08, 4.077262e-08, 4.4672564e-08, 5.474968e-10, 1.2188225e-10, 3.517082e-08, 8.0183016e-10, 6.559348e-10, 5.1463047e-09, 1.8888866e-08, 1.3424133e-09, 1.0823237e-08, 4.31503e-10, 2.7409655e-08, 1.0387256e-08, 1.2501109e-08, 1.1267671e-09, 5.51157e-10, 4.859329e-09, 2.7400797e-09, 2.6947452e-08, 4.282332e-09, 1.0266081e-10, 1.7017069e-08, 3.041313e-10, 1.6484906e-08, 1.4166748e-09, 1.649007e-09, 1.0126844e-09, 6.2378396e-09, 8.235802e-11, 6.797095e-09, 5.0539932e-09, 5.7199996e-09, 1.6371768e-09, 3.067749e-10, 2.7308031e-09, 2.9056872e-09, 1.0407587e-09, 5.1806275e-09, 4.0906154e-09, 4.3983903e-08, 2.6597846e-10]\n",
    "    #Stats2[( \"AEM_L3\", \"Sample\" )] = [9.518898e-09, 1.27464e-09, 3.8833985e-08, 1.4651571e-09, 2.8009433e-09, 1.3584062e-09, 6.11956e-09, 3.107995e-09, 4.24684e-09, 3.2873103e-08, 8.475515e-09, 4.165824e-09, 3.908122e-08, 7.2805566e-09, 4.0665938e-08, 1.7837495e-08, 1.8128925e-09, 5.285636e-08, 6.3407826e-09, 5.5626117e-09, 1.4412362e-07, 1.7359745e-09, 2.1320249e-08, 1.463807e-08, 2.950494e-09, 5.9469514e-08, 1.0799843e-08, 8.250815e-09, 4.218044e-08, 6.5836275e-10, 5.35778e-10, 1.9661668e-08, 1.4192106e-07, 4.732321e-09, 1.7882544e-10, 1.223656e-08, 6.950843e-11, 6.5227748e-09, 8.1680875e-09, 7.553436e-09, 7.1417494e-10, 1.8003114e-08, 3.772138e-09, 1.3795659e-08, 8.2685325e-09, 2.240433e-10, 9.484356e-09, 3.31965e-08, 2.0636206e-08, 4.9476892e-08]\n",
    "    print(\"\\nWilcoxon-test results for region\", RegionID, \":\")\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID) and len(B.JH_values)>0:\n",
    "            # calculate diference of each pair\n",
    "            Diffs = list()\n",
    "            Signs = list()\n",
    "            for i in range(0, k):\n",
    "                n = Stats2[( B.ID, \"Sample\" )][i] - Stats1[( B.ID, \"Sample\" )][i]\n",
    "                if n > 0:\n",
    "                    Diffs.append( abs(n) )\n",
    "                    Signs.append( 1 )\n",
    "                elif n < 0:\n",
    "                    Diffs.append( abs(n) )\n",
    "                    Signs.append( -1 ) \n",
    "            # sort diferrences\n",
    "            zipped = list(zip(Diffs, Signs))\n",
    "            zipped.sort()\n",
    "            Diffs, Signs = zip(*zipped)\n",
    "            Diffs = list(Diffs)\n",
    "            Signs = list(Signs)\n",
    "            #  calculate W\n",
    "            W = 0\n",
    "            Wplus = 0\n",
    "            Wminus = 0\n",
    "            for i in range(0, len(Diffs)):\n",
    "                W += Signs[i] * (i+1)\n",
    "                if Signs[i] == +1: Wplus  += (i+1)\n",
    "                if Signs[i] == -1: Wminus += (i+1)\n",
    "            # calculate variance etc for the W distribution\n",
    "            N = len(Diffs)\n",
    "            W_variance = N*(N+1)*(2*N+1)/6\n",
    "            W_stdev = math.sqrt(W_variance)\n",
    "            W_score = W / W_stdev\n",
    "            # display\n",
    "            print(\"   \", B.ID, \" \", B.Kp_min,\"<Kp<\",B.Kp_max, \" \", B.Altitude_min,\"<Alt<\",B.Altitude_max, \"  Wplus =\", Wplus, \" Wminus =\", Wminus, \"  W =\", W, \" W-score =\", W_score )\n",
    "\n",
    "    # ############ execute scipy-ranksums test (Compute the Wilcoxon rank-sum statistic for two samples) https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ranksums.html\n",
    "    print(\"\\nscipy-ranksums-test results for region\", RegionID, \":\")\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID) and len(B.JH_values)>0:\n",
    "            TestStatistic, Pvalue = ranksums( Stats1[( B.ID, \"AllData\" )], Stats2[( B.ID, \"AllData\" )] )\n",
    "            print(\" \", B.ID, B.Kp_min,\"<Kp<\",B.Kp_max, B.Altitude_min,\"<Alt<\",B.Altitude_max, \"DataLen:\", len(Stats1[( B.ID, \"AllData\" )]), \"&\" ,len(Stats2[( B.ID, \"AllData\" )]) ,\"TestStatistic =\", TestStatistic, \"Pvalue =\", Pvalue)\n",
    "    # ############ execute mannwhitneyu-test. Mannâ€“Whitney U test, also called Mannâ€“Whitneyâ€“Wilcoxon.  https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html#scipy.stats.mannwhitneyu\n",
    "    print(\"\\nmannwhitneyu-test results for region\", RegionID, \":\")\n",
    "    for B in Bins:\n",
    "        if B.ID.startswith(RegionID) and len(B.JH_values)>0:\n",
    "            print(\" \", B.ID, B.Kp_min,\"<Kp<\",B.Kp_max, B.Altitude_min,\"<Alt<\",B.Altitude_max, \"DataLen:\", len(Stats1[( B.ID, \"AllData\" )]), \"&\" ,len(Stats2[( B.ID, \"AllData\" )]))\n",
    "            TestStatistic, Pvalue = mannwhitneyu( Stats1[( B.ID, \"AllData\" )], Stats2[( B.ID, \"AllData\" )], use_continuity=True, alternative='two-sided' )\n",
    "            print( \"     Continuity=True Alternative=two-sided:\",  \"  TestStatistic =\", TestStatistic, \"Pvalue =\", Pvalue)\n",
    "            TestStatistic, Pvalue = mannwhitneyu( Stats1[( B.ID, \"AllData\" )], Stats2[( B.ID, \"AllData\" )], use_continuity=True, alternative='less' )\n",
    "            print( \"     Continuity=True Alternative=less:     \",  \"  TestStatistic =\", TestStatistic, \"Pvalue =\", Pvalue)\n",
    "            TestStatistic, Pvalue = mannwhitneyu( Stats1[( B.ID, \"AllData\" )], Stats2[( B.ID, \"AllData\" )], use_continuity=True, alternative='greater' )\n",
    "            print( \"     Continuity=True Alternative=greater:  \",  \"  TestStatistic =\", TestStatistic, \"Pvalue =\", Pvalue)\n",
    "            TestStatistic, Pvalue = mannwhitneyu( Stats1[( B.ID, \"AllData\" )], Stats2[( B.ID, \"AllData\" )], use_continuity=False, alternative='two-sided' )\n",
    "            print( \"     Continuity=False Alternative=two-sided:\",  \"  TestStatistic =\", TestStatistic, \"Pvalue =\", Pvalue)\n",
    "            TestStatistic, Pvalue = mannwhitneyu( Stats1[( B.ID, \"AllData\" )], Stats2[( B.ID, \"AllData\" )], use_continuity=False, alternative='less' )\n",
    "            print( \"     Continuity=False Alternative=less:     \",  \"  TestStatistic =\", TestStatistic, \"Pvalue =\", Pvalue)\n",
    "            TestStatistic, Pvalue = mannwhitneyu( Stats1[( B.ID, \"AllData\" )], Stats2[( B.ID, \"AllData\" )], use_continuity=False, alternative='greater' )\n",
    "            print( \"     Continuity=False Alternative=greater:  \",  \"  TestStatistic =\", TestStatistic, \"Pvalue =\", Pvalue)\n",
    "\n",
    "            \n",
    "display( createGUI() )\n",
    "Plot_JHvsMagLat_Checkbox.value = False\n",
    "Plot_JHvsMLT_Checkbox.value = False\n",
    "Plot_JHvsAltitude_Checkbox.value = False\n",
    "Plot_AltitudeVsMagLat_Checkbox.value = False\n",
    "Plot_JHdistribution_Checkbox.value = False\n",
    "Plot_AltProfilesCanonical_Checkbox.value = False\n",
    "Plot_AltProfilesNatural_Checkbox.value = False\n",
    "Plot_HeightIntegrated_Checkbox.value = False\n",
    "Plot_ColorSpreads_Checkbox.value = False\n",
    "Plot_PDFperSubBin_Checkbox.value = False\n",
    "#Test_statistical_Checkbox.value = False\n",
    "SavedFilenamesDuplicate_Dropdown.value = \"/home/NAS/Data_Files/CoverageResults/AEM.TIEGCM_Lifetime_2015_to_2018_JH_QD.1HzIntepolatedDATA.ValuesPerBinResults.nc\"\n",
    "#SavedFilenames_Dropdown.value = \"/home/NAS/Data_Files/CoverageResults/TRO.TIEGCM_Lifetime_2015_to_2018_JH_QD.TIEGCM_Lifetime_2015_to_2018_CAMP03.ValuesPerBinResults.nc\"\n",
    "#SavedFilenames_Dropdown.value = \"/home/NAS/Data_Files/CoverageResults/old_noSubBins.TRO.TIEGCM_Lifetime_2015_to_2018_JH_QD.TIEGCM_Lifetime_2015_to_2018_CAMP03.ValuesPerBinResults.nc\"\n",
    "#SavedFilenames_Dropdown.value = \"/home/balukid/old_onlyOhmic.TRO.TIEGCM_Lifetime_2015_to_2018_JH_QD.MultiFileResults/\"\n",
    "SavedFilenames_Dropdown.value = \"/home/NAS/Data_Files/CoverageResults/AEM.TIEGCM_Lifetime_2015_to_2018_JH_QD.Lifetime_10sTricubic.ValuesPerBinResults.nc\"\n",
    "#SavedFilenames_Dropdown.value = \"/home/NAS/Data_Files/CoverageResults/AEM.TIEGCM_Lifetime_2015_to_2018_JH_QD.1HzIntepolatedDATA.ValuesPerBinResults.nc\"\n",
    "BinGroups_Dropdown.value = \"AEM\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
